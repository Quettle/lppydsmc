{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main notebook\n",
    "\n",
    "For quick and generic simulations.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import lppydsmc as ld\n",
    "import plotting\n",
    "\n",
    "# other imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# you can choose the seed here\n",
    "np.random.seed(1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System choice\n",
    "\n",
    "Four default systems can be initialized using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_type = 'thruster_three_grids' # thruster, cylinder\n",
    "\n",
    "# ---------------------- System --------------------\n",
    "dz = 0.001\n",
    "typical_lenght = 0.001 # typical size of the system (minimum distance between two walls for example)\n",
    "                       # used for computing the mean free path later on (not used in the simulation)\n",
    "                       # just useful to have an idea of it.\n",
    "\n",
    "if system_type == 'tube':\n",
    "    system, idx_out_walls, idx_in_wall = ld.systems.helper.system_rectangle(l_x = 0.01, l_y = 0.001)\n",
    "    \n",
    "elif system_type == 'square':\n",
    "    system, idx_out_walls, idx_in_wall = ld.systems.helper.system_rectangle(l_x = 0.01, l_y = 0.01)\n",
    "\n",
    "elif(system_type == 'cylinder'):\n",
    "    system, idx_out_walls, idx_in_wall = ld.systems.helper.cylinder_system(res = 4, l_x = 0.003, l_y = 0.001, c_x = 0.0015 , c_y = 0.0005, r = 0.0001)\n",
    "\n",
    "elif(system_type == 'thruster'):\n",
    "    dp = 1e-3\n",
    "    dict_thruster = {\n",
    "        'w_in' : 5*dp,\n",
    "        'l_in' : 3*dp,\n",
    "        'w_1' : 3*dp,\n",
    "        'l_1' : dp,\n",
    "        'l_int' : dp,\n",
    "        'w_2' : dp,\n",
    "        'l_2' : 10*dp,\n",
    "        'w_out' : 5*dp,\n",
    "        'l_out' : dp,\n",
    "        'offsets' : np.array([0,0]) \n",
    "    }\n",
    "\n",
    "    system, idx_out_walls, idx_in_wall = ld.systems.helper.thruster_system(**dict_thruster)\n",
    "    # idx_out_walls = [10, 9, 11] # not the input wall\n",
    "\n",
    "elif(system_type == 'thruster_three_grids'):\n",
    "    dp = 1e-3\n",
    "    dict_thruster = {\n",
    "        'w_in' : 5*dp,\n",
    "        'l_in' : 3*dp,\n",
    "        'w_1' : 3*dp,\n",
    "        'l_1' : dp,\n",
    "        'l_int' : dp,\n",
    "        'w_2' : dp,\n",
    "        'l_2' : 10*dp,\n",
    "        'l_int_2' : dp,\n",
    "        'w_3' : 3*dp,\n",
    "        'l_3' : 1*dp,\n",
    "        'w_out' : 5*dp,\n",
    "        'l_out' : dp,\n",
    "        'offsets' : np.array([0,0]) \n",
    "    }\n",
    "    system, idx_out_walls, idx_in_wall = ld.systems.helper.thruster_three_grids_system(**dict_thruster)\n",
    "    # idx_out_walls = [13, 14, 15] # not the input wall\n",
    "\n",
    "offsets = system.get_offsets()\n",
    "system_shape = system.system_shape()\n",
    "a = system.get_dir_vects()\n",
    "segments = system.get_segments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSMC grid creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid :\n",
    "mean_number_per_cell = 10000 # 200 is enough to have a \"convergence\", however, it is better to use more for better statistics (you could also average over more time steps in steady state)\n",
    "max_number_per_cell = 10*mean_number_per_cell\n",
    "# factor 10 is completely overshot (Note : a future version will have dynamic arrays instead of static one)\n",
    "\n",
    "if system_type == 'tube':\n",
    "    resolutions = np.array((10,1), dtype = int) # tube\n",
    "\n",
    "elif system_type == 'square':\n",
    "    resolutions = np.array((3,3), dtype = int) # tube\n",
    "\n",
    "elif system_type == 'thruster':\n",
    "    resolutions = np.array((16,5), dtype = int)\n",
    "\n",
    "elif(system_type == 'cylinder'):\n",
    "    resolutions = np.array((9,9), dtype = int)\n",
    "\n",
    "elif system_type == 'thruster_three_grids':\n",
    "    resolutions = np.array((18,5), dtype = int)\n",
    "    \n",
    "cells_number = np.prod(resolutions)\n",
    "grid = ld.data_structures.Grid(cells_number, max_number_per_cell)\n",
    "\n",
    "# --------- useful quantity for the simulation ------------ #\n",
    "volume_cell = dz * system_shape[0]/resolutions[0] * system_shape[1]/resolutions[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Particles Params ----------------- #\n",
    "\n",
    "# particles density in the real system\n",
    "density = 3.2e19 # m-3\n",
    "\n",
    "part_type = 'I'\n",
    "charge, mass, radius = 0, ld.utils.physics.get_mass_part(53, 53, 74), 2e-10\n",
    "\n",
    "temperature = 300 # K \n",
    "v_mean = ld.utils.physics.maxwellian_mean_speed(temperature, mass)\n",
    "\n",
    "size_array = max_number_per_cell*cells_number # max size for the array\n",
    "container = ld.data_structures.Particle(part_type, charge, mass, radius, size_array)\n",
    "\n",
    "# ------ useful quantities for the simulation (or for plotting) ----------- #\n",
    "# ----------- based on params - should not be modified ---------------- #\n",
    "\n",
    "# \"mean number of particles in the simulated system\"\n",
    "n_simu = mean_number_per_cell * cells_number\n",
    "\n",
    "# \"mean number of particles in the real system\"\n",
    "n_real = volume_cell * density * cells_number \n",
    "\n",
    "# macro particules ratio = number of particles in the real system / number of macro part in the simulated system\n",
    "mr = n_real/n_simu \n",
    "\n",
    "# density in the dsmc\n",
    "density_dsmc = density/mr\n",
    "\n",
    "# particle cross section (useful for particles collision)\n",
    "cross_section = container.get_params()[3]  \n",
    "\n",
    "# mean free path and time\n",
    "mfp = ld.utils.physics.mean_free_path(cross_section, density)\n",
    "mft = ld.utils.physics.mean_free_time(mfp, v_mean = v_mean) # min(typical_lenght,mfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_particles = False\n",
    "\n",
    "if(init_particles):\n",
    "    # you have to decice your strategy to initialize a 2D array of size Nx5\n",
    "    # where N is the number of particle\n",
    "    # and each particle is given [x, y, vx, vy, vz].\n",
    "    init_size = mean_number_per_cell*np.prod(resolutions)\n",
    "    extremal_values = system.get_extremal_values() \n",
    "    loc = 0\n",
    "    vel_std = ld.utils.physics.gaussian(temperature, mass)\n",
    "    x = np.random.uniform(low = extremal_values['min_x'], high = extremal_values['max_x'], size = init_size)\n",
    "    y = np.random.uniform(low = extremal_values['min_y'], high = extremal_values['max_y'], size = init_size)\n",
    "    vx = np.random.normal(loc=0.0, scale=vel_std, size = init_size)\n",
    "    vy = np.random.normal(loc=0.0, scale=vel_std, size = init_size)\n",
    "    vz = np.random.normal(loc=0.0, scale=vel_std, size = init_size)\n",
    "    new = np.stack((x,y,vx,vy,vz), axis = 1) \n",
    "\n",
    "    container.add_multiple(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injection params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inject_particles = True\n",
    "\n",
    "if(inject_particles):\n",
    "    in_wall = segments[idx_in_wall]\n",
    "    in_vect = np.array([a[idx_in_wall,1], -a[idx_in_wall,0]]) # should be normalized\n",
    "    in_vect = in_vect/np.linalg.norm(in_vect)\n",
    "    \n",
    "    # for the injection\n",
    "    debit = ld.utils.physics.maxwellian_flux(density_dsmc, v_mean)*np.linalg.norm(in_wall[:2]-in_wall[2:])*dz\n",
    "    vel_std = ld.utils.physics.gaussian(temperature, mass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation params\n",
    "iterations = 5000\n",
    "dt = 1e-6 # in sec.\n",
    "\n",
    "# saving params\n",
    "saving_period = 500 # when do we save various data (see the simulation algo)\n",
    "adding_period = 100 # when to we add to the dataframe that contains the particles position and velocity\n",
    "\n",
    "# advection function - returns a 2D arrays containing the acceleration for each of the given particle\n",
    "    # here arr is a N x 5 array. N particles, and for each one : x, y, vx, vy, vz is stored.\n",
    "    # very simple for now - as there is no electric fields, nor any force in the system \n",
    "    # thus no acceleration\n",
    "accelerations = np.zeros(shape = (size_array, 3))\n",
    "\n",
    "def f(arr, t):\n",
    "    return np.concatenate((arr[:,2:4], accelerations[:arr.shape[0]]), axis = 1)\n",
    "\n",
    "# args is given to euler_explicit and then given to *f* (the advection function) in addition to arr and dt.\n",
    "# in our case, it is not needed. However, we could imagine a system with an electric field computed at the setup phase, \n",
    "# and we would like to give it as an args.\n",
    "args = []\n",
    "scheme = ld.utils.schemes.euler_explicit # rk4; euler_explicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing-up and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing a system of type thruster_three_grids, of shape [0.018 0.005] with 90 cells.\n",
      "The number of particles (type I) in the system is 0.\n",
      "Mean free path : 0.04396075762485869 m ; Mean free time : 0.00019727117199744968 m\n",
      "In steady state, 900000 can be expect in the simulated system, which represents 2880000000000.0 in the real system. The ratio between the two is 3200000.0.\n",
      "The simulation lasts 5000 iterations, with a time step of 1e-06 s. Simulation duration : 0.005 s\n",
      "Disk space usage for saving this simulation (counting ONLY the particles positions and speed) and considering that we save 900000 particles each time is 858.306884765625 MB.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de08f7146a14e859c282aa9f1a64a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Initializing a system of type {system_type}, of shape {system_shape} with {np.prod(resolutions)} cells.')\n",
    "print(f'The number of particles (type {part_type}) in the system is {container.get_current()}.')\n",
    "print(f'Mean free path : {mfp} m ; Mean free time : {mft} m')\n",
    "print(f'In steady state, {n_simu} can be expect in the simulated system, which represents {round(n_real,3)} in the real system. The ratio between the two is {round(mr,3)}.')\n",
    "print(f'The simulation lasts {iterations} iterations, with a time step of {dt} s. Simulation duration : {dt*iterations} s')\n",
    "# Note:  HDF5 uses a different format than csv, and the size on the disk is much different that what is expected. Check out : https://support.hdfgroup.org/HDF5/doc/H5.intro.html\n",
    "# Here, you can at least multiply by 4 the size (considering we save much more than )\n",
    "print(f'Disk space usage for saving this simulation (counting ONLY the particles positions and speed) and considering that we save {n_simu} particles each time is {iterations//adding_period*n_simu*(5*4)/1024**2} MB.') \n",
    "plotting.plt_tools.plot_system(container.get_array(), segments, radius, resolutions, system_shape, offsets);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving directory and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which directory is used to save the data\n",
    "# and under what name.\n",
    "dir_path = Path('results/')\n",
    "name = 'neutral_three_grids.h5' \n",
    "\n",
    "saver = ld.data.saver.Saver(dir_path, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "\n",
    "The next cell takes care of the simulation. It algo gives you an idea of the evolution of the number of particles in the system and of its very general state.\n",
    "\n",
    "At the end, the *saver* which saves the data is closed and you can then analyse your simulation using *analysis.ipynb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    it    |   INIT   |  INJECT  |   DEL    |    TRY   |\n",
      "--------------------------------------------------------\n",
      "|   500    |  251350  |   2785   |   2704   |    3     |\n",
      "|   1000   |  261757  |   2785   |   2775   |    3     |\n",
      "|   1500   |  264826  |   2785   |   2899   |    3     |\n",
      "|   2000   |  265001  |   2785   |   2907   |    3     |\n",
      "|   2500   |  264949  |   2785   |   2808   |    3     |\n",
      "|   3000   |  265919  |   2786   |   2810   |    3     |\n",
      "|   3500   |  265955  |   2786   |   2809   |    3     |\n",
      "|   4000   |  265738  |   2786   |   2827   |    3     |\n",
      "|   4500   |  266010  |   2786   |   2852   |    3     |\n",
      "|   5000   |  265970  |   2786   |   2754   |    3     |\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['x','y','vx','vy','vz']) # bucket for the particles - index of particles is the iteration number\n",
    "nb_colls = np.zeros(grid.current.shape)\n",
    "collisions_with_walls = 0\n",
    "\n",
    "# creating the positions in grids saver\n",
    "# positions_in_grids_save = ld.data_structures.Container(size_array = container.get_max_size(), number_of_elements = 0, dtype=int)\n",
    "\n",
    "# adding particle before the simulation - step 0\n",
    "arr = container.get_array()\n",
    "df = df.append(pd.DataFrame(data=arr, index=[0]*arr.shape[0], columns = ['x','y','vx','vy','vz']))\n",
    "\n",
    "# defining useful arrays and ints \n",
    "remains = 0 # fractionnal part of the number of particles to inject (it is then passed to the following time step)\n",
    "averages = np.full(shape = grid.current.shape, fill_value = mean_number_per_cell) # average number of particles per cell\n",
    "pmax = v_mean*cross_section*np.ones(averages.shape) # np.full(shape = grid.current.shape, fill_value = 1e-13) # max proba per cell in the simu\n",
    "remains_per_cell = np.zeros(shape = grid.current.shape, dtype = float) # remains per cell for the particles collisions step\n",
    "\n",
    "# SIMULATING\n",
    "print('|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|'.format(' it ', ' INIT ', ' INJECT ', ' DEL ', ' TRY'))\n",
    "print('{:-^56}'.format(''))\n",
    "\n",
    "t = 0.0\n",
    "for it in range(1,iterations+1): # tqdm\n",
    "    n1 = container.get_current()\n",
    "                   \n",
    "    # ------------------------- INJECTING PARTICLES -------------------------\n",
    "    new, remains = ld.injection.maxwellian(in_wall, in_vect, debit, vel_std, dt, remains)\n",
    "    \n",
    "    container.add_multiple(new)\n",
    "        \n",
    "    n2 = container.get_current()\n",
    "    \n",
    "    ############################\n",
    "        # adding new particles to grid\n",
    "    # positions = ld.data_structures.grid.default_hashing(ld.data_structures.grid.pos_in_grid(new[:,:2], resolutions, offsets, system_shape), res_y = resolutions[1])\n",
    "    # parts_in_grid_format = ld.data_structures.grid.convert_to_grid_format(old = n1, new = n2)\n",
    "    # grid.add_multiple(positions, parts_in_grid_format)\n",
    "    \n",
    "        # and to the positions in grid saver\n",
    "    # positions_in_grids_save.add_multiple(positions)    \n",
    "    ############################\n",
    "    \n",
    "    # ---------------------------- PHASE : ADVECTING --------------------\n",
    "        # MOVING PARTICLES\n",
    "    arr = container.get_array()\n",
    "    ld.advection.advect(arr, f, dt, t, args, scheme) # advect is inplace\n",
    "    \n",
    "        # HANDLING BOUNDARIES\n",
    "    count = np.full(fill_value = True, shape = arr.shape[0])\n",
    "    idxes_out = []\n",
    "    c = 0\n",
    "    while(np.count_nonzero(count) > 0): # np.sum(count, where = count == True) > 0):\n",
    "        c+=1\n",
    "        ct, cp, cos_alpha = ld.advection.wall_collision.handler_wall_collision_point(arr[count], segments, a) # handler_wall_collision(arr[count], segments, a, radius)\n",
    "        count, idxes_out_, cos_alpha = ld.advection.wall_collision.make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count, cos_alpha) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "        idxes_out.append(idxes_out_)\n",
    "        \n",
    "        # the first one that is received is the number of particles colliding with walls.\n",
    "        if(c == 1):\n",
    "            collisions_with_walls += np.count_nonzero(count) # np.sum(count, where = count == True)\n",
    "    \n",
    "    idxes_out = np.sort(np.concatenate(idxes_out))\n",
    "    \n",
    "    # ----------------------------- PHASE : UPDATING DATA BUCKETS ----------------------------- \n",
    "            # TODO : this is for one container (one species of particle)\n",
    "        \n",
    "    ############################\n",
    "    # new_positions = ld.data_structures.grid.default_hashing(ld.data_structures.grid.pos_in_grid(arr[:,:2], resolutions, offsets, system_shape), res_y = resolutions[1])  \n",
    "    # count = idxes_out.shape[0]-1\n",
    "    # \n",
    "    # for idx in range(container.get_current()-1, -1, -1):\n",
    "    #     old_pos = positions_in_grids_save.get(idx)\n",
    "    #     new_pos = new_positions[idx]\n",
    "    #     \n",
    "    #     if(idxes_out.size > 0 and idx == idxes_out[count]):\n",
    "    #         # particle is outside\n",
    "    #         # we have to delete it\n",
    "    #         current = container.get_current() # current changes with each delete !\n",
    "    #         count -= 1\n",
    "\n",
    "    #         # swapping it with the last one in the container\n",
    "    #         container.delete(idx)\n",
    "    #         positions_in_grids_save.delete(idx)\n",
    "    #         # deleting the object in the grid\n",
    "    #         grid.remove(old_pos, np.array([0,idx], dtype = int)) # since [idx container, idx] is a unique key, we check for equality in values of the array (not in references)\n",
    "\n",
    "    #         # updating the swapped particle in the grid\n",
    "    #         swapping_particle_pos = positions_in_grids_save.get(idx) # this supposes that positions_in_grids_save is up-to-date for the particle previously at index 'current-1' (and now at index 'idx'). \n",
    "    #         # this is why we are iterating from the end\n",
    "    #         grid.update_index(swapping_particle_pos, idx_container = 0, old_index = current-1, new_index = idx)\n",
    "    #     elif(np.array_equal(old_pos, new_pos)):\n",
    "    #         pass\n",
    "    #     else:\n",
    "    #         # then the particle does not need to be deleted, just updated\n",
    "    #         grid.update(o = np.array([0,idx]), old_pos = old_pos, new_pos = new_pos) # in theory it should not changed the value of the object (indeed, its position in the grid should not have changed !)\n",
    "    #         # and update the new positions in grid in the saver\n",
    "    #         positions_in_grids_save.update(idx, new_pos)\n",
    "            \n",
    "    # arr = container.get_array()\n",
    "    ############################\n",
    "    \n",
    "    ############################\n",
    "    container.delete_multiple(idxes_out)\n",
    "    arr = container.get_array()\n",
    "    new_positions = ld.data_structures.grid.default_hashing(ld.data_structures.grid.pos_in_grid(arr[:,:2], resolutions, offsets, system_shape), res_y = resolutions[1])  \n",
    "    grid.reset()\n",
    "    parts_in_grid_format = ld.data_structures.grid.convert_to_grid_format(new = new_positions.shape[0])\n",
    "    grid.add_multiple(new_positions, parts_in_grid_format)\n",
    "    ############################\n",
    "\n",
    "    # ----------------------------- PHASE : DSMC COLLISIONS ----------------------------- \n",
    "        # TODO: make parallel (1st : note criticals functions in C++)\n",
    "    currents = grid.get_currents()\n",
    "    averages = (it*averages+currents)/(it+1) # TODO: may be it too violent ? \n",
    "    \n",
    "    remains_per_cell, nb_colls_, pmax, monitor = ld.collision.handler_particles_collisions([arr], grid.get_grid(), currents, dt, averages, pmax, cross_section, volume_cell, mr, remains_per_cell, monitoring = True)\n",
    "    nb_colls+=nb_colls_\n",
    "    t += dt\n",
    "    \n",
    "    # ----------------------------- PLOTTING AND SAVING (OPTIONAL) ----------------------------- \n",
    "    if(it%adding_period == 0 or it == iterations):\n",
    "        df = df.append(pd.DataFrame(data=arr, index=[it]*arr.shape[0], columns = ['x','y','vx','vy','vz']))\n",
    "        \n",
    "    if(it%saving_period == 0 or it == iterations): # saving if last iteration too\n",
    "        saver.save(it = it, append = {\n",
    "                        'df' : df,\n",
    "                        'collisions_per_cell' : nb_colls, # evolution of the number of collisions per cell - size : grid.shape[0] x grid.shape[1] (2D)\n",
    "                        'total_distance' : float(monitor[0]), # evolution of the sum of the distance accross all cells \n",
    "                        'total_proba' : float(monitor[1]), # evolution of the sum of proba accross all cells\n",
    "                        'pmax_per_cell' : pmax,  # evolution of the sum of pmax - per cell (2D)\n",
    "                        'total_deleted' : len(idxes_out), # evolution of the number of deleted particles per cell (int)\n",
    "                        'averages_per_cell' : averages, # evolution of the average number of particle per cell\n",
    "                        'collisions_with_walls' : collisions_with_walls, # number of collisions with walls - evolution\n",
    "\n",
    "                  })\n",
    "        \n",
    "        print('|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|'.format(it, n1, n2-n1, idxes_out.shape[0], c))\n",
    "        \n",
    "        \n",
    "        # resetting dataframe to not use too much memory\n",
    "        nb_colls = np.zeros(grid.current.shape)\n",
    "        collisions_with_walls = 0\n",
    "        df = pd.DataFrame(columns = ['x','y','vx','vy','vz'])\n",
    "        \n",
    "saver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
