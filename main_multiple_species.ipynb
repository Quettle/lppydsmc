{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c48f46",
   "metadata": {},
   "source": [
    "# Main notebook\n",
    "\n",
    "For quick and generic simulations.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f0e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import lppydsmc as ld\n",
    "import plotting\n",
    "\n",
    "# other imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "# you can choose the seed here\n",
    "np.random.seed(1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7a422",
   "metadata": {},
   "source": [
    "## System choice\n",
    "\n",
    "Four default systems can be initialized using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c464453",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_type = 'thruster_three_grids' # thruster, cylinder\n",
    "\n",
    "# ---------------------- System --------------------\n",
    "dz = 0.001\n",
    "typical_lenght = 0.001 # typical size of the system (minimum distance between two walls for example)\n",
    "                       # used for computing the mean free path later on (not used in the simulation)\n",
    "                       # just useful to have an idea of it.\n",
    "\n",
    "if system_type == 'tube':\n",
    "    system, idx_out_walls, idx_in_wall = ld.systems.helper.system_rectangle(l_x = 0.01, l_y = 0.001)\n",
    "    \n",
    "elif system_type == 'square':\n",
    "    system, idx_out_walls, idx_in_wall = ld.systems.helper.system_rectangle(l_x = 0.01, l_y = 0.01)\n",
    "\n",
    "elif(system_type == 'cylinder'):\n",
    "    system, idx_out_walls, idx_in_wall = ld.systems.helper.cylinder_system(res = 4, l_x = 0.003, l_y = 0.001, c_x = 0.0015 , c_y = 0.0005, r = 0.0001)\n",
    "\n",
    "elif(system_type == 'thruster'):\n",
    "    dp = 1e-3\n",
    "    dict_thruster = {\n",
    "        'w_in' : 5*dp,\n",
    "        'l_in' : 3*dp,\n",
    "        'w_1' : 3*dp,\n",
    "        'l_1' : dp,\n",
    "        'l_int' : dp,\n",
    "        'w_2' : dp,\n",
    "        'l_2' : 10*dp,\n",
    "        'w_out' : 5*dp,\n",
    "        'l_out' : dp,\n",
    "        'offsets' : np.array([0,0]) \n",
    "    }\n",
    "\n",
    "    system, idx_out_walls, idx_in_wall = ld.systems.helper.thruster_system(**dict_thruster)\n",
    "    # idx_out_walls = [10, 9, 11] # not the input wall\n",
    "\n",
    "elif(system_type == 'thruster_three_grids'):\n",
    "    dp = 1e-3\n",
    "    dict_thruster = {\n",
    "        'w_in' : 5*dp,\n",
    "        'l_in' : 3*dp,\n",
    "        'w_1' : 3*dp,\n",
    "        'l_1' : dp,\n",
    "        'l_int' : dp,\n",
    "        'w_2' : dp,\n",
    "        'l_2' : 10*dp,\n",
    "        'l_int_2' : dp,\n",
    "        'w_3' : 3*dp,\n",
    "        'l_3' : 1*dp,\n",
    "        'w_out' : 5*dp,\n",
    "        'l_out' : dp,\n",
    "        'offsets' : np.array([0,0]) \n",
    "    }\n",
    "    system, idx_out_walls, idx_in_wall = ld.systems.helper.thruster_three_grids_system(**dict_thruster)\n",
    "    # idx_out_walls = [13, 14, 15] # not the input wall\n",
    "\n",
    "offsets = system.get_offsets()\n",
    "system_shape = system.system_shape()\n",
    "a = system.get_dir_vects()\n",
    "segments = system.get_segments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ad0648-8e53-4254-be0e-653cec6ba293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric field and stuff\n",
    "import lppydsmc.poisson_solver as ps\n",
    "\n",
    "charge_density = {\n",
    "            'value' : '0',  # must be a string too\n",
    "            'degree' : 0,\n",
    "            'kwargs' : {}\n",
    "            }\n",
    "\n",
    "potential_field, electric_field = ps.helper.thruster(dimensions = dict_thruster, mesh_resolution = 100, \\\n",
    "                                                     potential_electrode_1 = '30', potential_electrode_2 = '300', \\\n",
    "                                                     potential_electrode_3 = '-100', charge_density = charge_density)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976a4e3",
   "metadata": {},
   "source": [
    "## DSMC grid creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b5cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid :\n",
    "mean_numbers_per_cell = np.array([2000, 20]) # 20 # choose them so that each specie has the same weight\n",
    "max_numbers_per_cell = 10*mean_numbers_per_cell\n",
    "# factor 10 is completely overshot (Note : a future version will have dynamic arrays instead of static one)\n",
    "\n",
    "if system_type == 'tube':\n",
    "    resolutions = np.array((10,1), dtype = int) # tube\n",
    "\n",
    "elif system_type == 'square':\n",
    "    resolutions = np.array((3,3), dtype = int) # tube\n",
    "\n",
    "elif system_type == 'thruster':\n",
    "    resolutions = np.array((16,5), dtype = int)\n",
    "\n",
    "elif(system_type == 'cylinder'):\n",
    "    resolutions = np.array((9,9), dtype = int)\n",
    "\n",
    "elif system_type == 'thruster_three_grids':\n",
    "    resolutions = np.array((18,5), dtype = int)\n",
    "    \n",
    "cells_number = np.prod(resolutions)\n",
    "grid = ld.data_structures.Grid(cells_number, np.sum(max_numbers_per_cell))\n",
    "\n",
    "# --------- useful quantity for the simulation ------------ #\n",
    "volume_cell = dz * system_shape[0]/resolutions[0] * system_shape[1]/resolutions[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d43ca1",
   "metadata": {},
   "source": [
    "## Particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74e044e-29a2-441a-90d0-9e994bad890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# useless\n",
    "def init_max_proba(radii, mean_speeds, grid_shape):\n",
    "    # radii and v_mean are of size Ns(number of species)\n",
    "    # grid_shape is of size Nc (the number of cells)\n",
    "    shape_pmax = [radii.shape[0], radii.shape[0]] + list(grid_shape)\n",
    "    pmax = np.ones(tuple(shape_pmax), dtype = float)\n",
    "    cross_sections = np.ones(tuple(shape_pmax), dtype = float)\n",
    "\n",
    "    for i in range(pmax.shape[0]):\n",
    "        for j in range(i+1):\n",
    "            if(i==j):\n",
    "                cross_sections[i,j] = np.pi * 4*radii[i]**2\n",
    "                pmax[i,j] *= 2*mean_speeds[i] * np.pi * 4*radii[i]**2  # we'll take the max proba straight away ?\n",
    "            else:\n",
    "                cross_sections[i,j] = np.pi * (radii[i]+radii[1])**2 \n",
    "                pmax[i,j] *= np.abs(mean_speeds[i]-mean_speeds[j]) * np.pi * (radii[i]+radii[1])**2   # we'll take the max proba straight away ?\n",
    "    return pmax, cross_sections\n",
    "\n",
    "def cross_sections(radii, mean_speeds):\n",
    "    # radii and v_mean are of size Ns(number of species)\n",
    "    # grid_shape is of size Nc (the number of cells)\n",
    "    shape_out = [radii.shape[0], radii.shape[0]]\n",
    "    cross_sections = np.ones(tuple(shape_out), dtype = float)\n",
    "\n",
    "    for i in range(cross_sections.shape[0]):\n",
    "        for j in range(i+1):\n",
    "            if(i==j):\n",
    "                cross_sections[i,j] = np.pi * 4*radii[i]**2\n",
    "            else:\n",
    "                cross_sections[i,j] = np.pi * (radii[i]+radii[1])**2 \n",
    "                cross_sections[j,i] = cross_sections[i,j]\n",
    "    return cross_sections\n",
    "\n",
    "def convert(species):\n",
    "    \"\"\"\n",
    "    Convert from dictionnary of species to dictionnary of quantities.\n",
    "    \"\"\"\n",
    "    dico = {}\n",
    "    \n",
    "    types = []\n",
    "    densities = []\n",
    "    charges = []\n",
    "    masses = []\n",
    "    radii = []\n",
    "    temperatures = []\n",
    "    \n",
    "    for key, val in species.items():\n",
    "        types.append(key)\n",
    "        densities.append(val['density'])\n",
    "        charges.append(val['charge'])\n",
    "        masses.append(val['mass'])\n",
    "        radii.append(val['radius'])\n",
    "        temperatures.append(val['temperature'])\n",
    "        \n",
    "        \n",
    "    dico['types'] = types\n",
    "    dico['densities'] = np.array(densities)\n",
    "    dico['charges'] = np.array(charges)\n",
    "    dico['masses'] = np.array(masses)\n",
    "    dico['radii'] = np.array(radii)\n",
    "    dico['temperatures'] = np.array(temperatures)\n",
    "    \n",
    "    # count of species\n",
    "    dico['count'] = len(types)\n",
    "    \n",
    "    return dico\n",
    "\n",
    "def species_setup(species, init_number_per_cells, number_of_cells, cell_volume):\n",
    "    params = convert(species)\n",
    "    \n",
    "    types = params['types']\n",
    "    densities = params['densities']\n",
    "    charges = params['charges']\n",
    "    masses = params['masses']\n",
    "    radii = params['radii']\n",
    "    temperatures = params['temperatures']\n",
    "    \n",
    "    # computed quantities\n",
    "    size_arrays = init_number_per_cells*number_of_cells # max size for the array\n",
    "    \n",
    "    params['mean_speeds'] =  ld.utils.physics.maxwellian_mean_speed(temperatures, masses)\n",
    "    params['containers'] = [ld.data_structures.Particle(types[k], charges[k], masses[k], radii[k], size_arrays[k]) for k in range(params['count'])]\n",
    "    \n",
    "    params['total_number_particles_simu'] = init_number_per_cells * number_of_cells\n",
    "    params['total_number_particles_real'] = cell_volume * densities * number_of_cells \n",
    "    params['particles_weight'] = params['total_number_particles_real']/params['total_number_particles_simu']\n",
    "    params['particles_weight'] = params['particles_weight'].astype(int)\n",
    "    w0 = params['particles_weight'][0]\n",
    "    for w in params['particles_weight']:\n",
    "        assert(w0==w)\n",
    "    params['particles_weight'] = w0\n",
    "    params['densities_dsmc'] = densities/params['particles_weight']\n",
    "    \n",
    "    params['cross_sections'] = cross_sections(radii, params['mean_speeds']) # np.array([params['containers'][k].get_params()[3] for k in range(params['count'])])\n",
    "    \n",
    "    params['mean_free_paths'] = ld.utils.physics.mean_free_path(params['cross_sections'], np.sum(densities)) # taking the sum of all densities\n",
    "    params['mean_free_times'] = ld.utils.physics.mean_free_time(params['mean_free_paths'], v_mean = params['mean_speeds'])\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3dd4707-a486-4943-9b7b-41862212d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = {\n",
    "    'I' : {\n",
    "        'density' : 3.2e19, # m-3\n",
    "        'charge' : 0, # C\n",
    "        'mass' : ld.utils.physics.get_mass_part(53, 53, 74), # kg\n",
    "        'radius' : 2e-10, # m\n",
    "        'temperature' : 300, # K\n",
    "    },\n",
    "    'I-' : {\n",
    "        'density' : 3.2e17, # m-3\n",
    "        'charge' : ld.utils.physics.ELECTRON_CHARGE, # C\n",
    "        'mass' : ld.utils.physics.get_mass_part(53+1, 53, 74), # kg\n",
    "        'radius' : 2e-10, # m\n",
    "        'temperature' : 1000, # K\n",
    "    }\n",
    "}\n",
    "\n",
    "reactions_list = [\n",
    "    'I- : I'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdf4015-a6ea-4fa2-9d82-a2a019fd57cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-': {'#': 1, 'reactants': ['I-'], 1: ['I']}}\n"
     ]
    }
   ],
   "source": [
    "params_species = species_setup(species, init_number_per_cells = mean_numbers_per_cell, number_of_cells = cells_number, cell_volume = volume_cell)\n",
    "reactions = ld.advection.reactions.parse(reactions_list)\n",
    "print(reactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb02c442",
   "metadata": {},
   "source": [
    "## Initialization of particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79de8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_particles = False\n",
    "\n",
    "# TODO:  make it compatible with several species\n",
    "if(init_particles):\n",
    "    # you have to decice your strategy to initialize a 2D array of size Nx5\n",
    "    # where N is the number of particle\n",
    "    # and each particle is given [x, y, vx, vy, vz].\n",
    "    init_size = mean_number_per_cell*np.prod(resolutions)\n",
    "    extremal_values = system.get_extremal_values() \n",
    "    loc = 0\n",
    "    vel_std = ld.utils.physics.gaussian(temperature, mass)\n",
    "    x = np.random.uniform(low = extremal_values['min_x'], high = extremal_values['max_x'], size = init_size)\n",
    "    y = np.random.uniform(low = extremal_values['min_y'], high = extremal_values['max_y'], size = init_size)\n",
    "    vx = np.random.normal(loc=0.0, scale=vel_std, size = init_size)\n",
    "    vy = np.random.normal(loc=0.0, scale=vel_std, size = init_size)\n",
    "    vz = np.random.normal(loc=0.0, scale=vel_std, size = init_size)\n",
    "    new = np.stack((x,y,vx,vy,vz), axis = 1) \n",
    "\n",
    "    container.add_multiple(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492324ec-5751-4b9f-97af-544c3d7cf725",
   "metadata": {},
   "source": [
    "## Load particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f97d43-392c-4a14-a1d5-9752967fc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_particles = True\n",
    "\n",
    "# TODO:  make it compatible with several species\n",
    "if(load_particles):\n",
    "    dir_path = Path('results/')\n",
    "    name = 'neutral_three_grids.h5'\n",
    "    store = pd.HDFStore(dir_path/name)\n",
    "    df = store['df']\n",
    "    unique_index = df.index.unique().values\n",
    "    new = df.loc[df.index == unique_index[-1]][['x','y','vx','vy','vz']].values\n",
    "    params_species['containers'][0].add_multiple(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b01b1d6-9061-411e-98d6-1fbbdd871321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53128\n"
     ]
    }
   ],
   "source": [
    "print(new.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6013a8",
   "metadata": {},
   "source": [
    "## Injection params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "370c6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "inject_particles = True\n",
    "\n",
    "drifts = np.array([0,2000.], dtype = float) # if you want to add drifts\n",
    "\n",
    "if(inject_particles):\n",
    "    densities_dsmc = params_species['densities_dsmc']\n",
    "    mean_speeds = params_species['mean_speeds']\n",
    "    temperatures = params_species['temperatures']\n",
    "    masses = params_species['masses']\n",
    "    in_wall = segments[idx_in_wall]\n",
    "    in_vect = np.array([a[idx_in_wall,1], -a[idx_in_wall,0]]) # should be normalized\n",
    "    in_vect = in_vect/np.linalg.norm(in_vect)\n",
    "    \n",
    "    # for the injection\n",
    "    debits= ld.utils.physics.maxwellian_flux(densities_dsmc, mean_speeds)*np.linalg.norm(in_wall[:2]-in_wall[2:])*dz\n",
    "    vel_stds = ld.utils.physics.gaussian(temperatures, masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b7a30",
   "metadata": {},
   "source": [
    "## Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34061913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation params\n",
    "iterations = 20000\n",
    "dt = 1e-8 # in sec.\n",
    "\n",
    "# saving params\n",
    "saving_period = 500 # when do we save various data (see the simulation algo)\n",
    "adding_period = 50 # when to we add to the dataframe that contains the particles position and velocity\n",
    "\n",
    "# advection function - returns a 2D arrays containing the acceleration for each of the given particle\n",
    "    # here arr is a N x 5 array. N particles, and for each one : x, y, vx, vy, vz is stored.\n",
    "    # very simple for now - as there is no electric fields, nor any force in the system \n",
    "    # thus no acceleration\n",
    "\n",
    "accelerations = np.zeros(shape = (params_species['containers'][0].get_max_size(), 3))\n",
    "\n",
    "def f_i(arr, t):\n",
    "    return np.concatenate((arr[:,2:4], accelerations[:arr.shape[0]]), axis = 1)\n",
    "\n",
    "# args is given to euler_explicit and then given to *f* (the advection function) in addition to arr and dt.\n",
    "# in our case, it is not needed. However, we could imagine a system with an electric field computed at the setup phase, \n",
    "# and we would like to give it as an args.\n",
    "args_i = []\n",
    "scheme_i = ld.utils.schemes.euler_explicit # rk4; euler_explicit\n",
    "\n",
    "\n",
    "# advection function - returns a 2D arrays containing the acceleration for each of the given particle\n",
    "    # here arr is a N x 5 array. N particles, and for each one : x, y, vx, vy, vz is stored.\n",
    "    \n",
    "def f_im(arr, t, m, q, electric_field):\n",
    "    der = np.zeros((arr.shape[0], 5)) # (vx, vy, ax, ay, az)\n",
    "    fact  = q/m\n",
    "    for k, part in enumerate(arr):\n",
    "        try:\n",
    "            der[k,2:4] =  fact * electric_field(part[:2]) # no acceleration on z\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    der[:,:2] = arr[:,2:4]\n",
    "    return der\n",
    "\n",
    "# args is given to euler_explicit and then given to *f* (the advection function) in addition to arr and dt.\n",
    "# in our case, it is not needed. However, we could imagine a system with an electric field computed at the setup phase, \n",
    "# and we would like to give it as an args.\n",
    "args_im = [params_species['masses'][1], params_species['charges'][1], electric_field]\n",
    "scheme_im = ld.utils.schemes.rk4\n",
    "\n",
    "update_functions = [f_i, f_im]\n",
    "args_update_functions = [args_i, args_im]\n",
    "schemes = [scheme_i, scheme_im]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88d3d6a",
   "metadata": {},
   "source": [
    "## Summing-up and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47178142-b083-4885-b7cf-49ea14d0c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot_simu = np.sum(params_species['total_number_particles_simu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad5125a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing a system of type thruster_three_grids, of shape [0.018 0.005] with 90 cells.\n",
      "Species parameters : \n",
      "\n",
      "{'charges': array([ 0.0e+00, -1.6e-19]),\n",
      " 'containers': [<lppydsmc.data_structures.particle.Particle object at 0x7f893869b2d0>,\n",
      "                <lppydsmc.data_structures.particle.Particle object at 0x7f89386ab090>],\n",
      " 'count': 2,\n",
      " 'cross_sections': array([[5.02654825e-19, 5.02654825e-19],\n",
      "       [5.02654825e-19, 5.02654825e-19]]),\n",
      " 'densities': array([3.2e+19, 3.2e+17]),\n",
      " 'densities_dsmc': array([2.e+12, 2.e+10]),\n",
      " 'masses': array([2.12392283e-25, 2.12393194e-25]),\n",
      " 'mean_free_paths': array([[0.0435255, 0.0435255],\n",
      "       [0.0435255, 0.0435255]]),\n",
      " 'mean_free_times': array([[0.00019532, 0.00010698],\n",
      "       [0.00019532, 0.00010698]]),\n",
      " 'mean_speeds': array([222.84430705, 406.85530673]),\n",
      " 'particles_weight': 16000000,\n",
      " 'radii': array([2.e-10, 2.e-10]),\n",
      " 'temperatures': array([ 300, 1000]),\n",
      " 'total_number_particles_real': array([2.88e+12, 2.88e+10]),\n",
      " 'total_number_particles_simu': array([180000,   1800]),\n",
      " 'types': ['I', 'I-']}\n",
      "The simulation lasts 20000 iterations, with a time step of 1e-08 s. Simulation duration : 0.0002 s\n",
      "Disk space usage for saving this simulation (counting ONLY the particles positions and speed) and considering that we save 181800 particles each time is 1387.02392578125 MB.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f71c2d1b084486883fb7fd10902013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Initializing a system of type {system_type}, of shape {system_shape} with {np.prod(resolutions)} cells.')\n",
    "print(f'Species parameters : \\n')\n",
    "pprint(params_species)\n",
    "print(f'The simulation lasts {iterations} iterations, with a time step of {dt} s. Simulation duration : {dt*iterations} s')\n",
    "# Note:  HDF5 uses a different format than csv, and the size on the disk is much different that what is expected. Check out : https://support.hdfgroup.org/HDF5/doc/H5.intro.html\n",
    "# Here, you can at least multiply by 4 the size (considering we save much more than )\n",
    "print(f'Disk space usage for saving this simulation (counting ONLY the particles positions and speed) and considering that we save {n_tot_simu} particles each time is {iterations//adding_period*n_tot_simu*(5*4)/1024**2} MB.') \n",
    "plotting.plt_tools.plot_system(params_species['containers'][0].get_array(), segments, 0.1, resolutions, system_shape, offsets);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514540a8",
   "metadata": {},
   "source": [
    "# Saving directory and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aa8d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which directory is used to save the data\n",
    "# and under what name.\n",
    "dir_path = Path('results/')\n",
    "name = 'test_dmsc_reactions_with_loading.h5' \n",
    "\n",
    "saver = ld.data.saver.Saver(dir_path, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7241c3",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "\n",
    "The next cell takes care of the simulation. It algo gives you an idea of the evolution of the number of particles in the system and of its very general state.\n",
    "\n",
    "At the end, the *saver* which saves the data is closed and you can then analyse your simulation using *analysis.ipynb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76911f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    it    |   INIT   |  INJECT  |   DEL    |    TRY   | C. WALLS | C. PARTS |\n",
      "------------------------------------------------------------------------------\n",
      "|   500    |  53119   |    6     |    0     |    1     |  15348   |   1137   |\n",
      "|   1000   |  53097   |    6     |    0     |    1     |  15144   |   2253   |\n",
      "|   1500   |  53163   |    5     |    0     |    1     |  15056   |   2687   |\n",
      "|   2000   |  53112   |    6     |    0     |    1     |  14838   |   3181   |\n",
      "|   2500   |  53102   |    5     |    0     |    1     |  15067   |   3237   |\n",
      "|   3000   |  53148   |    6     |    0     |    1     |  14936   |   3215   |\n",
      "|   3500   |  53098   |    5     |    0     |    2     |  15016   |   3264   |\n",
      "|   4000   |  53042   |    6     |    0     |    1     |  15058   |   3330   |\n",
      "|   4500   |  53134   |    5     |    0     |    1     |  14921   |   3333   |\n",
      "|   5000   |  53223   |    6     |    0     |    1     |  15046   |   3663   |\n",
      "|   5500   |  53266   |    6     |    0     |    1     |  15239   |   3779   |\n",
      "|   6000   |  53312   |    5     |    0     |    1     |  15002   |   4345   |\n",
      "|   6500   |  53282   |    6     |    0     |    1     |  15065   |   4947   |\n",
      "|   7000   |  53221   |    5     |    0     |    1     |  15102   |   5020   |\n",
      "|   7500   |  53184   |    6     |    0     |    2     |  14993   |   5107   |\n",
      "|   8000   |  53159   |    5     |    0     |    1     |  15054   |   5161   |\n",
      "|   8500   |  53159   |    6     |    0     |    1     |  14957   |   5233   |\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['x','y','vx','vy','vz','species']) # bucket for the particles - index of particles is the iteration number\n",
    "df_out_particles = pd.DataFrame(columns = ['x','y','vx','vy','vz','species'])\n",
    "nb_colls = np.zeros(grid.current.shape)\n",
    "collisions_with_walls = 0\n",
    "# df_collision_with_walls = pd.DataFrame(columns = ['x','y','type'])\n",
    "\n",
    "# adding particle before the simulation - step 0\n",
    "nb_species = params_species['count']\n",
    "containers = params_species['containers']\n",
    "types = params_species['types']\n",
    "types_dict = {}\n",
    "for idx, t in enumerate(types):\n",
    "    types_dict[t] = idx\n",
    "arrays = [containers[k].get_array() for k in range(nb_species)]\n",
    "masses = [containers[k].mass() for k in range(nb_species)]\n",
    "\n",
    "# No injection\n",
    "# for arr, typ in zip(arrays, types):\n",
    "#   df = df.append(pd.DataFrame(data=np.concatenate((arr, [typ]*arr.shape[0]), axis = 1), index=[0]*arr.shape[0], columns = ['x','y','vx','vy','vz','species']))\n",
    "\n",
    "# defining useful arrays and ints \n",
    "    # injection\n",
    "remains = np.zeros((nb_species)) # fractionnal part of the number of particles to inject (it is then passed to the following time step)\n",
    "    # grids\n",
    "averages = np.full(shape = grid.current.shape, fill_value = np.sum(mean_numbers_per_cell)) # average number of particles per cell\n",
    "cross_sections = params_species['cross_sections']\n",
    "pmax = 2*np.min(params_species['mean_speeds'])*np.mean(cross_sections)*np.ones(averages.shape) # max proba per cell in the simu\n",
    "remains_per_cell = np.zeros(shape = grid.current.shape, dtype = float) # remains per cell for the particles collisions step\n",
    "\n",
    "# SIMULATING\n",
    "print('|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|'.format(' it ', ' INIT ', ' INJECT ', ' DEL ', ' TRY', ' C. WALLS', ' C. PARTS' ))\n",
    "print('{:-^78}'.format(''))\n",
    "\n",
    "t = 0.0\n",
    "for it in range(1,iterations+1): # tqdm\n",
    "    n1 = np.sum([containers[k].get_current() for k in range(nb_species)])\n",
    "    \n",
    "    # ------------------------- INJECTING PARTICLES -------------------------\n",
    "    \n",
    "    for k in range(nb_species):\n",
    "        new, remains[k] = ld.injection.maxwellian(in_wall, in_vect, debits[k], vel_stds[k], dt, remains[k], drifts[k])\n",
    "        containers[k].add_multiple(new)\n",
    "        \n",
    "    n2 = np.sum([containers[k].get_current() for k in range(nb_species)])\n",
    "    \n",
    "    # ---------------------------- PHASE : ADVECTING --------------------\n",
    "        # MOVING PARTICLES\n",
    "    arrays = [containers[k].get_array() for k in range(nb_species)]\n",
    "    \n",
    "    \n",
    "    for k in range(nb_species):\n",
    "        ld.advection.advect(arrays[k], update_functions[k], dt, t, args_update_functions[k], schemes[k]) # advect is inplace\n",
    "    \n",
    "        # HANDLING BOUNDARIES\n",
    "    \n",
    "    list_counts = []\n",
    "    for k in range(nb_species):\n",
    "        # initializing local variable\n",
    "        arr = arrays[k]\n",
    "        container = containers[k]\n",
    "        \n",
    "        count = np.full(fill_value = True, shape = arr.shape[0])\n",
    "        idxes_out = []\n",
    "        collided = []\n",
    "        c = 0\n",
    "        while(np.count_nonzero(count) > 0): # np.sum(count, where = count == True) > 0):\n",
    "            c+=1\n",
    "            ct, cp, cos_alpha = ld.advection.wall_collision.handler_wall_collision_point(arr[count], segments, a) # handler_wall_collision(arr[count], segments, a, radius)\n",
    "            count, idxes_out_, cos_alpha = ld.advection.wall_collision.make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count, cos_alpha) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "            idxes_out.append(idxes_out_)\n",
    "\n",
    "            # the first one that is received is the number of particles colliding with walls.\n",
    "            if(c == 1):\n",
    "                collisions_with_walls += np.count_nonzero(count) # np.sum(count, where = count == True)\n",
    "                collided = np.copy(count) # np.where(collided[:collided_current], 1, 0)\n",
    "                \n",
    "        if(len(idxes_out)>0):\n",
    "            idxes_out = np.sort(np.concatenate(idxes_out))\n",
    "            \n",
    "            collided_current = collided.shape[0]\n",
    "            \n",
    "            for idx in np.flip(idxes_out): # view = constant time \n",
    "                collided[idx] = collided[collided_current-1]\n",
    "                collided_current -= 1\n",
    "                \n",
    "            list_counts.append(np.expand_dims(np.where(collided[:collided_current])[0], axis = 1))\n",
    "            \n",
    "            out_arr = container.pop_multiple(idxes_out)\n",
    "            # using k instead of types[k] because this avoids using string in the dataframes which ALWAYS goes bad\n",
    "            df_out_particles = df_out_particles.append(pd.DataFrame(data=np.concatenate((out_arr, np.expand_dims([k]*out_arr.shape[0], axis = 1)), axis = 1), index=[it]*out_arr.shape[0], columns = ['x','y','vx','vy','vz','species']))\n",
    "        else:\n",
    "            list_counts.append(np.array([])) # appending empty list to conserve the correspondance between rank in the global list and species\n",
    "    \n",
    "\n",
    "        \n",
    "    particles_to_add = {}\n",
    "    for k in range(nb_species):\n",
    "        if types[k] in reactions:\n",
    "            reacting_particles, particles_to_add_ = ld.advection.reactions.react(np.array(list_counts[k]), arrays = arrays, masses = masses, types_dict = types_dict, reactions = reactions[types[k]], p = None)\n",
    "            # reacting_particles should be deleted in arrays[k]\n",
    "            # particles_to_add should be added the the asssociated array\n",
    "            list_counts[k] = reacting_particles # updating the actually reacting particles\n",
    "\n",
    "            for key, val in particles_to_add_.items():\n",
    "                if(key in particles_to_add):\n",
    "                    particles_to_add[key] += val\n",
    "                else:\n",
    "                    particles_to_add[key] = val\n",
    "        else:\n",
    "            list_counts[k] = np.array([]) \n",
    "    # then and only then we delete everything in the update list_counts\n",
    "    # print(f'Total collision with walls: {collisions_with_walls}')\n",
    "    # print('DELETE')\n",
    "    for k in range(nb_species): # here it's only one particle as it is colliding with the wall\n",
    "        # thus it is easier to delete\n",
    "        # print('{} - {}'.format(types[k], list_counts[k].shape[0]))\n",
    "        containers[k].delete_multiple(list_counts[k])\n",
    "        if(types[k] in particles_to_add):\n",
    "            # print('ADDING - {} - {}'.format(types[k], len(particles_to_add[types[k]])))\n",
    "            containers[k].add_multiple(np.array(particles_to_add[types[k]]))\n",
    "    \n",
    "    arrays = [containers[k].get_array() for k in range(nb_species)]\n",
    "    \n",
    "    grid.reset()\n",
    "    for k in range(nb_species):\n",
    "        arr = arrays[k]\n",
    "        new_positions = ld.data_structures.grid.default_hashing(ld.data_structures.grid.pos_in_grid(arr[:,:2], resolutions, offsets, system_shape), res_y = resolutions[1])  \n",
    "        parts_in_grid_format = ld.data_structures.grid.convert_to_grid_format(new = new_positions.shape[0], old = 0, container_idx = k)\n",
    "        grid.add_multiple(new_positions, parts_in_grid_format)\n",
    " \n",
    "    # ----------------------------- PHASE : DSMC COLLISIONS ----------------------------- \n",
    "        # TODO: make parallel (1st : note criticals functions in C++)    \n",
    "    currents = grid.get_currents()\n",
    "    averages = (it*averages+currents)/(it+1) # TODO: may be it too violent ? \n",
    "\n",
    "    remains_per_cell, nb_colls_, pmax, monitor = ld.collision.handler_particles_collisions(arrays, grid.get_grid(), currents, dt, averages, pmax, cross_sections, volume_cell, params_species['particles_weight'], remains_per_cell, monitoring = True)\n",
    "    nb_colls += nb_colls_\n",
    "    t += dt\n",
    "    \n",
    "    # ----------------------------- PLOTTING AND SAVING (OPTIONAL) ----------------------------- \n",
    "    if(it%adding_period == 0 or it == iterations):\n",
    "        # print('Mean speed : ' + ' - '.join([str(np.mean(np.linalg.norm(arrays[k][:,2:], axis = 1))) for k in range(nb_species)]) + '\\t m/s')\n",
    "        for k, arr in enumerate(arrays):\n",
    "            df = df.append(pd.DataFrame(data=np.concatenate((arr, np.expand_dims([k]*arr.shape[0], axis = 1)), axis = 1), index=[it]*arr.shape[0], columns = ['x','y','vx','vy','vz','species']))\n",
    "            \n",
    "    if(it%saving_period == 0 or it == iterations): # saving if last iteration too\n",
    "        saver.save(it = it, append = {\n",
    "                        'df' : df,\n",
    "                        'collisions_per_cell' : nb_colls, # evolution of the number of collisions per cell - size : grid.shape[0] x grid.shape[1] (2D)\n",
    "                        'total_distance' : float(monitor[0]), # evolution of the sum of the distance accross all cells \n",
    "                        'total_proba' : float(monitor[1]), # evolution of the sum of proba accross all cells\n",
    "                        'pmax_per_cell' : pmax,  # evolution of the sum of pmax - per cell (2D)\n",
    "                        'total_deleted' : len(idxes_out), # evolution of the number of deleted particles per cell (int)\n",
    "                        'averages_per_cell' : averages, # evolution of the average number of particle per cell\n",
    "                        'collisions_with_walls' : collisions_with_walls, # number of collisions with walls - evolution\n",
    "                        'df_out_particles' : df_out_particles\n",
    "                  })\n",
    "\n",
    "        print('|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|'.format(it, n1, n2-n1, idxes_out.shape[0], c, collisions_with_walls, int(np.sum(nb_colls))))\n",
    "        \n",
    "        # resetting dataframe to not use too much memory\n",
    "        collisions_with_walls = 0\n",
    "        nb_colls = np.zeros(grid.current.shape)\n",
    "        df = pd.DataFrame(columns = ['x','y','vx','vy','vz','species'])\n",
    "        df_out_particles = pd.DataFrame(columns = ['x','y','vx','vy','vz','species'])\n",
    "        \n",
    "saver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2e720-2848-445b-82b4-48a952fe6e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
