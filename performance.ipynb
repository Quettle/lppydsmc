{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unknown-squad",
   "metadata": {},
   "source": [
    "Performance tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-vocabulary",
   "metadata": {},
   "source": [
    "Performance analysis - date structure to store particles in cells\n",
    "Needs :\n",
    "- delete (for advection phase)\n",
    "- add\n",
    "- get (for collisisons)\n",
    "\n",
    "Ideally, we want only $O(1)$\n",
    "\n",
    "Conclusion : \n",
    "While python seems faster than numpy array with the small examples I made, it is because each time we do a *get* or a *add* or a remove, we do not use the fact that the memory is contiguous for numpy array. We do one at a time. Thus, python list is faster by a factor 2 relativley to numpy array.\n",
    "\n",
    "However as soon as we want to remove several contiguous particles at a time, or get add several contiguous particles, then the numpy array \"retake the lead\".\n",
    "\n",
    "For our use case, there is no preference for one or the other. We use both cases even though only on one element most of the time.\n",
    "\n",
    "However, the advantage of using array numpy comes from the possiblity to easily parallize and cythonize it in the future. If we do that, we should not get too big an overhead while converting and we would go much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import LinkedList\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Array(object):\n",
    "    def __init__(self, shape, dtype = int):\n",
    "        self.arr = np.empty(shape, dtype = dtype)\n",
    "        self.init_shape = shape\n",
    "        self.max_size = shape[0]\n",
    "        self.elements_nb = 0\n",
    "        \n",
    "    def add(self, o):\n",
    "        if(self.elements_nb >= self.max_size):\n",
    "            print(f'Max size reach. Changing size from {self.max_size} to {self.max_size+self.init_shape[0]}')\n",
    "            self.arr = np.concatenate([self.arr, self.empty(shape, dtype = dtype)])\n",
    "        self.arr[self.elements_nb] = o\n",
    "        self.elements_nb += 1   \n",
    "\n",
    "    def add_multiple(self, new_arr):\n",
    "        if(self.elements_nb+new_arr.shape[0] > self.max_size):\n",
    "            print(f'Max size reach. Changing size from {self.max_size} to {self.max_size+self.init_shape[0]}')\n",
    "            self.arr = np.concatenate([self.arr, self.empty(shape, dtype = dtype)])\n",
    "        self.arr[self.elements_nb:self.elements_nb+new_arr.shape[0]] = new_arr\n",
    "        self.elements_nb += new_arr.shape[0]   \n",
    "\n",
    "    def remove(self, idx):\n",
    "        self.elements_nb -= 1\n",
    "        self.arr[idx] = self.arr[self.elements_nb]\n",
    "    we dont do remove multiple as we will never use it in practice\n",
    "    def get(self, idx):\n",
    "        return self.arr[idx]\n",
    "\n",
    "class PythonList(object):\n",
    "    def __init__(self):\n",
    "        self.arr = []\n",
    "        self.elements_nb = 0\n",
    "        \n",
    "    def add(self, o):\n",
    "        self.arr.append(o)\n",
    "        self.elements_nb += 1   \n",
    "    \n",
    "    def remove(self, idx):\n",
    "        self.elements_nb -= 1\n",
    "        self.arr.pop(idx)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        return self.arr[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = Array((1000,2)) max size is 1000\n",
    "linkedlist = LinkedList()\n",
    "mylist = PythonList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_add(particle, structure):\n",
    "    structure.add(particle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "part = np.array([1,1], dtype = int)\n",
    "%timeit lambda : arr.add(part)\n",
    "%timeit lambda : linkedlist.insert(part)\n",
    "%timeit lambda : mylist.add(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = np.random.randint(low=0, high = 100, size = (500,2), dtype = int)\n",
    "for part in particles:\n",
    "    arr.add(part)\n",
    "    linkedlist.insert(part)\n",
    "    mylist.add(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit lambda : arr.get(100)\n",
    "%timeit lambda : linkedlist.get(100)\n",
    "%timeit lambda : mylist.get(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit lambda : arr.remove(100)\n",
    "%timeit lambda : linkedlist.remove(array([ 4, 52]))\n",
    "%timeit lambda : mylist.remove(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    mylist.get(100)\n",
    "    t1 += time()-tmp\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    arr.get(100)\n",
    "    t1 += time()-tmp\n",
    "\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    linkedlist.get(100)\n",
    "    t1 += time()-tmp\n",
    "\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    mylist.add(np.array([10,10]))\n",
    "    tmp = time()\n",
    "    mylist.remove(100)\n",
    "    t1+=time()-tmp\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    arr.add(np.array([10,10]))\n",
    "    tmp = time()\n",
    "    arr.remove(100)\n",
    "    t1+=time()-tmp\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    linkedlist.insert(np.array([10,10]))\n",
    "    tmp = time()\n",
    "    linkedlist.remove(100)\n",
    "    t1+=time()-tmp\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_list = [part for part in particles]\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    particles_list[100:200]\n",
    "    t1 += time()-tmp\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    particles[100:200]\n",
    "    t1 += time()-tmp\n",
    "\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-feeding",
   "metadata": {},
   "source": [
    "##Add multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    for part in particles:\n",
    "        mylist.add(part)\n",
    "    t1 += time()-tmp\n",
    "    for k in range(len(particles)):\n",
    "        mylist.remove(0)\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    arr.add_multiple(particles)\n",
    "    t1 += time()-tmp\n",
    "    for k in range(len(particles)):\n",
    "        arr.remove(0)\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-purchase",
   "metadata": {},
   "source": [
    "#Testing expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numexpr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "walls = np.array([[-1,1,1,1], [1,1,1,1]])\n",
    "arr = np.array([[1,1,1,1,0], [2,1,-1,-1,0]])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = walls[:,:2]-walls[:,2:]\n",
    "supposing dp.x > 0\n",
    "ctheta, stheta = dp[:,0], dp[:,1]\n",
    "x, y, vx, vy, vz = np.split(arr, indices_or_sections=5, axis = 1)\n",
    "b = numexpr.evaluate(\"-vx*stheta+vy*ctheta\")  -velocity.x*stheta+velocity.y*ctheta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-object",
   "metadata": {},
   "source": [
    "#Collisions with wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized\n",
    "import numpy as np\n",
    "N = 1000\n",
    "walls = np.array([[0,0,1,0], [0,0,0,1], [1,0,1,1], [0,1,1,1]])\n",
    "a = np.array([[1,0, 1],[0,1, 1],[0,1, 1],[1,0, 1]])\n",
    "arr =  np.random.random((N,5)) np.array([[2,0.5,1,0,0], [0.5,2,0,1,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [0.5,0.5,-1,0,0]]*N)\n",
    "radius = 0.1\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "%timeit lambda : make_collisions(np.copy(arr), walls, a, ct, cp) not to sure about this one\n",
    "%timeit lambda : make_collisions_parallel(np.copy(arr), walls, a, ct, cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "from tqdm import tqdm\n",
    "\n",
    "def perf_N(tries=100):\n",
    "\n",
    "    N_list = [1,10, 100, 1000, 10000]\n",
    "\n",
    "    walls = np.array([[0,0,1,0], [0,0,0,1], [1,0,1,1], [0,1,1,1]])\n",
    "    a = np.array([[1,0, 1],[0,1, 1],[0,1, 1],[1,0, 1]])\n",
    "\n",
    "    radius = 0.1\n",
    "    L1, L2 = [], []\n",
    "    \n",
    "    for N in N_list :\n",
    "        t1 = 0\n",
    "        t2 = 0\n",
    "        for k in tqdm(range(tries)):\n",
    "            arr = np.random.random((N,5))\n",
    "            ct, cp = handler_wall_collision(arr, walls, a, radius)\n",
    "            arr1 = np.copy(arr)\n",
    "            arr2 = np.copy(arr)\n",
    "\n",
    "            tmp = time()\n",
    "            make_collisions(arr1, a, ct, cp)\n",
    "            t1+= time()-tmp\n",
    "\n",
    "            tmp = time()\n",
    "            make_collisions_vectorized(arr2, a, ct, cp)\n",
    "            t2+= time()-tmp\n",
    "        L1.append(t1)\n",
    "        L2.append(t2)\n",
    "    return N_list, np.array(L1)/tries, np.array(L2)/tries\n",
    "\n",
    "def perf_walls(tries=100):\n",
    "\n",
    "    def wall_builders(N):\n",
    "        split = N//4 \n",
    "        l = 1.0/split\n",
    "        walls = []\n",
    "        a = np.array(split*[[1,0, 1],[0,1, 1],[0,1, 1],[1,0, 1]])\n",
    "        for k in range(split):\n",
    "            w1 = [k*split, 0, (k+1)*split, 0]\n",
    "            w2 = [0, k*split, 0, (k+1)*split]\n",
    "            w3 = [1, k*split, 1, (k+1)*split]\n",
    "            w4 = [k*split, 1, (k+1)*split, 1]\n",
    "            walls.append(w1)\n",
    "            walls.append(w2)\n",
    "            walls.append(w3)\n",
    "            walls.append(w4)\n",
    "        return np.array(walls), a\n",
    "\n",
    "    N = 1000\n",
    "    walls_number = [4, 8, 16, 32, 64, 128]     we will keep a square\n",
    "\n",
    "    radius = 0.1\n",
    "    L1, L2 = [], []\n",
    "    for nb in walls_number :\n",
    "        t1 = 0\n",
    "        t2 = 0\n",
    "        for k in tqdm(range(tries)):\n",
    "            arr = np.random.random((N,5))\n",
    "            walls, a = wall_builders(nb)\n",
    "\n",
    "            ct, cp = handler_wall_collision(arr, walls, a, radius)\n",
    "\n",
    "            arr1 = np.copy(arr)\n",
    "            arr2 = np.copy(arr)\n",
    "\n",
    "            tmp = time()\n",
    "            make_collisions(arr1, a, ct, cp)\n",
    "            t1+= time()-tmp\n",
    "\n",
    "            tmp = time()\n",
    "            make_collisions_vectorized(arr2, a, ct, cp)\n",
    "            t2+= time()-tmp\n",
    "        L1.append(t1)\n",
    "        L2.append(t2)\n",
    "    return walls_number, np.array(L1)/tries, np.array(L2)/tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, L1, L2 = perf_N() \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(N, L1, 'r')\n",
    "plt.plot(N, L2, 'b')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N, L1, L2 = perf_walls() perf_walls()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(N, L1, 'r')\n",
    "plt.plot(N, L2, 'b')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de276143-b7c2-41d2-97c1-c89c48e61cf6",
   "metadata": {},
   "source": [
    "# Hard reset vs Update of the grid \n",
    "\n",
    "The goal is to measure how long it takes to update the grid vs hard resetting it for various number of particles and particles to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cc0248-fa84-416d-8883-04fc53ddc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce07a0b-2249-4c0a-b0a7-644a2fdd814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import time\n",
    "\n",
    "def _template_func(setup, func):\n",
    "    \"\"\"Create a timer function. Used if the \"statement\" is a callable.\"\"\"\n",
    "    def inner(_it, _timer, _func=func):\n",
    "        setup()\n",
    "        _t0 = _timer()\n",
    "        for _i in _it:\n",
    "            retval = _func()\n",
    "        _t1 = _timer()\n",
    "        return _t1 - _t0, retval\n",
    "    return inner\n",
    "\n",
    "timeit._template_func = _template_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9222224a-a42d-4e76-9e99-f5edffc5726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as ld\n",
    "def performance_comparison(N = 1000, rate_out = 0.05):\n",
    "    resolutions = np.array([10,10], dtype = int)\n",
    "    offsets = np.array([0,0])\n",
    "    system_shape = np.array([100, 100])\n",
    "    \n",
    "    container = ld.data_structures.Container(size_array = N, number_of_elements = 5, dtype=float)\n",
    "    grid = ld.data_structures.Grid(100, max_number_per_cell = int(10*N//100))\n",
    "    positions_in_grids_save = ld.data_structures.Container(size_array = N, number_of_elements = 0, dtype=int)\n",
    "    \n",
    "     \n",
    "    arr = np.random.randint(low = 0, high = 100, size = (N,5)) # with int\n",
    "    idxes_out = np.random.randint(low = 0, high = N, size = (int(rate_out*N))) # selecting certain \n",
    "    new_positions = ld.data_structures.grid.default_hashing(ld.data_structures.grid.pos_in_grid(arr[:,:2], resolutions, offsets, system_shape), res_y = resolutions[1])\n",
    "    \n",
    "    container.add_multiple(arr)\n",
    "        \n",
    "    n2 = container.get_current()\n",
    "    \n",
    "    ############################\n",
    "        # adding new particles to grid\n",
    "    positions = ld.data_structures.grid.default_hashing(ld.data_structures.grid.pos_in_grid(arr[:,:2], resolutions, offsets, system_shape), res_y = resolutions[1])\n",
    "    parts_in_grid_format = ld.data_structures.grid.convert_to_grid_format(new = n2)\n",
    "    grid.add_multiple(positions, parts_in_grid_format)\n",
    "    \n",
    "        # and to the positions in grid saver\n",
    "    positions_in_grids_save.add_multiple(positions)    \n",
    "    ############################\n",
    "    \n",
    "        \n",
    "    def hard_reset():\n",
    "        container.delete_multiple(idxes_out)\n",
    "        grid.reset()\n",
    "        parts_in_grid_format = ld.data_structures.grid.convert_to_grid_format(new = new_positions.shape[0])\n",
    "        grid.add_multiple(positions, parts_in_grid_format)\n",
    "    \n",
    "    def update_grid():\n",
    "        idxes_out_ = np.sort(idxes_out) # required here\n",
    "        count = idxes_out_.shape[0]-1\n",
    "        \n",
    "        for idx in range(container.get_current()-1, -1, -1):\n",
    "            old_pos = positions_in_grids_save.get(idx)\n",
    "            new_pos = new_positions[idx]\n",
    "            \n",
    "            if(idxes_out.size > 0 and idx == idxes_out_[count]):\n",
    "                # particle is outside\n",
    "                # we have to delete it\n",
    "                current = container.get_current() # current changes with each delete !\n",
    "                count -= 1\n",
    "\n",
    "                # swapping it with the last one in the container\n",
    "                container.delete(idx)\n",
    "                positions_in_grids_save.delete(idx)\n",
    "                # deleting the object in the grid\n",
    "                grid.remove(old_pos, np.array([0,idx], dtype = int)) # since [idx container, idx] is a unique key, we check for equality in values of the array (not in references)\n",
    "\n",
    "                # updating the swapped particle in the grid\n",
    "                swapping_particle_pos = positions_in_grids_save.get(idx) # this supposes that positions_in_grids_save is up-to-date for the particle previously at index 'current-1' (and now at index 'idx'). \n",
    "                # this is why we are iterating from the end\n",
    "                grid.update_index(swapping_particle_pos, idx_container = 0, old_index = current-1, new_index = idx)\n",
    "            elif(np.array_equal(old_pos, new_pos)):\n",
    "                pass\n",
    "            else:\n",
    "                # then the particle does not need to be deleted, just updated\n",
    "                grid.update(o = np.array([0,idx]), old_pos = old_pos, new_pos = new_pos) # in theory it should not changed the value of the object (indeed, its position in the grid should not have changed !)\n",
    "                # and update the new positions in grid in the saver\n",
    "                positions_in_grids_save.update(idx, new_pos)\n",
    "        \n",
    "        \n",
    "\n",
    "    t1 = timeit.Timer(hard_reset)\n",
    "    time1 = t1.timeit(number=1) # this is the time it took\n",
    "\n",
    "    t2 = timeit.Timer(update_grid)\n",
    "    time2 = t2.timeit(number=1) # this is the time it took\n",
    "\n",
    "    return time1, time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8791ea3e-9d8b-4c08-ae4b-f9247f1475bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, t2 = performance_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2914e31-07c7-4552-8859-902773c21643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [02:44<00:51, 51.11s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "T1, T2 = [], []\n",
    "list_N = [1e3,1e4,1e5,1e6,1e7,1e8]\n",
    "for N in tqdm(list_N):\n",
    "    N = int(N)\n",
    "    t1, t2 = performance_comparison(N, rate_out = 0.01) # in fact its more 1% for the tube\n",
    "    T1.append(t1)\n",
    "    T2.append(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c34ec-22dc-47ae-9fd0-fb83a6bd206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list_N, T1, 'r')\n",
    "plt.plot(list_N, T2, 'b')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c93ae-9e90-411d-a661-5d8b1acd6c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
