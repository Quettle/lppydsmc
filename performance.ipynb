{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unknown-squad",
   "metadata": {},
   "source": [
    "# Performance tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-vocabulary",
   "metadata": {},
   "source": [
    "# Performance analysis - date structure to store particles in cells\n",
    "Needs :\n",
    "- delete (for advection phase)\n",
    "- add\n",
    "- get (for collisisons)\n",
    "\n",
    "Ideally, we want only $O(1)$\n",
    "\n",
    "Conclusion : \n",
    "While python seems faster than numpy array with the small examples I made, it is because each time we do a *get* or a *add* or a remove, we do not use the fact that the memory is contiguous for numpy array. We do one at a time. Thus, python list is faster by a factor 2 relativley to numpy array.\n",
    "\n",
    "However as soon as we want to remove several contiguous particles at a time, or get add several contiguous particles, then the numpy array \"retake the lead\".\n",
    "\n",
    "For our use case, there is no preference for one or the other. We use both cases even though only on one element most of the time.\n",
    "\n",
    "However, the advantage of using array numpy comes from the possiblity to easily parallize and cythonize it in the future. If we do that, we should not get too big an overhead while converting and we would go much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import LinkedList\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Array(object):\n",
    "    def __init__(self, shape, dtype = int):\n",
    "        self.arr = np.empty(shape, dtype = dtype)\n",
    "        self.init_shape = shape\n",
    "        self.max_size = shape[0]\n",
    "        self.elements_nb = 0\n",
    "        \n",
    "    def add(self, o):\n",
    "        if(self.elements_nb >= self.max_size):\n",
    "            print(f'Max size reach. Changing size from {self.max_size} to {self.max_size+self.init_shape[0]}')\n",
    "            self.arr = np.concatenate([self.arr, self.empty(shape, dtype = dtype)])\n",
    "        self.arr[self.elements_nb] = o\n",
    "        self.elements_nb += 1   \n",
    "\n",
    "    def add_multiple(self, new_arr):\n",
    "        if(self.elements_nb+new_arr.shape[0] > self.max_size):\n",
    "            print(f'Max size reach. Changing size from {self.max_size} to {self.max_size+self.init_shape[0]}')\n",
    "            self.arr = np.concatenate([self.arr, self.empty(shape, dtype = dtype)])\n",
    "        self.arr[self.elements_nb:self.elements_nb+new_arr.shape[0]] = new_arr\n",
    "        self.elements_nb += new_arr.shape[0]   \n",
    "\n",
    "    def remove(self, idx):\n",
    "        self.elements_nb -= 1\n",
    "        self.arr[idx] = self.arr[self.elements_nb]\n",
    "    # we dont do remove multiple as we will never use it in practice\n",
    "    def get(self, idx):\n",
    "        return self.arr[idx]\n",
    "\n",
    "class PythonList(object):\n",
    "    def __init__(self):\n",
    "        self.arr = []\n",
    "        self.elements_nb = 0\n",
    "        \n",
    "    def add(self, o):\n",
    "        self.arr.append(o)\n",
    "        self.elements_nb += 1   \n",
    "    \n",
    "    def remove(self, idx):\n",
    "        self.elements_nb -= 1\n",
    "        self.arr.pop(idx)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        return self.arr[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = Array((1000,2)) # max size is 1000\n",
    "linkedlist = LinkedList()\n",
    "mylist = PythonList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_add(particle, structure):\n",
    "    structure.add(particle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "part = np.array([1,1], dtype = int)\n",
    "%timeit lambda : arr.add(part)\n",
    "%timeit lambda : linkedlist.insert(part)\n",
    "%timeit lambda : mylist.add(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = np.random.randint(low=0, high = 100, size = (500,2), dtype = int)\n",
    "for part in particles:\n",
    "    arr.add(part)\n",
    "    linkedlist.insert(part)\n",
    "    mylist.add(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit lambda : arr.get(100)\n",
    "%timeit lambda : linkedlist.get(100)\n",
    "%timeit lambda : mylist.get(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit lambda : arr.remove(100)\n",
    "%timeit lambda : linkedlist.remove(array([ 4, 52]))\n",
    "%timeit lambda : mylist.remove(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    mylist.get(100)\n",
    "    t1 += time()-tmp\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    arr.get(100)\n",
    "    t1 += time()-tmp\n",
    "\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    linkedlist.get(100)\n",
    "    t1 += time()-tmp\n",
    "\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    mylist.add(np.array([10,10]))\n",
    "    tmp = time()\n",
    "    mylist.remove(100)\n",
    "    t1+=time()-tmp\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    arr.add(np.array([10,10]))\n",
    "    tmp = time()\n",
    "    arr.remove(100)\n",
    "    t1+=time()-tmp\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    linkedlist.insert(np.array([10,10]))\n",
    "    tmp = time()\n",
    "    linkedlist.remove(100)\n",
    "    t1+=time()-tmp\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_list = [part for part in particles]\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    particles_list[100:200]\n",
    "    t1 += time()-tmp\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    particles[100:200]\n",
    "    t1 += time()-tmp\n",
    "\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-feeding",
   "metadata": {},
   "source": [
    "### Add multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "t1 = t0\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    for part in particles:\n",
    "        mylist.add(part)\n",
    "    t1 += time()-tmp\n",
    "    for k in range(len(particles)):\n",
    "        mylist.remove(0)\n",
    "print(t1-t0)\n",
    "\n",
    "t0 = time()\n",
    "t1 = t0\n",
    "\n",
    "for k in range(100000):\n",
    "    tmp = time()\n",
    "    arr.add_multiple(particles)\n",
    "    t1 += time()-tmp\n",
    "    for k in range(len(particles)):\n",
    "        arr.remove(0)\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-purchase",
   "metadata": {},
   "source": [
    "## Testing expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numexpr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "walls = np.array([[-1,1,1,1], [1,1,1,1]])\n",
    "arr = np.array([[1,1,1,1,0], [2,1,-1,-1,0]])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = walls[:,:2]-walls[:,2:]\n",
    "# supposing dp.x > 0\n",
    "ctheta, stheta = dp[:,0], dp[:,1]\n",
    "x, y, vx, vy, vz = np.split(arr, indices_or_sections=5, axis = 1)\n",
    "b = numexpr.evaluate(\"-vx*stheta+vy*ctheta\")  # -velocity.x*stheta+velocity.y*ctheta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-object",
   "metadata": {},
   "source": [
    "## Collisions with wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized\n",
    "import numpy as np\n",
    "N = 1000\n",
    "walls = np.array([[0,0,1,0], [0,0,0,1], [1,0,1,1], [0,1,1,1]])\n",
    "a = np.array([[1,0, 1],[0,1, 1],[0,1, 1],[1,0, 1]])\n",
    "arr =  np.random.random((N,5)) # np.array([[2,0.5,1,0,0], [0.5,2,0,1,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [0.5,0.5,-1,0,0]]*N)\n",
    "radius = 0.1\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "%timeit lambda : make_collisions(np.copy(arr), walls, a, ct, cp) # not to sure about this one\n",
    "%timeit lambda : make_collisions_parallel(np.copy(arr), walls, a, ct, cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "from tqdm import tqdm\n",
    "\n",
    "def perf_N(tries=100):\n",
    "\n",
    "    N_list = [1,10, 100, 1000, 10000]\n",
    "\n",
    "    walls = np.array([[0,0,1,0], [0,0,0,1], [1,0,1,1], [0,1,1,1]])\n",
    "    a = np.array([[1,0, 1],[0,1, 1],[0,1, 1],[1,0, 1]])\n",
    "\n",
    "    radius = 0.1\n",
    "    L1, L2 = [], []\n",
    "    \n",
    "    for N in N_list :\n",
    "        t1 = 0\n",
    "        t2 = 0\n",
    "        for k in tqdm(range(tries)):\n",
    "            arr = np.random.random((N,5))\n",
    "            ct, cp = handler_wall_collision(arr, walls, a, radius)\n",
    "            arr1 = np.copy(arr)\n",
    "            arr2 = np.copy(arr)\n",
    "\n",
    "            tmp = time()\n",
    "            make_collisions(arr1, a, ct, cp)\n",
    "            t1+= time()-tmp\n",
    "\n",
    "            tmp = time()\n",
    "            make_collisions_vectorized(arr2, a, ct, cp)\n",
    "            t2+= time()-tmp\n",
    "        L1.append(t1)\n",
    "        L2.append(t2)\n",
    "    return N_list, np.array(L1)/tries, np.array(L2)/tries\n",
    "\n",
    "def perf_walls(tries=100):\n",
    "\n",
    "    def wall_builders(N):\n",
    "        split = N//4 \n",
    "        l = 1.0/split\n",
    "        walls = []\n",
    "        a = np.array(split*[[1,0, 1],[0,1, 1],[0,1, 1],[1,0, 1]])\n",
    "        for k in range(split):\n",
    "            w1 = [k*split, 0, (k+1)*split, 0]\n",
    "            w2 = [0, k*split, 0, (k+1)*split]\n",
    "            w3 = [1, k*split, 1, (k+1)*split]\n",
    "            w4 = [k*split, 1, (k+1)*split, 1]\n",
    "            walls.append(w1)\n",
    "            walls.append(w2)\n",
    "            walls.append(w3)\n",
    "            walls.append(w4)\n",
    "        return np.array(walls), a\n",
    "\n",
    "    N = 1000\n",
    "    walls_number = [4, 8, 16, 32, 64, 128]     # we will keep a square\n",
    "\n",
    "    radius = 0.1\n",
    "    L1, L2 = [], []\n",
    "    for nb in walls_number :\n",
    "        t1 = 0\n",
    "        t2 = 0\n",
    "        for k in tqdm(range(tries)):\n",
    "            arr = np.random.random((N,5))\n",
    "            walls, a = wall_builders(nb)\n",
    "\n",
    "            ct, cp = handler_wall_collision(arr, walls, a, radius)\n",
    "\n",
    "            arr1 = np.copy(arr)\n",
    "            arr2 = np.copy(arr)\n",
    "\n",
    "            tmp = time()\n",
    "            make_collisions(arr1, a, ct, cp)\n",
    "            t1+= time()-tmp\n",
    "\n",
    "            tmp = time()\n",
    "            make_collisions_vectorized(arr2, a, ct, cp)\n",
    "            t2+= time()-tmp\n",
    "        L1.append(t1)\n",
    "        L2.append(t2)\n",
    "    return walls_number, np.array(L1)/tries, np.array(L2)/tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, L1, L2 = perf_N() \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(N, L1, 'r')\n",
    "plt.plot(N, L2, 'b')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N, L1, L2 = perf_walls() # perf_walls()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(N, L1, 'r')\n",
    "plt.plot(N, L2, 'b')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
