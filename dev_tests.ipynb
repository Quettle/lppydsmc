{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5d244-2fbf-49c0-8ab0-15689d05a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import is_notebook\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-christian",
   "metadata": {},
   "source": [
    "# Module Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa58db60-ce2b-4218-8236-04fecfd75e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src.plotting import plot_boundaries, plot_particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-accident",
   "metadata": {},
   "source": [
    "## System creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "from src.system_creator import SystemCreator\n",
    "\n",
    "# Tube creation :\n",
    "tube_segments = 0.001*np.array([[0,0,10,0], [0,0,0,1], [10,0,10,1], [0,1,10,1]])\n",
    "tube = SystemCreator(tube_segments)\n",
    "\n",
    "offsets = tube.get_offsets()\n",
    "system_shape = tube.system_shape()\n",
    "a = tube.get_dir_vects()\n",
    "\n",
    "print(f'Tube : \\noffsets : {offsets}')\n",
    "print(f'System size : {system_shape} \\n')\n",
    "\n",
    "# Cylinder\n",
    "circle = [[5+np.cos(k*np.pi/8), 5+np.sin(k*np.pi/8), 5+np.cos((k+1)*np.pi/8), 5+np.sin((k+1)*np.pi/8)] for k in range(16)]\n",
    "cylinder_segments = 0.001*np.array([[0,0,10,0], [0,0,0,10], [10,0,10,10], [0,10,10,10]]+circle)\n",
    "cylinder = SystemCreator(cylinder_segments)\n",
    "\n",
    "print(f'Cylinder : \\noffsets : {cylinder.get_offsets()}')\n",
    "print(f'System size : {cylinder.system_shape()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots();\n",
    "plot_boundaries(ax, tube_segments);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, cylinder_segments)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-impact",
   "metadata": {},
   "source": [
    "## Particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Particle, get_mass_part\n",
    "\n",
    "# Iodine\n",
    "container = Particle('I', 0, get_mass_part(53, 53, 74), radius = 2e-10, size_array = 10000)\n",
    "N = 500\n",
    "arr =  np.random.random((N,5))\n",
    "print(f'mass, charge, radius, cross-section = {container.get_params()}'); # mass, charge, radius, cross-section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "container.add_multiple(arr)\n",
    "print(container.get_current())\n",
    "print(container.get_particles().shape)\n",
    "print(container.arr.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of particles : {container.get_current()}')\n",
    "for k in range(3):\n",
    "    container.add_multiple(np.random.random((1000,5)))\n",
    "    print(f'Number of particles : {container.get_current()}')\n",
    "    container.delete_multiple(np.random.choice(a = container.get_current(), size = 500, replace = False))\n",
    "    print(f'Number of particles : {container.get_current()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : make 'dynamic' arrays (when increasing the size).\n",
    "container.add_multiple(np.random.random((3000,5)))\n",
    "print(f'Number of particles : {container.get_current()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-library",
   "metadata": {},
   "source": [
    "**Conclusion**  : make 'dynamic' array (can increase time, but not decrease it for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-hollow",
   "metadata": {},
   "source": [
    "## Grid\n",
    "For now : 2D-ndarray with value of type *ndarray* which are 2D.\n",
    "```python\n",
    "# grid[x_int, y_int] is the container for a cell\n",
    "# grid[x_int, y_int][idx] contains the particle indexes\n",
    "grid[x_int, y_int][idx] = [idx_container, idx_particle_in_container]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Grid, pos_in_grid\n",
    "resolutions = np.array([4,4])\n",
    "max_number_per_cell = 10 # to initialize the array which will contain the particles indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid(resolutions, max_number_per_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, vx, vy, vz\n",
    "arr = np.array([[-1.5,1.2,1,0,0], [-1.3,-0.8,0,-1,0], [1.3,-0.5,-1,0,0], [1,1,-1,-1,-1], [-1,1,1,0,0]])\n",
    "print(arr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signature : pos_in_grid(pos, grid_res, offsets, system_shape)\n",
    "pos = pos_in_grid(arr[:,:2], resolutions, offsets = np.array([-2, -2]), system_shape = np.array([4,4])) # not inplace\n",
    "print(pos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [pos_x, pos_y, idx_container, idx_particle_in_container]\n",
    "idx_container = np.array([0,0,0,0,0])\n",
    "idx_particle_in_container = np.array([0,1,2,3,4])\n",
    "idxes = np.stack((idx_container, idx_particle_in_container), axis = 1)\n",
    "new_arr = np.concatenate((pos, idxes), axis = 1)\n",
    "print(new_arr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.reset()\n",
    "grid.add_multiple(new_arr)\n",
    "print(grid.current);\n",
    "print(grid.get([0,1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : delete multiple\n",
    "grid.delete([0,1], 0) # can still take lots of time\n",
    "print(grid.current);\n",
    "print(grid.get([0,1]));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-laptop",
   "metadata": {},
   "source": [
    "**Conclusion** :\n",
    "- Add a 'delete_multiple' built on *NumPy* - **DONE**\n",
    "- Maybe change the grid to a 4D-array :\n",
    "    - Pro : faster everything.\n",
    "    - Cons : waste of memory for system with density gradients, increasing size of the array costs much more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-seller",
   "metadata": {},
   "source": [
    "## Injector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    " # notebook\n",
    "from src.plotting import plot_particles, plot_boundaries\n",
    "import src.plotting.analysis as analysis\n",
    "from src.utils import inject \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signature : inject(in_wall, in_vect, debit, vel_std, radius, dt)\n",
    "in_wall =  np.array([0,0,0,1]) # np.array([0,0,0,1]) # np.array([0,0,1,0]) # np.array([0,0,0,1]) # np.array([0,0,1,1])\n",
    "a = np.array([0,1,1])\n",
    "in_vect = np.array([1,0]) # (1/np.sqrt(2))*np.array([-1,1]) # -np.array([1,0]) #  -np.array([0,1]) # np.array([1,0])# (1/np.sqrt(2))*np.array([1,1])\n",
    "debit = 100000000 # particles / s\n",
    "dt = 0.001\n",
    "vel_std = 200. # m/s\n",
    "radius = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr, remains = inject(in_wall, in_vect, debit, vel_std, radius, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, np.expand_dims(in_wall, axis = 0))\n",
    "plot_particles(ax, arr, r = 10*radius, arrows = False)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(arr, columns = ['x', 'y', 'vx', 'vy', 'vz'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.velocity_distribution(df, bins = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-backup",
   "metadata": {},
   "source": [
    "## Advection (and schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import advect\n",
    "from src.utils import euler_explicit, leap_frog\n",
    "from src.plotting import plot_particles, plot_boundaries\n",
    "\n",
    "# notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signature : advect(arr, f, dt, args, scheme)\n",
    "arr = np.array([[1,1,1,1,0], [2,1,-1,-1,0]], dtype = float)\n",
    "#arr = np.random.random((10,5))\n",
    "def f(arr, dt):\n",
    "    return np.zeros(shape = (arr.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_ = np.copy(arr)\n",
    "advect(arr_, f, dt = 0.1, args = [], scheme = euler_explicit) # seems ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr__ =  np.copy(arr)\n",
    "advect(arr__, f, dt = 0.1, args = [], scheme = leap_frog) # seems ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_particles(ax, arr, r = 10) \n",
    "plot_particles(ax, arr_, r = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-dinner",
   "metadata": {},
   "source": [
    "## Collision with walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plotting import plot_boundaries, plot_particles\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized, make_collisions_out_walls\n",
    "import numpy as np\n",
    "N = 10\n",
    "walls = 1.5*np.array([[0,0,1,0], [0,0,0,1], [1,0,1,1], [0,1,1,1]]) # bottom, left, right, top\n",
    "a = np.array([[1,0, 1.5],[0,1, 1.5],[0,1, 1.5],[1,0, 1.5]])\n",
    "# arr = np.array([[2,0.5,1,0,0], [0.5,2,0,1,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [-0.5,0.5,-1,0,0]])  # np.random.random((N,5)) # \n",
    "arr = np.array([[1.5,2,1,1,0]])\n",
    "arr[:,2:] = 5*arr[:,2:]\n",
    "radius = 0.1\n",
    "idx_out_walls = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, walls)\n",
    "plot_particles(ax, arr, r = 8, arrows = True)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct, cp = handler_wall_collision(arr, walls, a, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr_1 = np.copy(arr)\n",
    "new_arr_2 = np.copy(arr)\n",
    "new_arr_3 = np.copy(arr)\n",
    "make_collisions(new_arr_1, a, ct, cp)\n",
    "make_collisions_vectorized(new_arr_2, a, ct, cp)\n",
    "indexes = make_collisions_out_walls(new_arr_3, a, ct, cp, idx_out_walls)\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "\n",
    "plot_boundaries(ax[0,0], walls)\n",
    "plot_particles(ax[0,0], arr, r = 8, arrows = True)\n",
    "\n",
    "plot_boundaries(ax[0,1], walls)\n",
    "plot_particles(ax[0,1], new_arr_1, r = 8, arrows = True)\n",
    "\n",
    "plot_boundaries(ax[1,0], walls)\n",
    "plot_particles(ax[1,0], new_arr_2, r = 8, arrows = True)\n",
    "\n",
    "plot_boundaries(ax[1,1], walls)\n",
    "plot_particles(ax[1,1], new_arr_3, r = 8, arrows = True)\n",
    "\n",
    "ax[0,0].axis('equal')\n",
    "ax[0,1].axis('equal')\n",
    "ax[1,0].axis('equal')\n",
    "ax[1,1].axis('equal')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-michael",
   "metadata": {},
   "source": [
    "#### Collision with walls - and outwalls\n",
    "\n",
    "Problem : sometimes a particle can collide and be reflected but remain outside the system. In such a case, we have to make sure the particle is reflected again, and as many time as necessary. In addition, particles that went out (by the out walls) should be taken into account and :\n",
    " - not reflected back into the system but instead removed\n",
    " - a particle can, after its second reflection in a row, finds itself going trough the 'out wall'. In such a case it should be added to the list of particle to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized, make_collisions_out_walls\n",
    "import numpy as np\n",
    "from src.plotting import plot_boundaries, plot_particles\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 10\n",
    "segments = 1.5*np.array([[0,0,1,0], [0,0,0,1], [1,0,1,1], [0,1,1,1]]) # bottom, left, right, top\n",
    "a = np.array([[1,0, 1.5],[0,1, 1.5],[0,1, 1.5],[1,0, 1.5]])\n",
    "arr = np.array([[-4,5.5,-1,1,0], [1.6,2,1,1,0],[2,0.5,1,0,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [-0.5,0.5,-1,0,0]])  # np.random.random((N,5)) # \n",
    "radius = 0.01\n",
    "idx_out_walls = [2] # 2 : Right\n",
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, segments)\n",
    "plot_particles(ax, arr, r = 8, arrows = True)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.full(shape = (arr.shape[0]), fill_value = True)\n",
    "idxes_out = []\n",
    "c = 0\n",
    "while(np.sum(count, where = count == True) > 0):\n",
    "        print(c)\n",
    "        c+=1\n",
    "        ct, cp = handler_wall_collision(arr[count], segments, a, radius)\n",
    "        print(cp)\n",
    "        count, idxes_out_ = make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "        idxes_out.append(idxes_out_)\n",
    "        fig, ax = plt.subplots()\n",
    "        plot_boundaries(ax, segments)\n",
    "        plot_particles(ax, arr, r = 8, arrows = True)\n",
    "        plt.axis('equal');\n",
    "        \n",
    "        #print(count)\n",
    "        if(c>20):\n",
    "            break\n",
    "print(c)\n",
    "idxes_out = np.concatenate(idxes_out)\n",
    "\n",
    "arr[idxes_out.shape[0]:,:] = np.delete(arr, idxes_out, axis = 0) # operation is not inplace\n",
    "c-=idxes_out.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e07cabc",
   "metadata": {},
   "source": [
    "### Collision with walls - cylinder - why does it not work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4fbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized, make_collisions_out_walls, deal_with_corner\n",
    "import numpy as np\n",
    "from src.plotting import plot_boundaries, plot_particles\n",
    "import matplotlib.pyplot as plt\n",
    "from src.system_creator import SystemCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb265779",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 4\n",
    "circle = [[1.5+0.5*np.cos(k*np.pi/res), 1+0.5*np.sin(k*np.pi/res), 1.5+0.5*np.cos((k+1)*np.pi/res), 1+0.5*np.sin((k+1)*np.pi/res)] for k in range(2*res)]\n",
    "segments = 0.001*np.array([[0,0,3,0], [0,0,0,2], [3,0,3,2], [0,2,3,2]]+circle)\n",
    "system = SystemCreator(segments)\n",
    "\n",
    "offsets = system.get_offsets()\n",
    "system_shape = system.system_shape()\n",
    "a = system.get_dir_vects()\n",
    "segments = system.get_segments()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, segments, color = 'k')\n",
    "\n",
    "# liste_vectors_segment = np.concatenate((segments[:,:2], segments[:,:2]+0.001*a[:,:2]), axis = 1)\n",
    "# plot_boundaries(ax, liste_vectors_segment, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining particles\n",
    "# arr = 0.001*np.array([[-4,5.5,-1,1,0], [1.6,2,1,1,0],[2,0.5,1,0,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [-0.5,0.5,-1,0,0]])  # np.random.random((N,5)) # \n",
    "arr = np.array([[0.0015, 0.001, 100, 0,0]])\n",
    "radius = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.full(shape = (arr.shape[0]), fill_value = True)\n",
    "idxes_out = []\n",
    "c = 0\n",
    "idx_out_walls = []\n",
    "while(np.sum(count, where = count == True) > 0):\n",
    "        c+=1\n",
    "        ct, cp = handler_wall_collision(arr[count], segments, a, radius)\n",
    "        print(ct)\n",
    "        deal_with_corner(ct)\n",
    "        print(ct)\n",
    "        count, idxes_out_ = make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "        idxes_out.append(idxes_out_)\n",
    "        fig, ax = plt.subplots()\n",
    "        plot_boundaries(ax, segments)\n",
    "        plot_particles(ax, arr, r = 1, arrows = False)\n",
    "        plt.axis('equal');\n",
    "\n",
    "        if(c>20):\n",
    "            break\n",
    "\n",
    "np.concatenate(idxes_out)\n",
    "\n",
    "# arr[idxes.shape[0]:,:] = np.delete(arr, idxes, axis = 0) # operation is not inplace\n",
    "# current-=idxes.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-angle",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-mortality",
   "metadata": {},
   "source": [
    "## Particles collisions\n",
    "\n",
    "Signatures of the functions :\n",
    "* candidates(currents, dt, average, pmax, volume_cell, mr, remains)\n",
    "* index_choosen_couples(current, candidates)\n",
    "* probability(vr_norm, pmax, cross_sections)\n",
    "* is_colliding(proba)\n",
    "* reflect(arr, vr_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import candidates, index_choosen_couples, probability, is_colliding, reflect\n",
    "import numpy as np\n",
    "from src.plotting import plot_particles, plot_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "currents = 10*np.array([\n",
    "    [16,22,14],\n",
    "    [9,13,11],\n",
    "    [4,9,6]\n",
    "])\n",
    "dt = 1e-7\n",
    "averages = 10*np.array([\n",
    "    [15,20,15],\n",
    "    [10,15,10],\n",
    "    [5,10,5]\n",
    "])\n",
    "radius = 2e-10\n",
    "cross_section = 4 * np.pi * radius**2\n",
    "pmax = cross_section * 600\n",
    "pmax_vect = cross_section * 600 * np.ones(averages.shape)\n",
    "print(pmax_vect.shape)\n",
    "volume_cell = (0.001)**3\n",
    "mr = 1e15\n",
    "remains = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "remains, cands = candidates(currents, dt, averages, pmax, volume_cell, mr, remains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f371a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remains, cands = candidates(currents, dt, averages, pmax_vect, volume_cell, mr, remains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [np.random.uniform(low = -1, high = 1, size = (current, 5)) for current in currents.flatten()]\n",
    "arr = np.concatenate(arrays, axis = 0)\n",
    "arr_save = np.copy(arr)\n",
    "print(arr.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_shape = currents.shape\n",
    "system_shape = (2.,2.)\n",
    "offsets = np.array([-1, -1])\n",
    "fig, ax = plt.subplots()\n",
    "plot_grid(ax, grid_shape, system_shape, offsets)\n",
    "plot_particles(ax, arr, r = 0.1)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-syndrome",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for count, (i, j) in enumerate(np.ndindex(currents.shape)):\n",
    "    choice = index_choosen_couples(currents[i,j], int(cands[i,j]))\n",
    "    vr_norm = np.linalg.norm((arrays[count][choice][:,1,2:]-arrays[count][choice][:,0,2:]), axis = 1)\n",
    "    proba = probability(vr_norm = vr_norm, pmax = pmax, cross_sections = cross_section)\n",
    "    collidings_couples = is_colliding(proba)\n",
    "    print(np.sum(collidings_couples))\n",
    "    # if(not all(~collidings_couples)):\n",
    "    #    ic(all(~collidings_couples))\n",
    "    #    ic(arr)\n",
    "    # can not be inplace\n",
    "    arrays[count][choice[collidings_couples]] = reflect(arrays[count][choice[collidings_couples]], vr_norm[collidings_couples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.concatenate(arrays, axis = 0)\n",
    "df1 = pd.DataFrame(arr_save, columns = ['x','y','vx','vy','vz'])\n",
    "df2 = pd.DataFrame(arr, columns = ['x','y','vx','vy','vz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "df1['vx'].plot.hist(bins=50, ax = ax[0,0])\n",
    "df1['vy'].plot.hist(bins=50, ax = ax[0,1])\n",
    "df2['vx'].plot.hist(bins=50, ax = ax[1,0])\n",
    "df2['vy'].plot.hist(bins=50, ax = ax[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "g = sns.JointGrid(data=df1, x=\"vx\", y=\"vy\", space=0)\n",
    "g.plot_joint(sns.kdeplot,\n",
    "             fill=True,\n",
    "             thresh=0, levels=100, cmap=\"rocket\")\n",
    "g.plot_marginals(sns.histplot, color=\"#03051A\", alpha=1, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "g = sns.JointGrid(data=df2, x=\"vx\", y=\"vy\", space=0)\n",
    "g.plot_joint(sns.kdeplot,\n",
    "             fill=True,\n",
    "             thresh=0, levels=100, cmap=\"rocket\")\n",
    "g.plot_marginals(sns.histplot, color=\"#03051A\", alpha=1, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "x = df1['x']\n",
    "y = df2['y']\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y, c=z, s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-bangladesh",
   "metadata": {},
   "source": [
    "### From grid, get particles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.utils import candidates, index_choosen_couples, probability, is_colliding, reflect\n",
    "\n",
    "currents = 10*np.array([\n",
    "    [24,26],\n",
    "    [25,25]\n",
    "], dtype = int)\n",
    "\n",
    "arr = [np.random.uniform(low = -1.0, high = 1.0, size = (1000,5))]\n",
    "arr_copy = np.copy(arr[0])\n",
    "# zer = np.zeros(250)\n",
    "t = np.arange(1000)\n",
    "np.random.shuffle(t)\n",
    "arr1, arr2, arr3, arr4 = np.split(t, indices_or_sections = [240,500,750], axis = 0)\n",
    "p1, p2 = np.stack((np.zeros(240), arr1), axis = 1), np.stack((np.zeros(260), arr2), axis = 1)\n",
    "p3, p4 = np.stack((np.zeros(250), arr3), axis = 1), np.stack((np.zeros(250), arr4), axis = 1)\n",
    "\n",
    "grid = np.array([\n",
    "    [p1, p2],\n",
    "    [p3, p4]],\n",
    "    dtype = np.ndarray)\n",
    "\n",
    "print(f'Currents : \\n {currents}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to get all that is in arr from grid...\n",
    "# and do this in place ... which will be VERY fucking hard\n",
    "# VERY SLOW\n",
    "cands = np.array([[120,123],[124,124]])\n",
    "cross_section = 1\n",
    "pmax = 2\n",
    "for k, (i, j) in enumerate(np.ndindex(currents.shape)):\n",
    "    choice = index_choosen_couples(currents[i,j], int(cands[i,j])) # choice contains the possible couples\n",
    "    # now, we have to get their pos and speed\n",
    "    g = grid[i,j]\n",
    "    parts = np.array([[g[c[0]], g[c[1]]] for c in choice], dtype = int)\n",
    "    array = np.array([[ arr[c[0,0]][c[0,1]] , arr[c[1,0]][c[1,1]] ] for c in parts])\n",
    "    # blablabla [...] -> DSMC etc.\n",
    "    # TODO: make those stuff and see if it still works\n",
    "\n",
    "    vr_norm = np.linalg.norm((array[:,1,2:]-array[:,0,2:]), axis = 1)\n",
    "    proba = probability(vr_norm = vr_norm, pmax = pmax, cross_sections = cross_section)\n",
    "\n",
    "    # TODO : should update pmax here (or return something)...\n",
    "    collidings_couples = is_colliding(proba)\n",
    "    array[collidings_couples] = reflect(array[collidings_couples], vr_norm[collidings_couples])\n",
    "    \n",
    "    for k in range(len(array)):\n",
    "        c1, c2 = array[k,0], array[k,1]\n",
    "        c = parts[k]\n",
    "        arr[c[0,0]][c[0,1]][:] = c1 # copy\n",
    "        arr[c[1,0]][c[1,1]][:] = c2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(arr_copy, arr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-server",
   "metadata": {},
   "source": [
    "### Reflection study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import reflect\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "arr = np.array([[[1,1,1,1,1], [1,1,-1,-1,1]]])\n",
    "vr_norm = np.linalg.norm((arr[:,1,2:]-arr[:,0,2:]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_ = reflect(np.copy(arr),vr_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr);\n",
    "print(arr_);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-painting",
   "metadata": {},
   "source": [
    "## Update position in grids - tests\n",
    "\n",
    "##### Idea : \n",
    "1. Create particles and initialize them in the grids\n",
    "2. Do something \n",
    "3. Update position in the grid\n",
    "\n",
    "For now, we are simply resetting all of them as it does not cost much to do so. (structured grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Grid, pos_in_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 100\n",
    "arr = np.random.uniform(low = -1, high = 1, size = (N,5))\n",
    "grid = Grid(np.array([3,7]), 10)\n",
    "\n",
    "from src.plotting import plot_particles, plot_grid\n",
    "resolutions = (3,7)\n",
    "system_shape = (2.,2.)\n",
    "offsets = np.array([-1, -1])\n",
    "fig, ax = plt.subplots()\n",
    "plot_grid(ax, resolutions, system_shape, offsets)\n",
    "plot_particles(ax, arr, r = 0.1)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grid_datatype(positions, new, old = 0):\n",
    "    index_container = np.zeros((new-old))\n",
    "    index_in_container = np.arange(old, new)\n",
    "    indexes = np.stack((index_container, index_in_container), axis = 1)\n",
    "    return np.concatenate((positions, indexes), axis = 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = pos_in_grid(arr[:,:2], resolutions, offsets, system_shape)\n",
    "particles = convert_to_grid_datatype(positions, new = positions.shape[0])\n",
    "print(particles[:10])\n",
    "grid.add_multiple(particles)\n",
    "print(grid.current);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.reset() # that's how we are going to do...\n",
    "print(grid.current);\n",
    "grid.add_multiple(particles)\n",
    "print(grid.current);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-construction",
   "metadata": {},
   "source": [
    "# Integration test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-mattress",
   "metadata": {},
   "source": [
    "Signatures :\n",
    " - SystemCreator(segments)\n",
    " - inject(in_wall, in_vect, debit, vel_std, radius, dt, remains)\n",
    " - advect(arr, f, dt, args, scheme)\n",
    " - handler_wall_collision(arr, walls, a, radius)\n",
    " - make_collisions_vectorized(arr, a, ct, cp)\n",
    " - Particle(part_type, charge, mass, radius, size_array)\n",
    " - Grid(resolutions, max_number_per_cell)\n",
    " - collider(arr, grid, currents, dt, average, pmax, cross_section, volume_cell, mr, remains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# system\n",
    "from src.system_creator import SystemCreator\n",
    "\n",
    "# Grid\n",
    "from src.utils import Grid, pos_in_grid, convert_to_grid_datatype\n",
    "\n",
    "# Particles\n",
    "from src.utils import Particle\n",
    "\n",
    "# injection \n",
    "from src.utils import inject\n",
    "\n",
    "# advection\n",
    "from src.utils import advect\n",
    "from src.utils import euler_explicit, leap_frog\n",
    "\n",
    "# collisions\n",
    "from src.utils import handler_wall_collision, handler_wall_collision_point, make_collisions_vectorized, make_collisions_out_walls, deal_with_corner\n",
    "\n",
    "# utils \n",
    "from src.utils import gaussian, maxwellian_flux, maxwellian_mean_speed, get_mass_part, mean_free_path, mean_free_time\n",
    "\n",
    "# systems\n",
    "from src.utils import systems\n",
    "\n",
    "# plotting \n",
    "from src.plotting import plot_boundaries, plot_particles, plot_grid, plot_system\n",
    "from src.plotting import analysis\n",
    "\n",
    "# collisions between particles\n",
    "from src.utils import handler_particles_collisions, candidates # candidates, index_choosen_couples, probability, is_colliding, reflect, \n",
    "\n",
    "# saving \n",
    "from src.data import Saver\n",
    "\n",
    "# other imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "np.random.seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "western-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System :\n",
    "dz = 0.001\n",
    "\n",
    "    # tube, square etc.\n",
    "# system, idx_out_walls, idx_in_wall = systems.system_rectangle(lx = 0.01, ly = 0.001)\n",
    "\n",
    "    # thruster \n",
    "dp = 0.001\n",
    "system, idx_out_walls, idx_in_wall = systems.thruster_system(w_in = 5*dp, l_in = 3*dp, w1 = 3*dp, l1 = dp, l_int = dp, w2 = dp, l2 = 5*dp, w_out = 5*dp, l_out = dp, offsets = np.array([0,0]))\n",
    "\n",
    "    # cylinder\n",
    "# system, idx_out_walls, idx_in_wall = systems.cylinder_system(res = 4, lx = 0.003, ly = 0.001, cx = 0.0015 , cy = 0.0005, r = 0.0001)\n",
    "\n",
    "offsets = system.get_offsets()\n",
    "system_shape = system.system_shape()\n",
    "a = system.get_dir_vects()\n",
    "segments = system.get_segments()\n",
    "\n",
    "# grid :\n",
    "mean_number_per_cell = 1000\n",
    "max_number_per_cell = 10*mean_number_per_cell\n",
    "# resolutions = np.array((10,1), dtype = int) # tube\n",
    "resolutions = np.array((11,5), dtype = int) # thruster\n",
    "# resolutions = np.array((9,9), dtype = int) # cylinder\n",
    "\n",
    "grid = Grid(resolutions, max_number_per_cell)\n",
    "volume_cell = dz * system_shape[0]/resolutions[0] * system_shape[1]/resolutions[1]\n",
    "\n",
    "# Particles - 1 type \n",
    "density = 3.2e19 # m-3\n",
    "n_simu = mean_number_per_cell*np.prod(resolutions) # number of particles in the simulated system\n",
    "n_real = volume_cell * density * np.prod(resolutions) # number of particles in the real system\n",
    "mr = n_real/n_simu # macro particules ratio = number of particles in the real system / number of macro part in the simulated system\n",
    "density_dsmc = density/mr\n",
    "temperature = 300 # K\n",
    "\n",
    "part_type = 'I'\n",
    "charge, mass, radius = 0, get_mass_part(53, 53, 74), 2e-10\n",
    "size_array = 2*mean_number_per_cell*np.prod(resolutions)\n",
    "v_mean = maxwellian_mean_speed(temperature, mass)\n",
    "container = Particle(part_type, charge, mass, radius, size_array)\n",
    "cross_section = container.get_params()[3]\n",
    "\n",
    "# mean free path and time\n",
    "mfp = mean_free_path(cross_section, density)\n",
    "typical_lenght = 0.001\n",
    "mft = mean_free_time(typical_lenght, v_mean = v_mean)\n",
    "\n",
    "    # Injection params\n",
    "in_wall = segments[idx_in_wall]\n",
    "in_vect = np.array([in_wall[3]-in_wall[1],in_wall[0]-in_wall[2]]) # a[idx_in_wall]\n",
    "\n",
    "debit = maxwellian_flux(density_dsmc, v_mean)*np.linalg.norm(in_wall[:2]-in_wall[2:])*dz\n",
    "vel_std = gaussian(temperature, mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93da17a6-808a-455b-9534-58f8ebdd46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation params\n",
    "iterations = 1000\n",
    "dt = 1e-6 # in sec, should be a fraction of the mean free time\n",
    "\n",
    "# saving params\n",
    "saving_period = 10\n",
    "adding_period = 1\n",
    "\n",
    "# advection\n",
    "def f(arr, dt):\n",
    "    return np.zeros(shape = (arr.shape[0], 3))\n",
    "\n",
    "args = []\n",
    "scheme = euler_explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alpha-kinase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222.84430705073834\n",
      "0.062169899645271615\n",
      "4.487437948200826e-06\n",
      "278.5553838134229\n",
      "1.760000e+12\n",
      "3.200000e+07\n",
      "139.6469602234833\n",
      "222.84430705073834\n",
      "111.47995555086219\n"
     ]
    }
   ],
   "source": [
    "print(v_mean);\n",
    "print(mfp);\n",
    "print(mft);\n",
    "print(debit*dt);\n",
    "print(\"{:e}\".format(n_real))\n",
    "print(\"{:e}\".format(mr));\n",
    "print(vel_std)\n",
    "print(v_mean)\n",
    "new, remains = inject(in_wall, in_vect, debit*100, vel_std, radius, dt, 0)\n",
    "print(np.mean(np.linalg.norm(new[:,2:], axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_system(None, segments, radius, resolutions, system_shape, offsets);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a04e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAME tests\n",
    "from pathlib import Path\n",
    "\n",
    "dir_path = Path('results/')\n",
    "name = 'test_thruster.h5'\n",
    "\n",
    "saver = Saver(dir_path, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-hotel",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['x','y','vx','vy','vz']) # bucket for the particles - index of particles is the iteration number\n",
    "\n",
    "# defining useful arrays and ints \n",
    "remains = 0 # fractionnal part of the number of particles to inject (it is then passed to the following time step)\n",
    "averages = np.full(shape = grid.current.shape, fill_value = mean_number_per_cell) # average number of particles per cell\n",
    "pmax = 2*v_mean*cross_section*np.ones(averages.shape) # max proba per cell in the simu\n",
    "remains_per_cell = np.zeros(shape = grid.current.shape, dtype = float) # remains per cell for the particles collisions step\n",
    "\n",
    "# SIMULATING\n",
    "print('|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|'.format(' it ', ' INIT ', ' INJECT ', ' DEL ', ' TRY'))\n",
    "print('{:-^56}'.format(''))\n",
    "\n",
    "for it in range(iterations): # tqdm\n",
    "    n1 = container.get_current()\n",
    "                   \n",
    "    # injecting particles\n",
    "    new, remains = inject(in_wall, in_vect, debit, vel_std, radius, dt, remains)\n",
    "    container.add_multiple(new)\n",
    "                   \n",
    "    n2 = container.get_current()-n1\n",
    "    \n",
    "    # PHASE : ADVECTING\n",
    "        # MOVING PARTICLES\n",
    "    arr = container.get_particles()\n",
    "    \n",
    "    if(it%adding_period == 0):\n",
    "        df = df.append(pd.DataFrame(data=arr, index=[it]*arr.shape[0], columns = ['x','y','vx','vy','vz']))\n",
    "    \n",
    "    advect(arr, f, dt, args, scheme) # advect is inplace\n",
    "    \n",
    "        # HANDLING BOUNDARIES \n",
    "    count = np.full(fill_value = True, shape = arr.shape[0])\n",
    "    idxes_out = []\n",
    "    c = 0\n",
    "    while(np.sum(count, where = count == True) > 0):\n",
    "        c+=1\n",
    "        ct, cp = handler_wall_collision_point(arr[count], segments, a) # handler_wall_collision(arr[count], segments, a, radius)\n",
    "        count, idxes_out_ = make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "        idxes_out.append(idxes_out_)\n",
    "    \n",
    "    idxes_out = np.concatenate(idxes_out)\n",
    "    \n",
    "    # TODO : make delete multiple better - currently the function creates a new array where as we can do it inplace.\n",
    "    container.delete_multiple(idxes_out)\n",
    "    \n",
    "    arr = container.get_particles()\n",
    "    \n",
    "    # PHASE : COLLISIONS\n",
    "        # UPDATING GRID - HARD RESET\n",
    "        # TODO : change the way it's done\n",
    "    grid.reset()\n",
    "    positions = pos_in_grid(arr[:,:2], resolutions, offsets, system_shape)\n",
    "    particles = convert_to_grid_datatype(positions, new = positions.shape[0])\n",
    "    grid.add_multiple(particles)\n",
    "        \n",
    "        # DSMC\n",
    "        # TODO: make parallel\n",
    "    currents = grid.get_currents()\n",
    "    averages = (it*averages+currents)/(it+1) # may be it too violent ? \n",
    "    \n",
    "    remains_per_cell, nb_colls, pmax, monitor = handler_particles_collisions([arr], grid.get_grid(), currents, dt, averages, pmax, cross_section, volume_cell, mr, remains_per_cell, monitoring = True)\n",
    "    # PLOTTING AND SAVING (OPTIONAL)\n",
    "    if(it%saving_period==0 or it == iterations-1): # saving if last iterations too\n",
    "        saver.save(it = it, append = {\n",
    "                        'df' : df,\n",
    "                        'collisions_per_cell' : nb_colls, # evolution of the number of collisions per cell - size : grid.shape[0] x grid.shape[1] (2D)\n",
    "                        'total_distance' : float(monitor[0]), # evolution of the sum of the distance accross all cells \n",
    "                        'total_proba' : float(monitor[1]), # evolution of the sum of proba accross all cells\n",
    "                        'pmax_per_cell' : pmax,  # evolution of the sum of pmax - per cell (2D)\n",
    "                        'total_deleted' : len(idxes_out), # evolution of the number of deleted particles per cell (int)\n",
    "                        'averages_per_cell' : averages\n",
    "                  })\n",
    "        \n",
    "        # resetting dataframe to not use too much memory\n",
    "        df = pd.DataFrame(columns = ['x','y','vx','vy','vz'])\n",
    "        print('|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|'.format(it, n1, n2, idxes_out.shape[0], c))\n",
    "saver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "induced-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from src.data import Saver\n",
    "from src.plotting import analysis\n",
    "dir_path = Path('results/')\n",
    "name = 'test_thruster.h5'\n",
    "store = pd.HDFStore(dir_path/name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf82cee6-1daa-4118-a18c-a7a633abac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_per_cell = store['collisions_per_cell'] \n",
    "df = store['df']\n",
    "pmax_per_cell = store['pmax_per_cell']\n",
    "averages_per_cell = store['averages_per_cell']\n",
    "total_deleted = store['total_deleted']\n",
    "total_distance = store['total_distance']\n",
    "total_proba = store['total_proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d631f6-cd67-4d56-a30e-8f42abdf22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_index = df.index.unique().values\n",
    "nb_save = unique_index.shape[0]\n",
    "iterations = np.max(unique_index)\n",
    "adding_period = unique_index[1]-unique_index[0] # adding period - required to\n",
    "frames = unique_index[int(0.8*nb_save):nb_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9892ad3b-7eb7-496d-89ec-60203405e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817\n",
      " 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835\n",
      " 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853\n",
      " 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871\n",
      " 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889\n",
      " 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907\n",
      " 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925\n",
      " 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943\n",
      " 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961\n",
      " 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979\n",
      " 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997\n",
      " 998 999]\n"
     ]
    }
   ],
   "source": [
    "print(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5fb7d",
   "metadata": {},
   "source": [
    "## Number of particles - evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "analysis.nb_particles_evolution(ax, store['df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a5201-2759-42ba-a8df-fe6eae2e712c",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50fd1de-cd30-4047-a1cd-7c6c27ffeaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "analysis.state(ax, df.loc[df.index == 999], c = None)\n",
    "# analysis.velocity_distribution(df, frames);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fae861-bbf6-4d34-82d6-ac9bdc01dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.spatial_hist2d(df, frames, val = 'vx', x_res = 11, y_res = 5, x_step = 0.001, y_step=0.001);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97277115",
   "metadata": {},
   "source": [
    "## Number of collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_collisions_per_cell = store['collisions_per_cell']\n",
    "nb_collisions_per_cell = nb_collisions_per_cell.groupby(nb_collisions_per_cell.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(nb_collisions_per_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of collision : \\n', np.sum(nb_collisions_per_cell));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210b44e",
   "metadata": {},
   "source": [
    "## DSMC - monitoring \n",
    "\n",
    "- proba (over the system - not by cell)\n",
    "- distance between collisioning particles (over the system - not by cell)\n",
    "- average number of particle per cell (by cell)\n",
    "- pmax (by cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = total_proba/nb_collisions_per_cell\n",
    "dist = total_distance/nb_collisions_per_cell\n",
    "print('Mean proba : {:e}'.format(np.mean(proba)))\n",
    "print('Mean distance : {:e} m'.format(np.mean(dist)))\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].plot(proba.index, proba, label = 'proba')\n",
    "ax[1].plot(dist.index, dist, label = 'distance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e53bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmax = pmax_per_cell.groupby(pmax_per_cell.index).sum()\n",
    "averages = averages_per_cell.groupby(averages_per_cell.index).sum()\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].plot(pmax, label = 'proba')\n",
    "ax[1].plot(averages, label = 'averages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400f4f7b-9e64-400d-a5b2-164c522040c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speed_norm'] = np.sqrt(df['vx']**2+df['vy']**2+df['vz']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "equal-finland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe8e3078d7a4eee9a03d03cc2cd70af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "# plt.style.use('seaborn-pastel')\n",
    "\n",
    "def update_hist(num, df):\n",
    "    #plt.cla() # to clear the current figure\n",
    "    dfit = df.loc[df.index == num]\n",
    "    # since we modifying scat we dont want to use plt.cla\n",
    "    scat.set_offsets(np.c_[dfit['x'],dfit['y']])\n",
    "    # scat.set_array(df['speed_norm'])\n",
    "    # plot_grid(ax, resolutions, system_shape)\n",
    "    ax.set_title('{}/{}'.format(num+1, 1000), fontsize=15)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "dfit = df.loc[df.index == 0]\n",
    "scat = ax.scatter(dfit['x'], dfit['y'], s=0.1, c = dfit['speed_norm'], cmap='seismic') #  c = df['speed_norm']\n",
    "plot_boundaries(ax, segments)\n",
    "# plot_grid(ax, resolutions, system_shape)\n",
    "ax.set_title('{}/{}'.format(1, 1000), fontsize=12)\n",
    "\n",
    "# ax.axis('equal')\n",
    "# ax.set_xlim(x_min, x_max)\n",
    "# ax.set_ylim(y_min, y_max)\n",
    "\n",
    "ax.axis('equal')\n",
    "# min_x, min_y, max_x, max_y = min(df['x']), min(df['y']), max(df['x']), max(df['y'])\n",
    "# ax.set(xlim=(-0.001, 0.011), ylim=(-0.0001, 0.0011))\n",
    "# ax.set(xlim=(0, 0.003), ylim=(0, 0.002))\n",
    "\n",
    "interval = 40 # 25 images per second\n",
    "\n",
    "anim = FuncAnimation(fig, update_hist, interval=interval, frames=1000, fargs=(df, ), save_count=1000)\n",
    "# plt.show()\n",
    "anim.save('system_evo_thruster_test.mp4', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94b6a7-5cad-42b9-993e-aa58b022732d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
