{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f5d244-2fbf-49c0-8ab0-15689d05a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-christian",
   "metadata": {},
   "source": [
    "# Module Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa58db60-ce2b-4218-8236-04fecfd75e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src.plotting import plot_boundaries, plot_particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-accident",
   "metadata": {},
   "source": [
    "## System creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "from src.system_creator import SystemCreator\n",
    "\n",
    "# Tube creation :\n",
    "tube_segments = 0.001*np.array([[0,0,10,0], [0,0,0,1], [10,0,10,1], [0,1,10,1]])\n",
    "tube = SystemCreator(tube_segments)\n",
    "\n",
    "offsets = tube.get_offsets()\n",
    "system_shape = tube.system_shape()\n",
    "a = tube.get_dir_vects()\n",
    "\n",
    "print(f'Tube : \\noffsets : {offsets}')\n",
    "print(f'System size : {system_shape} \\n')\n",
    "\n",
    "# Cylinder\n",
    "circle = [[5+np.cos(k*np.pi/8), 5+np.sin(k*np.pi/8), 5+np.cos((k+1)*np.pi/8), 5+np.sin((k+1)*np.pi/8)] for k in range(16)]\n",
    "cylinder_segments = 0.001*np.array([[0,0,10,0], [0,0,0,10], [10,0,10,10], [0,10,10,10]]+circle)\n",
    "cylinder = SystemCreator(cylinder_segments)\n",
    "\n",
    "print(f'Cylinder : \\noffsets : {cylinder.get_offsets()}')\n",
    "print(f'System size : {cylinder.system_shape()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots();\n",
    "plot_boundaries(ax, tube_segments);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, cylinder_segments)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-impact",
   "metadata": {},
   "source": [
    "## Particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Particle, get_mass_part\n",
    "\n",
    "# Iodine\n",
    "container = Particle('I', 0, get_mass_part(53, 53, 74), radius = 2e-10, size_array = 10000)\n",
    "N = 500\n",
    "arr =  np.random.random((N,5))\n",
    "print(f'mass, charge, radius, cross-section = {container.get_params()}'); # mass, charge, radius, cross-section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "container.add_multiple(arr)\n",
    "print(container.get_current())\n",
    "print(container.get_particles().shape)\n",
    "print(container.arr.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of particles : {container.get_current()}')\n",
    "for k in range(3):\n",
    "    container.add_multiple(np.random.random((1000,5)))\n",
    "    print(f'Number of particles : {container.get_current()}')\n",
    "    container.delete_multiple(np.random.choice(a = container.get_current(), size = 500, replace = False))\n",
    "    print(f'Number of particles : {container.get_current()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : make 'dynamic' arrays (when increasing the size).\n",
    "container.add_multiple(np.random.random((3000,5)))\n",
    "print(f'Number of particles : {container.get_current()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-library",
   "metadata": {},
   "source": [
    "**Conclusion**  : make 'dynamic' array (can increase time, but not decrease it for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-hollow",
   "metadata": {},
   "source": [
    "## Grid\n",
    "For now : 2D-ndarray with value of type *ndarray* which are 2D.\n",
    "```python\n",
    "# grid[x_int, y_int] is the container for a cell\n",
    "# grid[x_int, y_int][idx] contains the particle indexes\n",
    "grid[x_int, y_int][idx] = [idx_container, idx_particle_in_container]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Grid, pos_in_grid\n",
    "resolutions = np.array([4,4])\n",
    "max_number_per_cell = 10 # to initialize the array which will contain the particles indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid(resolutions, max_number_per_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, vx, vy, vz\n",
    "arr = np.array([[-1.5,1.2,1,0,0], [-1.3,-0.8,0,-1,0], [1.3,-0.5,-1,0,0], [1,1,-1,-1,-1], [-1,1,1,0,0]])\n",
    "print(arr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signature : pos_in_grid(pos, grid_res, offsets, system_shape)\n",
    "pos = pos_in_grid(arr[:,:2], resolutions, offsets = np.array([-2, -2]), system_shape = np.array([4,4])) # not inplace\n",
    "print(pos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [pos_x, pos_y, idx_container, idx_particle_in_container]\n",
    "idx_container = np.array([0,0,0,0,0])\n",
    "idx_particle_in_container = np.array([0,1,2,3,4])\n",
    "idxes = np.stack((idx_container, idx_particle_in_container), axis = 1)\n",
    "new_arr = np.concatenate((pos, idxes), axis = 1)\n",
    "print(new_arr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.reset()\n",
    "grid.add_multiple(new_arr)\n",
    "print(grid.current);\n",
    "print(grid.get([0,1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : delete multiple\n",
    "grid.delete([0,1], 0) # can still take lots of time\n",
    "print(grid.current);\n",
    "print(grid.get([0,1]));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-laptop",
   "metadata": {},
   "source": [
    "**Conclusion** :\n",
    "- Add a 'delete_multiple' built on *NumPy* - **DONE**\n",
    "- Maybe change the grid to a 4D-array :\n",
    "    - Pro : faster everything.\n",
    "    - Cons : waste of memory for system with density gradients, increasing size of the array costs much more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-seller",
   "metadata": {},
   "source": [
    "## Injector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    " # notebook\n",
    "from src.plotting import plot_particles, plot_boundaries\n",
    "import src.plotting.analysis as analysis\n",
    "from src.utils import inject \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signature : inject(in_wall, in_vect, debit, vel_std, radius, dt)\n",
    "in_wall =  np.array([0,0,0,1]) # np.array([0,0,0,1]) # np.array([0,0,1,0]) # np.array([0,0,0,1]) # np.array([0,0,1,1])\n",
    "a = np.array([0,1,1])\n",
    "in_vect = np.array([1,0]) # (1/np.sqrt(2))*np.array([-1,1]) # -np.array([1,0]) #  -np.array([0,1]) # np.array([1,0])# (1/np.sqrt(2))*np.array([1,1])\n",
    "debit = 100000000 # particles / s\n",
    "dt = 0.001\n",
    "vel_std = 200. # m/s\n",
    "radius = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr, remains = inject(in_wall, in_vect, debit, vel_std, radius, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, np.expand_dims(in_wall, axis = 0))\n",
    "plot_particles(ax, arr, r = 10*radius, arrows = False)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(arr, columns = ['x', 'y', 'vx', 'vy', 'vz'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.velocity_distribution(df, bins = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-backup",
   "metadata": {},
   "source": [
    "## Advection (and schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import advect\n",
    "from src.utils import euler_explicit, leap_frog\n",
    "from src.plotting import plot_particles, plot_boundaries\n",
    "\n",
    "# notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signature : advect(arr, f, dt, args, scheme)\n",
    "arr = np.array([[1,1,1,1,0], [2,1,-1,-1,0]], dtype = float)\n",
    "#arr = np.random.random((10,5))\n",
    "def f(arr, dt):\n",
    "    return np.zeros(shape = (arr.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_ = np.copy(arr)\n",
    "advect(arr_, f, dt = 0.1, args = [], scheme = euler_explicit) # seems ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr__ =  np.copy(arr)\n",
    "advect(arr__, f, dt = 0.1, args = [], scheme = leap_frog) # seems ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_particles(ax, arr, r = 10) \n",
    "plot_particles(ax, arr_, r = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-dinner",
   "metadata": {},
   "source": [
    "## Collision with walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plotting import plot_boundaries, plot_particles\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized, make_collisions_out_walls\n",
    "import numpy as np\n",
    "N = 10\n",
    "walls = 1.5*np.array([[0,0,1,0], [0,0,0,1], [1,0,1,1], [0,1,1,1]]) # bottom, left, right, top\n",
    "a = np.array([[1,0, 1.5],[0,1, 1.5],[0,1, 1.5],[1,0, 1.5]])\n",
    "# arr = np.array([[2,0.5,1,0,0], [0.5,2,0,1,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [-0.5,0.5,-1,0,0]])  # np.random.random((N,5)) # \n",
    "arr = np.array([[1.5,2,1,1,0]])\n",
    "arr[:,2:] = 5*arr[:,2:]\n",
    "radius = 0.1\n",
    "idx_out_walls = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, walls)\n",
    "plot_particles(ax, arr, r = 8, arrows = True)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct, cp = handler_wall_collision(arr, walls, a, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr_1 = np.copy(arr)\n",
    "new_arr_2 = np.copy(arr)\n",
    "new_arr_3 = np.copy(arr)\n",
    "make_collisions(new_arr_1, a, ct, cp)\n",
    "make_collisions_vectorized(new_arr_2, a, ct, cp)\n",
    "indexes = make_collisions_out_walls(new_arr_3, a, ct, cp, idx_out_walls)\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "\n",
    "plot_boundaries(ax[0,0], walls)\n",
    "plot_particles(ax[0,0], arr, r = 8, arrows = True)\n",
    "\n",
    "plot_boundaries(ax[0,1], walls)\n",
    "plot_particles(ax[0,1], new_arr_1, r = 8, arrows = True)\n",
    "\n",
    "plot_boundaries(ax[1,0], walls)\n",
    "plot_particles(ax[1,0], new_arr_2, r = 8, arrows = True)\n",
    "\n",
    "plot_boundaries(ax[1,1], walls)\n",
    "plot_particles(ax[1,1], new_arr_3, r = 8, arrows = True)\n",
    "\n",
    "ax[0,0].axis('equal')\n",
    "ax[0,1].axis('equal')\n",
    "ax[1,0].axis('equal')\n",
    "ax[1,1].axis('equal')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-michael",
   "metadata": {},
   "source": [
    "#### Collision with walls - and outwalls\n",
    "\n",
    "Problem : sometimes a particle can collide and be reflected but remain outside the system. In such a case, we have to make sure the particle is reflected again, and as many time as necessary. In addition, particles that went out (by the out walls) should be taken into account and :\n",
    " - not reflected back into the system but instead removed\n",
    " - a particle can, after its second reflection in a row, finds itself going trough the 'out wall'. In such a case it should be added to the list of particle to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized, make_collisions_out_walls\n",
    "import numpy as np\n",
    "from src.plotting import plot_boundaries, plot_particles\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 10\n",
    "segments = 1.5*np.array([[0,0,1,0], [0,0,0,1], [1,0,1,1], [0,1,1,1]]) # bottom, left, right, top\n",
    "a = np.array([[1,0, 1.5],[0,1, 1.5],[0,1, 1.5],[1,0, 1.5]])\n",
    "arr = np.array([[-4,5.5,-1,1,0], [1.6,2,1,1,0],[2,0.5,1,0,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [-0.5,0.5,-1,0,0]])  # np.random.random((N,5)) # \n",
    "radius = 0.01\n",
    "idx_out_walls = [2] # 2 : Right\n",
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, segments)\n",
    "plot_particles(ax, arr, r = 8, arrows = True)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.full(shape = (arr.shape[0]), fill_value = True)\n",
    "idxes_out = []\n",
    "c = 0\n",
    "while(np.sum(count, where = count == True) > 0):\n",
    "        print(c)\n",
    "        c+=1\n",
    "        ct, cp = handler_wall_collision(arr[count], segments, a, radius)\n",
    "        print(cp)\n",
    "        count, idxes_out_ = make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "        idxes_out.append(idxes_out_)\n",
    "        fig, ax = plt.subplots()\n",
    "        plot_boundaries(ax, segments)\n",
    "        plot_particles(ax, arr, r = 8, arrows = True)\n",
    "        plt.axis('equal');\n",
    "        \n",
    "        #print(count)\n",
    "        if(c>20):\n",
    "            break\n",
    "print(c)\n",
    "idxes_out = np.concatenate(idxes_out)\n",
    "\n",
    "arr[idxes_out.shape[0]:,:] = np.delete(arr, idxes_out, axis = 0) # operation is not inplace\n",
    "c-=idxes_out.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e07cabc",
   "metadata": {},
   "source": [
    "### Collision with walls - cylinder - why does it not work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4fbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized, make_collisions_out_walls, deal_with_corner\n",
    "import numpy as np\n",
    "from src.plotting import plot_boundaries, plot_particles\n",
    "import matplotlib.pyplot as plt\n",
    "from src.system_creator import SystemCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb265779",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 4\n",
    "circle = [[1.5+0.5*np.cos(k*np.pi/res), 1+0.5*np.sin(k*np.pi/res), 1.5+0.5*np.cos((k+1)*np.pi/res), 1+0.5*np.sin((k+1)*np.pi/res)] for k in range(2*res)]\n",
    "segments = 0.001*np.array([[0,0,3,0], [0,0,0,2], [3,0,3,2], [0,2,3,2]]+circle)\n",
    "system = SystemCreator(segments)\n",
    "\n",
    "offsets = system.get_offsets()\n",
    "system_shape = system.system_shape()\n",
    "a = system.get_dir_vects()\n",
    "segments = system.get_segments()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, segments, color = 'k')\n",
    "\n",
    "# liste_vectors_segment = np.concatenate((segments[:,:2], segments[:,:2]+0.001*a[:,:2]), axis = 1)\n",
    "# plot_boundaries(ax, liste_vectors_segment, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining particles\n",
    "# arr = 0.001*np.array([[-4,5.5,-1,1,0], [1.6,2,1,1,0],[2,0.5,1,0,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [-0.5,0.5,-1,0,0]])  # np.random.random((N,5)) # \n",
    "arr = np.array([[0.0015, 0.001, 100, 0,0]])\n",
    "radius = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.full(shape = (arr.shape[0]), fill_value = True)\n",
    "idxes_out = []\n",
    "c = 0\n",
    "idx_out_walls = []\n",
    "while(np.sum(count, where = count == True) > 0):\n",
    "        c+=1\n",
    "        ct, cp = handler_wall_collision(arr[count], segments, a, radius)\n",
    "        print(ct)\n",
    "        deal_with_corner(ct)\n",
    "        print(ct)\n",
    "        count, idxes_out_ = make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "        idxes_out.append(idxes_out_)\n",
    "        fig, ax = plt.subplots()\n",
    "        plot_boundaries(ax, segments)\n",
    "        plot_particles(ax, arr, r = 1, arrows = False)\n",
    "        plt.axis('equal');\n",
    "\n",
    "        if(c>20):\n",
    "            break\n",
    "\n",
    "np.concatenate(idxes_out)\n",
    "\n",
    "# arr[idxes.shape[0]:,:] = np.delete(arr, idxes, axis = 0) # operation is not inplace\n",
    "# current-=idxes.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-angle",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-mortality",
   "metadata": {},
   "source": [
    "## Particles collisions\n",
    "\n",
    "Signatures of the functions :\n",
    "* candidates(currents, dt, average, pmax, volume_cell, mr, remains)\n",
    "* index_choosen_couples(current, candidates)\n",
    "* probability(vr_norm, pmax, cross_sections)\n",
    "* is_colliding(proba)\n",
    "* reflect(arr, vr_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import candidates, index_choosen_couples, probability, is_colliding, reflect\n",
    "import numpy as np\n",
    "from src.plotting import plot_particles, plot_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "currents = 10*np.array([\n",
    "    [16,22,14],\n",
    "    [9,13,11],\n",
    "    [4,9,6]\n",
    "])\n",
    "dt = 1e-7\n",
    "averages = 10*np.array([\n",
    "    [15,20,15],\n",
    "    [10,15,10],\n",
    "    [5,10,5]\n",
    "])\n",
    "radius = 2e-10\n",
    "cross_section = 4 * np.pi * radius**2\n",
    "pmax = cross_section * 600\n",
    "pmax_vect = cross_section * 600 * np.ones(averages.shape)\n",
    "print(pmax_vect.shape)\n",
    "volume_cell = (0.001)**3\n",
    "mr = 1e15\n",
    "remains = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "remains, cands = candidates(currents, dt, averages, pmax, volume_cell, mr, remains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f371a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remains, cands = candidates(currents, dt, averages, pmax_vect, volume_cell, mr, remains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [np.random.uniform(low = -1, high = 1, size = (current, 5)) for current in currents.flatten()]\n",
    "arr = np.concatenate(arrays, axis = 0)\n",
    "arr_save = np.copy(arr)\n",
    "print(arr.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_shape = currents.shape\n",
    "system_shape = (2.,2.)\n",
    "offsets = np.array([-1, -1])\n",
    "fig, ax = plt.subplots()\n",
    "plot_grid(ax, grid_shape, system_shape, offsets)\n",
    "plot_particles(ax, arr, r = 0.1)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-syndrome",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for count, (i, j) in enumerate(np.ndindex(currents.shape)):\n",
    "    choice = index_choosen_couples(currents[i,j], int(cands[i,j]))\n",
    "    vr_norm = np.linalg.norm((arrays[count][choice][:,1,2:]-arrays[count][choice][:,0,2:]), axis = 1)\n",
    "    proba = probability(vr_norm = vr_norm, pmax = pmax, cross_sections = cross_section)\n",
    "    collidings_couples = is_colliding(proba)\n",
    "    print(np.sum(collidings_couples))\n",
    "    # if(not all(~collidings_couples)):\n",
    "    #    ic(all(~collidings_couples))\n",
    "    #    ic(arr)\n",
    "    # can not be inplace\n",
    "    arrays[count][choice[collidings_couples]] = reflect(arrays[count][choice[collidings_couples]], vr_norm[collidings_couples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.concatenate(arrays, axis = 0)\n",
    "df1 = pd.DataFrame(arr_save, columns = ['x','y','vx','vy','vz'])\n",
    "df2 = pd.DataFrame(arr, columns = ['x','y','vx','vy','vz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "df1['vx'].plot.hist(bins=50, ax = ax[0,0])\n",
    "df1['vy'].plot.hist(bins=50, ax = ax[0,1])\n",
    "df2['vx'].plot.hist(bins=50, ax = ax[1,0])\n",
    "df2['vy'].plot.hist(bins=50, ax = ax[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "g = sns.JointGrid(data=df1, x=\"vx\", y=\"vy\", space=0)\n",
    "g.plot_joint(sns.kdeplot,\n",
    "             fill=True,\n",
    "             thresh=0, levels=100, cmap=\"rocket\")\n",
    "g.plot_marginals(sns.histplot, color=\"#03051A\", alpha=1, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "g = sns.JointGrid(data=df2, x=\"vx\", y=\"vy\", space=0)\n",
    "g.plot_joint(sns.kdeplot,\n",
    "             fill=True,\n",
    "             thresh=0, levels=100, cmap=\"rocket\")\n",
    "g.plot_marginals(sns.histplot, color=\"#03051A\", alpha=1, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "x = df1['x']\n",
    "y = df2['y']\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y, c=z, s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-bangladesh",
   "metadata": {},
   "source": [
    "### From grid, get particles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.utils import candidates, index_choosen_couples, probability, is_colliding, reflect\n",
    "\n",
    "currents = 10*np.array([\n",
    "    [24,26],\n",
    "    [25,25]\n",
    "], dtype = int)\n",
    "\n",
    "arr = [np.random.uniform(low = -1.0, high = 1.0, size = (1000,5))]\n",
    "arr_copy = np.copy(arr[0])\n",
    "# zer = np.zeros(250)\n",
    "t = np.arange(1000)\n",
    "np.random.shuffle(t)\n",
    "arr1, arr2, arr3, arr4 = np.split(t, indices_or_sections = [240,500,750], axis = 0)\n",
    "p1, p2 = np.stack((np.zeros(240), arr1), axis = 1), np.stack((np.zeros(260), arr2), axis = 1)\n",
    "p3, p4 = np.stack((np.zeros(250), arr3), axis = 1), np.stack((np.zeros(250), arr4), axis = 1)\n",
    "\n",
    "grid = np.array([\n",
    "    [p1, p2],\n",
    "    [p3, p4]],\n",
    "    dtype = np.ndarray)\n",
    "\n",
    "print(f'Currents : \\n {currents}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to get all that is in arr from grid...\n",
    "# and do this in place ... which will be VERY fucking hard\n",
    "# VERY SLOW\n",
    "cands = np.array([[120,123],[124,124]])\n",
    "cross_section = 1\n",
    "pmax = 2\n",
    "for k, (i, j) in enumerate(np.ndindex(currents.shape)):\n",
    "    choice = index_choosen_couples(currents[i,j], int(cands[i,j])) # choice contains the possible couples\n",
    "    # now, we have to get their pos and speed\n",
    "    g = grid[i,j]\n",
    "    parts = np.array([[g[c[0]], g[c[1]]] for c in choice], dtype = int)\n",
    "    array = np.array([[ arr[c[0,0]][c[0,1]] , arr[c[1,0]][c[1,1]] ] for c in parts])\n",
    "    # blablabla [...] -> DSMC etc.\n",
    "    # TODO: make those stuff and see if it still works\n",
    "\n",
    "    vr_norm = np.linalg.norm((array[:,1,2:]-array[:,0,2:]), axis = 1)\n",
    "    proba = probability(vr_norm = vr_norm, pmax = pmax, cross_sections = cross_section)\n",
    "\n",
    "    # TODO : should update pmax here (or return something)...\n",
    "    collidings_couples = is_colliding(proba)\n",
    "    array[collidings_couples] = reflect(array[collidings_couples], vr_norm[collidings_couples])\n",
    "    \n",
    "    for k in range(len(array)):\n",
    "        c1, c2 = array[k,0], array[k,1]\n",
    "        c = parts[k]\n",
    "        arr[c[0,0]][c[0,1]][:] = c1 # copy\n",
    "        arr[c[1,0]][c[1,1]][:] = c2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(arr_copy, arr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-server",
   "metadata": {},
   "source": [
    "### Reflection study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import reflect\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "arr = np.array([[[1,1,1,1,1], [1,1,-1,-1,1]]])\n",
    "vr_norm = np.linalg.norm((arr[:,1,2:]-arr[:,0,2:]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_ = reflect(np.copy(arr),vr_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr);\n",
    "print(arr_);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-painting",
   "metadata": {},
   "source": [
    "## Update position in grids - tests\n",
    "\n",
    "##### Idea : \n",
    "1. Create particles and initialize them in the grids\n",
    "2. Do something \n",
    "3. Update position in the grid\n",
    "\n",
    "For now, we are simply resetting all of them as it does not cost much to do so. (structured grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Grid, pos_in_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 100\n",
    "arr = np.random.uniform(low = -1, high = 1, size = (N,5))\n",
    "grid = Grid(np.array([3,7]), 10)\n",
    "\n",
    "from src.plotting import plot_particles, plot_grid\n",
    "resolutions = (3,7)\n",
    "system_shape = (2.,2.)\n",
    "offsets = np.array([-1, -1])\n",
    "fig, ax = plt.subplots()\n",
    "plot_grid(ax, resolutions, system_shape, offsets)\n",
    "plot_particles(ax, arr, r = 0.1)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grid_datatype(positions, new, old = 0):\n",
    "    index_container = np.zeros((new-old))\n",
    "    index_in_container = np.arange(old, new)\n",
    "    indexes = np.stack((index_container, index_in_container), axis = 1)\n",
    "    return np.concatenate((positions, indexes), axis = 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = pos_in_grid(arr[:,:2], resolutions, offsets, system_shape)\n",
    "particles = convert_to_grid_datatype(positions, new = positions.shape[0])\n",
    "print(particles[:10])\n",
    "grid.add_multiple(particles)\n",
    "print(grid.current);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.reset() # that's how we are going to do...\n",
    "print(grid.current);\n",
    "grid.add_multiple(particles)\n",
    "print(grid.current);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-construction",
   "metadata": {},
   "source": [
    "# Integration test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-mattress",
   "metadata": {},
   "source": [
    "Signatures :\n",
    " - SystemCreator(segments)\n",
    " - inject(in_wall, in_vect, debit, vel_std, radius, dt, remains)\n",
    " - advect(arr, f, dt, args, scheme)\n",
    " - handler_wall_collision(arr, walls, a, radius)\n",
    " - make_collisions_vectorized(arr, a, ct, cp)\n",
    " - Particle(part_type, charge, mass, radius, size_array)\n",
    " - Grid(resolutions, max_number_per_cell)\n",
    " - collider(arr, grid, currents, dt, average, pmax, cross_section, volume_cell, mr, remains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# system\n",
    "from src.system_creator import SystemCreator\n",
    "\n",
    "# Grid\n",
    "from src.utils import Grid, pos_in_grid, convert_to_grid_datatype\n",
    "\n",
    "# Particles\n",
    "from src.utils import Particle\n",
    "\n",
    "# injection \n",
    "from src.utils import inject\n",
    "\n",
    "# advection\n",
    "from src.utils import advect\n",
    "from src.utils import euler_explicit, leap_frog\n",
    "\n",
    "# collisions\n",
    "from src.utils import handler_wall_collision, handler_wall_collision_point, make_collisions_vectorized, make_collisions_out_walls, deal_with_corner\n",
    "\n",
    "# utils \n",
    "from src.utils import gaussian, maxwellian_flux, maxwellian_mean_speed, get_mass_part, mean_free_path, mean_free_time\n",
    "\n",
    "# systems\n",
    "from src.utils import systems\n",
    "\n",
    "# plotting \n",
    "from src.plotting import plot_boundaries, plot_particles, plot_grid, plot_system\n",
    "from src.plotting import analysis\n",
    "\n",
    "# collisions between particles\n",
    "from src.utils import handler_particles_collisions, candidates # candidates, index_choosen_couples, probability, is_colliding, reflect, \n",
    "\n",
    "# saving \n",
    "from src.data import Saver\n",
    "\n",
    "# other imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "np.random.seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System :\n",
    "dz = 0.001\n",
    "\n",
    "    # tube, square etc.\n",
    "system, idx_out_walls, idx_in_wall = systems.system_rectangle(lx = 0.01, ly = 0.001)\n",
    "\n",
    "    # thruster \n",
    "# dp = 0.001\n",
    "# isystem, idx_out_walls, idx_in_wall = systems.thruster_system(w_in = 5*dp, l_in = 3*dp, w1 = 3*dp, l1 = dp, l_int = dp, w2 = dp, l2 = 5*dp, w_out = 5*dp, l_out = dp, offsets = np.array([0,0]))\n",
    "\n",
    "    # cylinder\n",
    "# system, idx_out_walls, idx_in_wall = systems.cylinder_system(res = 4, lx = 0.003, ly = 0.001, cx = 0.0015 , cy = 0.0005, r = 0.0001)\n",
    "\n",
    "offsets = system.get_offsets()\n",
    "system_shape = system.system_shape()\n",
    "a = system.get_dir_vects()\n",
    "segments = system.get_segments()\n",
    "\n",
    "# grid :\n",
    "mean_number_per_cell = 1000\n",
    "max_number_per_cell = 10*mean_number_per_cell\n",
    "resolutions = np.array((10,1), dtype = int) # tube\n",
    "# resolutions = np.array((11,5), dtype = int) # thruster\n",
    "# resolutions = np.array((9,9), dtype = int) # cylinder\n",
    "\n",
    "grid = Grid(resolutions, max_number_per_cell)\n",
    "volume_cell = dz * system_shape[0]/resolutions[0] * system_shape[1]/resolutions[1]\n",
    "\n",
    "# Particles - 1 type \n",
    "density = 3.2e19 # m-3\n",
    "n_simu = mean_number_per_cell*np.prod(resolutions) # number of particles in the simulated system\n",
    "n_real = volume_cell * density * np.prod(resolutions) # number of particles in the real system\n",
    "mr = n_real/n_simu # macro particules ratio = number of particles in the real system / number of macro part in the simulated system\n",
    "density_dsmc = density/mr\n",
    "temperature = 300 # K\n",
    "\n",
    "part_type = 'I'\n",
    "charge, mass, radius = 0, get_mass_part(53, 53, 74), 2e-10\n",
    "size_array = 2*mean_number_per_cell*np.prod(resolutions)\n",
    "v_mean = maxwellian_mean_speed(temperature, mass)\n",
    "container = Particle(part_type, charge, mass, radius, size_array)\n",
    "cross_section = container.get_params()[3]\n",
    "\n",
    "# mean free path and time\n",
    "mfp = mean_free_path(cross_section, density)\n",
    "typical_lenght = 0.001\n",
    "mft = mean_free_time(typical_lenght, v_mean = v_mean)\n",
    "\n",
    "    # Injection params\n",
    "in_wall = segments[idx_in_wall]\n",
    "# you may have to change in_vect (adding a '-' should be enough) depending on the direction of injection of the particles\n",
    "in_vect = np.array([a[idx_in_wall,1], -a[idx_in_wall,0]]) # np.array([in_wall[3]-in_wall[1],in_wall[0]-in_wall[2]]) # a[idx_in_wall]\n",
    "\n",
    "debit = maxwellian_flux(density_dsmc, v_mean)*np.linalg.norm(in_wall[:2]-in_wall[2:])*dz\n",
    "vel_std = gaussian(temperature, mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da17a6-808a-455b-9534-58f8ebdd46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation params\n",
    "iterations = 1000\n",
    "dt = 1e-6 # in sec, should be a fraction of the mean free time\n",
    "\n",
    "# saving params\n",
    "saving_period = 10\n",
    "adding_period = 1\n",
    "\n",
    "# advection\n",
    "def f(arr, dt):\n",
    "    return np.zeros(shape = (arr.shape[0], 3))\n",
    "\n",
    "args = []\n",
    "scheme = euler_explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v_mean);\n",
    "print(mfp);\n",
    "print(mft);\n",
    "print(debit*dt);\n",
    "print(\"{:e}\".format(n_real))\n",
    "print(\"{:e}\".format(mr));\n",
    "print(vel_std)\n",
    "print(v_mean)\n",
    "new, remains = inject(in_wall, in_vect, debit*100, vel_std, radius, dt, 0)\n",
    "print(np.mean(np.linalg.norm(new[:,2:], axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_system(None, segments, radius, resolutions, system_shape, offsets);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a04e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAME tests\n",
    "from pathlib import Path\n",
    "\n",
    "dir_path = Path('results/')\n",
    "name = 'test_tube.h5'\n",
    "\n",
    "saver = Saver(dir_path, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-hotel",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['x','y','vx','vy','vz']) # bucket for the particles - index of particles is the iteration number\n",
    "\n",
    "# defining useful arrays and ints \n",
    "remains = 0 # fractionnal part of the number of particles to inject (it is then passed to the following time step)\n",
    "averages = np.full(shape = grid.current.shape, fill_value = mean_number_per_cell) # average number of particles per cell\n",
    "pmax = 2*v_mean*cross_section*np.ones(averages.shape) # max proba per cell in the simu\n",
    "remains_per_cell = np.zeros(shape = grid.current.shape, dtype = float) # remains per cell for the particles collisions step\n",
    "\n",
    "# SIMULATING\n",
    "print('|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|'.format(' it ', ' INIT ', ' INJECT ', ' DEL ', ' TRY'))\n",
    "print('{:-^56}'.format(''))\n",
    "\n",
    "for it in range(iterations): # tqdm\n",
    "    n1 = container.get_current()\n",
    "                   \n",
    "    # injecting particles\n",
    "    new, remains = inject(in_wall, in_vect, debit, vel_std, radius, dt, remains)\n",
    "    container.add_multiple(new)\n",
    "                   \n",
    "    n2 = container.get_current()-n1\n",
    "    \n",
    "    # PHASE : ADVECTING\n",
    "        # MOVING PARTICLES\n",
    "    arr = container.get_particles()\n",
    "    \n",
    "    if(it%adding_period == 0):\n",
    "        df = df.append(pd.DataFrame(data=arr, index=[it]*arr.shape[0], columns = ['x','y','vx','vy','vz']))\n",
    "    \n",
    "    advect(arr, f, dt, args, scheme) # advect is inplace\n",
    "    \n",
    "        # HANDLING BOUNDARIES \n",
    "    count = np.full(fill_value = True, shape = arr.shape[0])\n",
    "    idxes_out = []\n",
    "    c = 0\n",
    "    collisions_with_walls = 0\n",
    "    while(np.sum(count, where = count == True) > 0):\n",
    "        c+=1\n",
    "        ct, cp = handler_wall_collision_point(arr[count], segments, a) # handler_wall_collision(arr[count], segments, a, radius)\n",
    "        count, idxes_out_ = make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "        # tracking then number of wall collisions\n",
    "        if(c == 1):\n",
    "            collisions_with_walls = np.sum(count, where = count == True)\n",
    "        # the first value of np.sum(count, where = count == True) is then number of colliding particles !\n",
    "        idxes_out.append(idxes_out_)\n",
    "    \n",
    "    idxes_out = np.concatenate(idxes_out)\n",
    "    \n",
    "    # TODO : make delete multiple better - currently the function creates a new array where as we can do it inplace.\n",
    "    container.delete_multiple(idxes_out)\n",
    "    \n",
    "    arr = container.get_particles()\n",
    "    \n",
    "    # PHASE : COLLISIONS\n",
    "        # UPDATING GRID - HARD RESET\n",
    "        # TODO : change the way it's done\n",
    "    grid.reset()\n",
    "    positions = pos_in_grid(arr[:,:2], resolutions, offsets, system_shape)\n",
    "    particles = convert_to_grid_datatype(positions, new = positions.shape[0])\n",
    "    grid.add_multiple(particles)\n",
    "        \n",
    "        # DSMC\n",
    "        # TODO: make parallel\n",
    "    currents = grid.get_currents()\n",
    "    averages = (it*averages+currents)/(it+1) # may be it too violent ? \n",
    "    \n",
    "    remains_per_cell, nb_colls, pmax, monitor = handler_particles_collisions([arr], grid.get_grid(), currents, dt, averages, pmax, cross_section, volume_cell, mr, remains_per_cell, monitoring = True)\n",
    "    # PLOTTING AND SAVING (OPTIONAL)\n",
    "    if(it%saving_period==0 or it == iterations-1): # saving if last iterations too\n",
    "        saver.save(it = it, append = {\n",
    "                        'df' : df,\n",
    "                        'collisions_per_cell' : nb_colls, # evolution of the number of collisions per cell - size : grid.shape[0] x grid.shape[1] (2D)\n",
    "                        'total_distance' : float(monitor[0]), # evolution of the sum of the distance accross all cells \n",
    "                        'total_proba' : float(monitor[1]), # evolution of the sum of proba accross all cells\n",
    "                        'pmax_per_cell' : pmax,  # evolution of the sum of pmax - per cell (2D)\n",
    "                        'total_deleted' : len(idxes_out), # evolution of the number of deleted particles per cell (int)\n",
    "                        'averages_per_cell' : averages,\n",
    "                        'collisions_with_walls' : collisions_with_walls\n",
    "                  })\n",
    "        \n",
    "        # resetting dataframe to not use too much memory\n",
    "        df = pd.DataFrame(columns = ['x','y','vx','vy','vz'])\n",
    "        print('|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|'.format(it, n1, n2, idxes_out.shape[0], c))\n",
    "saver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from src.data import Saver\n",
    "from src.plotting import analysis\n",
    "dir_path = Path('results/')\n",
    "name = 'test_tube.h5'\n",
    "store = pd.HDFStore(dir_path/name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82cee6-1daa-4118-a18c-a7a633abac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_per_cell = store['collisions_per_cell'] \n",
    "df = store['df']\n",
    "pmax_per_cell = store['pmax_per_cell']\n",
    "averages_per_cell = store['averages_per_cell']\n",
    "total_deleted = store['total_deleted']\n",
    "total_distance = store['total_distance']\n",
    "total_proba = store['total_proba']\n",
    "collisions_with_walls = store['collisions_with_walls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d631f6-cd67-4d56-a30e-8f42abdf22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_index = df.index.unique().values\n",
    "nb_save = unique_index.shape[0]\n",
    "iterations = np.max(unique_index)\n",
    "adding_period = unique_index[1]-unique_index[0] # adding period - required to\n",
    "frames = unique_index[int(0.8*nb_save):nb_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892ad3b-7eb7-496d-89ec-60203405e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5fb7d",
   "metadata": {},
   "source": [
    "## Number of particles - evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "analysis.nb_particles_evolution(ax, store['df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a5201-2759-42ba-a8df-fe6eae2e712c",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50fd1de-cd30-4047-a1cd-7c6c27ffeaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "analysis.state(ax, df.loc[df.index == 999], c = None)\n",
    "# analysis.velocity_distribution(df, frames);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fae861-bbf6-4d34-82d6-ac9bdc01dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.spatial_hist2d(df, frames, val = 'vx', x_res = 10, y_res = 1, x_step = 0.001, y_step=0.001);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97277115",
   "metadata": {},
   "source": [
    "## Number of collisions between particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_collisions_per_cell = store['collisions_per_cell']\n",
    "nb_collisions_per_cell = nb_collisions_per_cell.groupby(nb_collisions_per_cell.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(nb_collisions_per_cell) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of collision : \\n', np.sum(nb_collisions_per_cell));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34ee3d-89ad-4719-8c69-e2ab6f2cc0d3",
   "metadata": {},
   "source": [
    "## Number of collisions with walls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea32de-aa38-46ce-a7de-4971356192ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(collisions_with_walls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210b44e",
   "metadata": {},
   "source": [
    "## DSMC - monitoring \n",
    "\n",
    "- proba (over the system - not by cell)\n",
    "- distance between collisioning particles (over the system - not by cell)\n",
    "- average number of particle per cell (by cell)\n",
    "- pmax (by cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = total_proba/nb_collisions_per_cell\n",
    "dist = total_distance/nb_collisions_per_cell\n",
    "print('Mean proba : {:e}'.format(np.mean(proba)))\n",
    "print('Mean distance : {:e} m'.format(np.mean(dist)))\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].plot(proba.index, proba, label = 'proba')\n",
    "ax[1].plot(dist.index, dist, label = 'distance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e53bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmax = pmax_per_cell.groupby(pmax_per_cell.index).sum()\n",
    "averages = averages_per_cell.groupby(averages_per_cell.index).sum()\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].plot(pmax, label = 'proba')\n",
    "ax[1].plot(averages, label = 'averages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f4f7b-9e64-400d-a5b2-164c522040c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speed_norm'] = np.sqrt(df['vx']**2+df['vy']**2+df['vz']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "# plt.style.use('seaborn-pastel')\n",
    "\n",
    "def update_hist(num, df):\n",
    "    #plt.cla() # to clear the current figure\n",
    "    dfit = df.loc[df.index == num]\n",
    "    # since we modifying scat we dont want to use plt.cla\n",
    "    scat.set_offsets(np.c_[dfit['x'],dfit['y']])\n",
    "    # scat.set_array(df['speed_norm'])\n",
    "    # plot_grid(ax, resolutions, system_shape)\n",
    "    ax.set_title('{}/{}'.format(num+1, 1000), fontsize=15)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "dfit = df.loc[df.index == 0]\n",
    "scat = ax.scatter(dfit['x'], dfit['y'], s=0.1, c = dfit['speed_norm'], cmap='seismic') #  c = df['speed_norm']\n",
    "plot_boundaries(ax, segments)\n",
    "# plot_grid(ax, resolutions, system_shape)\n",
    "ax.set_title('{}/{}'.format(1, 1000), fontsize=12)\n",
    "\n",
    "# ax.axis('equal')\n",
    "# ax.set_xlim(x_min, x_max)\n",
    "# ax.set_ylim(y_min, y_max)\n",
    "\n",
    "ax.axis('equal')\n",
    "# min_x, min_y, max_x, max_y = min(df['x']), min(df['y']), max(df['x']), max(df['y'])\n",
    "# ax.set(xlim=(-0.001, 0.011), ylim=(-0.0001, 0.0011))\n",
    "# ax.set(xlim=(0, 0.003), ylim=(0, 0.002))\n",
    "\n",
    "interval = 40 # 25 images per second\n",
    "\n",
    "anim = FuncAnimation(fig, update_hist, interval=interval, frames=1000, fargs=(df, ), save_count=1000)\n",
    "# plt.show()\n",
    "anim.save('system_evo_thruster_test.mp4', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ce723-babc-4290-a33c-bf48409a322e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reactions - collision with walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4b6e3-47fa-4532-95d3-d880127c3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as ld\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fedac-4ed9-4efd-a1ef-941648354c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1.2,3.2,1,2,0], [1.2,3.2,9,1,10], [1.2,3.2,4,6,4], [1.2,3.2,1,2,1]])\n",
    "count = np.array([2, 0, 1, 1])\n",
    "\n",
    "law = lambda part, c : (0.5)**c # part = [x,y,vx,vy,vz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75319879-aeeb-47ea-87d0-7b3e788b24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reacts = ld.advection.reactions.basic(arr, count, law)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d633ef-e1cb-431a-941c-109e565a4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "reacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e77260-455b-489e-bc90-33d933126d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = np.random.random(10)\n",
    "proba = np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a1978-91c3-48c6-a365-7cd83c5e17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(proba>draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82418451-5d16-43ac-804a-44bab452e44a",
   "metadata": {},
   "source": [
    "## Adding reactioons betweeen particles\n",
    "\n",
    "Following this [article](https://doi.org/10.1080/00268976.2019.1602740). The goal is to make a \"background gas\" (made of $[I]$), interacting with it (collisions and reactions) and follow two species : the ion $[I^-]$ and the Iodine $[I]$.\n",
    "\n",
    "To simplify the approach, the background gas will not be updated.\n",
    "\n",
    "What needs to be implemented is :\n",
    "1. The background gas\n",
    "2. The collisions with it\n",
    "3. The potential reactions resulting from these collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05030395-d192-430b-92c2-e876973e9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56f69a-bef6-4707-9707-6d19319ff9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for particle sent ONE by ONE.\n",
    "# which is why its okay doing it this way.\n",
    "\n",
    "class BackgroundGas(object):\n",
    "    # compatible with as many species as we want\n",
    "    # densities - shape : number of species x number of cells\n",
    "    # or : number of cells x number of species (this has the advantage that we are iterating over the cells)\n",
    "    # which would result in better performance most likely.\n",
    "    # this is easy to revert though\n",
    "    \n",
    "    # second question is : how to take into acccount the functional / non functional forms ? (and use the efficiently).\n",
    "    \n",
    "    def __init__(self, densities, velocities, species, diameters, frequency_update = 10):\n",
    "        # we are considering that *number_of_velocities* is the same for every specie, and direction.\n",
    "        self.densities = densities # shape : number of cells x number of species - ndarrays of floats\n",
    "        self.dynamics = velocities # shape : number of cells x number of species x 3 - ndarray of object of type DistributionSampler\n",
    "\n",
    "        self.frequency_update = frequency_update # for now it is not used\n",
    "        self.species_dict = species # e.g. : {'I': 1, 'I-' : 2}\n",
    "        self.diameters = diameters # e.g. : {'I':2e-10, } # in meter\n",
    "\n",
    "    def probability(self, position, species, diameter, vel, dt, approx = None):\n",
    "        density = self.densities[position, self.species_dict[species]]\n",
    "        if(diameter == None):\n",
    "            cross_section = np.pi * self.diameters[self.species_dict[species]]\n",
    "        else:\n",
    "            cross_section = 0.5 * np.pi * (self.diameters[self.species_dict[species]]+diameter)\n",
    "            \n",
    "        if(approx == None):\n",
    "            # to do - a case without approximation\n",
    "            # vel_norm = ...\n",
    "            vr = np.linalg.norm(vel) # this is wrong\n",
    "            pass\n",
    "        elif(approx == 'faster'):\n",
    "            # vr ~ v_particle\n",
    "            vr = np.linalg.norm(vel)\n",
    "            # in this cas, the particle colliding is supposed to be much faster than the backgroung gas\n",
    "        elif(approx == 'slower'):\n",
    "            # vr ~ v_background_gas\n",
    "            vr = self.dynamics[position, self.species_dict[species]].mean_speed()\n",
    "        elif(approx == 'equal'):\n",
    "            # vr = vr_background_gas\n",
    "            vr = self.dynamics[position, self.species_dict[species]].mean_relative_speed()\n",
    "\n",
    "        return self.proba_collision(density, cross_section, vr, dt)\n",
    "    \n",
    "    # probability of collision with each gaz \n",
    "    def proba_collision(self, density, cross_section, vr, dt): # the one used in the article by Schullian - it is an approximation though (for small values of V)\n",
    "        return density * cross_section * vr * dt\n",
    "    \n",
    "    def update(self):\n",
    "        # should update each distribution, and the proba computed with those\n",
    "        pass\n",
    "    \n",
    "class DistributionSampler(object):\n",
    "    \n",
    "    def __init__(self, params, functional = True):\n",
    "        \n",
    "        self.params = params\n",
    "        self.functional = functional\n",
    "        if(functional):\n",
    "            self.random_variates = self.params\n",
    "        else:\n",
    "            self.current = 0\n",
    "            self.number_of_samples = self.params.shape[0]\n",
    "            self.random_variates = lambda size : np.choice(self.params, size=size, replace=True, p=None) # self.params should be 1D, if not this function should fails\n",
    "        \n",
    "    def draw(self, size = 1):\n",
    "        return self.random_variates(size)\n",
    "    \n",
    "    def update(self, new):\n",
    "        if(self.functional):\n",
    "            print(\"You cannot update a distribution which was given in a functional form.\")\n",
    "        else:\n",
    "            # replacing the k \"older\" ones by k more recent ones ; k = new_params.shape[0]\n",
    "            next_current = self.current + new.shape[0]\n",
    "            if(next_current > self.number_of_samples):\n",
    "                self.params[self.current:] = new[:self.number_of_samples-self.current]\n",
    "                next_current %= self.number_of_samples\n",
    "                self.params[:next_current] = new[self.number_of_samples-self.current:]\n",
    "            else:\n",
    "                self.params[self.current:next_current] = new\n",
    "                \n",
    "            self.current = next_current%self.number_of_samples\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b27d0a-3b4a-4345-a709-83ab7f4f3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a grid of 3 cells\n",
    "# we will make 4 distributions basically\n",
    "# considering it the same for vy, vz, for all cells\n",
    "# and that there is a different drift added in each cell along vx\n",
    "vx_distrib_form = lambda drift, std : (lambda size: np.random.normal(loc = drift, scale = std, size=size))\n",
    "vx1_distrib = DistributionSampler(params = vx_distrib_form(100, 200))\n",
    "vx2_distrib = DistributionSampler(params = vx_distrib_form(120, 200))\n",
    "vx3_distrib = DistributionSampler(params = vx_distrib_form(110, 200))\n",
    "vyz_distrib = DistributionSampler(params = vx_distrib_form(0, 200))\n",
    "densities = np.array([[3.2e19],[3.0e19],[2.5e19]], dtype = float)\n",
    "velocities = np.array([[vx1_distrib,vyz_distrib,vyz_distrib],[vx2_distrib,vyz_distrib,vyz_distrib],[vx2_distrib,vyz_distrib,vyz_distrib]], dtype = DistributionSampler)\n",
    "species = ['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54250d95-d7a6-4c95-8b00-7d279cb6b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_gas = BackgroundGas(densities = densities, velocities = velocities, species = species) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb7933-fa25-433e-8101-cfa1b54fd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBABILITY OF COLLISION\n",
    "\n",
    "def proba_approx(density, v1, cross_section, dt): # in our case, we will suppose relative velocity ~ v1 (because the ion is much much faster than the background gas)\n",
    "    return density*np.linalg.norm(v1)*cross_section*dt # proba that the particle collided with the slow background gas of density *density*.\n",
    "\n",
    "def proba(v1, v2, cross_section, cell_volume, dt):\n",
    "    return np.linalg.norm(v2-v1)*cross_section*dt/cell_volume\n",
    "\n",
    "def proba_gas(density, mean_speed_times_cross_section, dt): # the one used in the article by Schullian\n",
    "    return density * mean_speed_times_cross_section * dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea29581-ad01-4ac2-b668-214ca109c450",
   "metadata": {},
   "source": [
    "# Reactions with walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036c1797-4e08-43e3-b534-26c20c65c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc.advection.reactions as reactions\n",
    "import lppydsmc as ld\n",
    "path = 'walls_reactions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda7fadc-df3f-46a6-9856-1a83d813dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-': {'#': 1, 'reactants': ['I-'], 1: ['I']}, 'I2': {'#': 3, 'reactants': ['I2'], 1: ['I', 'I'], 2: ['I-', 'I+'], 3: ['I+', 'I']}}\n"
     ]
    }
   ],
   "source": [
    "print(reactions.parse_file(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cbfaf2f-3ac0-407e-971c-8459c0b279c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def p(size):\n",
    "    proba = np.random.uniform(low=0.0, high=1.0, size = size)\n",
    "    return (proba*p_+1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4613a2c4-4ea4-4368-b5b8-5cdf285f1839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ = 1\n",
    "p(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d342a4-a34d-4a8c-8933-cb3620b7d2a5",
   "metadata": {},
   "source": [
    "## testing reactions functions - with walls to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e677b96f-16eb-45f7-9222-3f0f6cb96c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_reacting_particles = np.array([[1]], dtype = int)\n",
    "\n",
    "arr1 = np.array([[0,0,3,4,0],[0,0,0,-4,0,]])\n",
    "arr2 = np.array([[0,0,2,3,0],[0,0,-1,17,9,]])\n",
    "arrays = [arr1, arr2]\n",
    "\n",
    "masses = np.array([1,2], dtype = float)\n",
    "\n",
    "types_dict = {\n",
    "    'I' : 0,\n",
    "    'I-' : 1\n",
    "}\n",
    "\n",
    "reactions_list = [\n",
    "    'I- : I'\n",
    "]\n",
    "nb_species = 2\n",
    "types = ['I', 'I-']\n",
    "reactions_dict = reactions.parse(reactions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72a2498a-a751-4281-af7d-044a37365a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "reacting_particles, particles_to_add = ld.advection.reactions.react(idx_reacting_particles, arrays, masses, types_dict, reactions_dict['I-'], p = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ca1c9c8-e8f1-4f59-aad5-089be43f2446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-': {'#': 1, 'reactants': ['I-'], 1: ['I']}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reactions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "123a7350-277f-4521-af6f-73f76d8f06ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reacting_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d188d3f5-dccb-4246-a366-d4d34d435f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': [array([-2., 34., 18.])]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particles_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d136815-1853-42cf-9f44-10832af4cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_counts = [np.array([]), reacting_particles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d545c4b0-37fd-4cfe-a814-ffc37ef0d2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE\n",
      "I - 0\n",
      "Deleting 0 particles of type I\n",
      "ADDING - I - 1\n",
      "I- - 1\n",
      "Deleting 1 particles of type I-\n"
     ]
    }
   ],
   "source": [
    "# print(f'Total collision with walls: {collisions_with_walls}')\n",
    "print('DELETE')\n",
    "for k in range(nb_species): # here it's only one particle as it is colliding with the wall\n",
    "    # thus it is easier to delete\n",
    "    print('{} - {}'.format(types[k], list_counts[k].shape[0]))\n",
    "    print(f'Deleting {len(list_counts[k])} particles of type {types[k]}')\n",
    "    # containers[k].delete_multiple(list_counts[k])\n",
    "    if(types[k] in particles_to_add):\n",
    "        print('ADDING - {} - {}'.format(types[k], len(particles_to_add[types[k]])))\n",
    "        # containers[k].add_multiple(np.array(particles_to_add[types[k]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b64af-1f4b-4565-8b02-eb77525dc14e",
   "metadata": {},
   "source": [
    "### Cfg - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729c68a3-1eff-4c22-9b52-7cee94a19afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as ld\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d407586-d0cd-4515-81dd-8df17b14ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_cfg = \"lppydsmc/config/example.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbef70d-4285-4c62-8633-c3cc2fbb1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ld.config.cfg_reader.read(path_to_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a8ebd-7450-4cc9-a993-6f5e665990de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(config.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29de3d7-e6ca-4ad7-9c94-6d7c90d1c93b",
   "metadata": {},
   "source": [
    "## Testing cfg run module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26640281-f2af-48ca-aef4-f0eb636abdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as ld\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbd5a4-8d7a-436e-9098-ed8f5fd7fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_cfg = \"lppydsmc/config/example.ini\"\n",
    "params = ld.run.run(path_to_cfg, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b966bb-551a-406d-9a97-299be03fb35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container filled at 5 x 345/18000 - Particle I : m = 2.160e-25 kg - q = 0.000e+00 C, r = 2.000e-10 m, cs = 5.027e-19 m2\n",
      "Container filled at 5 x 175/18000 - Particle I2 : m = 4.320e-25 kg - q = 0.000e+00 C, r = 2.660e-10 m, cs = 8.891e-19 m2\n",
      "Container filled at 5 x 3/162 - Particle I- : m = 2.160e-25 kg - q = -1.600e-19 C, r = 2.000e-10 m, cs = 5.027e-19 m2\n",
      "Container filled at 5 x 4/180 - Particle I+ : m = 2.160e-25 kg - q = 1.600e-19 C, r = 2.000e-10 m, cs = 5.027e-19 m2\n",
      "Container filled at 5 x 0/18 - Particle e- : m = 9.000e-31 kg - q = -1.600e-19 C, r = 2.800e-15 m, cs = 9.852e-29 m2\n"
     ]
    }
   ],
   "source": [
    "for key, val in params['setup']['containers'].items():\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaaeebda-d626-483b-b1a6-c3a0392fbe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/calot/Documents/projets/lppydsmc/results/cfg_tests/example/monitoring.h5\n"
     ]
    }
   ],
   "source": [
    "# quick analysis - just loading the hdf5\n",
    "path = params['setup']['path']/'monitoring.h5'\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8088c94f-32e3-40b4-9749-aad744ca8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "133436b6-d9f8-4e08-a9b7-b4e6c9601d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/dsmc_collisions',\n",
       " '/dsmc_tracking',\n",
       " '/fluxes',\n",
       " '/out_particles',\n",
       " '/particles',\n",
       " '/wall_collisions']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c526faf5-201d-454b-a2ce-526bb2269223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>160.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>88.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            in   out\n",
       "species             \n",
       "0.0      160.0  21.0\n",
       "1.0       88.0  24.0\n",
       "2.0        0.0   0.0\n",
       "3.0       12.0   0.0\n",
       "4.0        0.0   0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['fluxes'].groupby('species').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ac40ec3-a4a5-479b-92c2-692e99ad3936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90720.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['dsmc_collisions']['quantity'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34958d9c-7ddc-4e2e-8e65-3e0344001439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x   y  vx  vy  vz\n",
       "species                    \n",
       "0.0      21  21  21  21  21\n",
       "1.0      24  24  24  24  24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['out_particles'].groupby('species').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7b8f4-3439-4ce2-a6f1-9dd32ff88994",
   "metadata": {},
   "source": [
    "# Computing an approximation of a given volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39645a96-27b4-41ea-b694-8a05de6e1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "import lppydsmc as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "253eae00-c19f-453d-ad5f-8c216894c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([(0,0),(0,1),(1,2),(1,0)])\n",
    "samples = [10,100,1000,int(1e4),int(1e5), int(1e6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1df7bb-132e-41ba-83aa-1f93adebb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples :\n",
    "    t1 = time()\n",
    "    print(ld.utils.estimation.estimate_surface(sample, points)) \n",
    "    # works but it is pretty slow - I should see for reusing my algorithms which are vectorized and kind of optimized already\n",
    "    print('Time : {} s'.format(time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4e215-4997-4966-bea8-22d8a9626600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fe12c-6121-4ad5-9478-a24ad375ea2b",
   "metadata": {},
   "source": [
    "# Tests with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ced2a7-6e90-428e-9fc4-74484a985cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a0134a-978c-41f9-9f17-ed0b5f3934df",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros((2,3))\n",
    "inject = np.array([10,23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76d494f-34d5-42da-a710-58bc850af66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[:,0] = inject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f21b60-7d1e-4b3d-af94-d354b7ece6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.,  0.,  0.],\n",
       "       [23.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa10fd7-a3ca-4f3b-8a8d-a873a5d8a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3040bf0-03d5-446e-a478-cd5745e6e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "debits = np.array([1.108301380e8, 2.13390831e8, 1.10397103987e9])\n",
    "remains = np.array([0.9, 0.85, 0.2])\n",
    "dt = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e41f3bb-9056-45b7-8cc7-4b3ed2a2cab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.20138  , 0.75831  , 0.9103987]), array([ 1109,  2134, 11039]))\n"
     ]
    }
   ],
   "source": [
    "print(ld.injection.get_quantity(debits, remains, dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72626f40-35f3-4705-8a2c-231401afa122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1108.30138  ,  2133.90831  , 11039.7103987])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debits*dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "375358ce-2b36-4c31-aaef-1d693c144303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject(remains, debits, dt):\n",
    "    remains[:], inject_qties = ld.injection.get_quantity(debits, remains, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a777e7b8-4f81-4bbb-ac7d-6c89b05627eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20138   0.75831   0.9103987]\n",
      "[0.50276   0.66662   0.6207974]\n"
     ]
    }
   ],
   "source": [
    "print(remains)\n",
    "inject(remains, debits, dt)\n",
    "print(remains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0afdea8b-f043-4e49-a988-4dd873f96233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5, 649],\n",
       "       [702, 705],\n",
       "       [889, 136],\n",
       "       [162, 951],\n",
       "       [153,  93],\n",
       "       [568, 631],\n",
       "       [896, 458],\n",
       "       [954, 130],\n",
       "       [444,  91],\n",
       "       [820, 773]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.collision.collider.index_choosen_couples(1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8728f142-1178-44ea-b5f9-da871fc75340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_np(X, groups, axis = 0, uf = np.add, out = None, minlength = 0, identity = None):\n",
    "    if minlength < groups.max() + 1:\n",
    "        minlength = groups.max() + 1\n",
    "    if identity is None:\n",
    "        identity = uf.identity\n",
    "    i = list(range(X.ndim))\n",
    "    del i[axis]\n",
    "    i = tuple(i)\n",
    "    n = out is None\n",
    "    if n:\n",
    "        if identity is None:  # fallback to loops over 0-index for identity\n",
    "            assert np.all(np.in1d(np.arange(minlength), groups)), \"No valid identity for unassinged groups\"\n",
    "            s = [slice(None)] * X.ndim\n",
    "            for i_ in i:\n",
    "                s[i_] = 0\n",
    "            out = np.array([uf.reduce(X[tuple(s)][groups == i]) for i in range(minlength)])\n",
    "        else:\n",
    "            out = np.full((minlength,), identity, dtype = X.dtype)\n",
    "    uf.at(out, groups, uf.reduce(X, i))\n",
    "    if n:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9031f592-8b7c-4d48-90da-914b5e364624",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_species = 3\n",
    "arr = np.array([[[0,103],[1,20]],[[0,1],[0,13]],[[1,4411],[2,94]],[[2,4411],[0,94]],[[2,4411],[2,94]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dca21d57-a36b-4414-bb6a-d50f082eb048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "545649c4-bc82-449c-a263-35cfafc66a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      0,       0,       0,       1,  829268, 1658536])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_np(X = arr, groups = np.array([1,0,4,2,5]), axis = 0, uf = np.multiply, out = None, minlength = 0, identity = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9dba078-3636-4479-b99d-40980437f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = (arr[:,0,0]*nb_species+arr[:,1,0]) # you would have to sort first !!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c3372bd-38c1-4805-a647-2fce53a643f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 5, 6, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2406dddb-211e-4b5b-9acb-2778b9b0fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad971922-ce05-4599-bcea-0772c7fa05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first function\n",
    "# grouping like we want to \n",
    "# not something generic\n",
    "\n",
    "def groups_1(arr, nb_species): # with the loops\n",
    "    groups = np.zeros(arr.shape[0])\n",
    "    for k, a in enumerate(arr):\n",
    "        c1, c2 = arr[0][0], arr[0][1]\n",
    "        if(c1>c2):\n",
    "            groups[k] = c1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf3756ed-725d-41d7-8db1-432512b4d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_species = 10\n",
    "groups = np.zeros((nb_species, nb_species))\n",
    "count = 0\n",
    "for i in range(nb_species):\n",
    "    for j in range(i, nb_species):\n",
    "        groups[i,j] = count\n",
    "        groups[j,i] = count\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18d895dd-e8f9-4f27-95a4-e0f094b954ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
       "       [ 1., 10., 11., 12., 13., 14., 15., 16., 17., 18.],\n",
       "       [ 2., 11., 19., 20., 21., 22., 23., 24., 25., 26.],\n",
       "       [ 3., 12., 20., 27., 28., 29., 30., 31., 32., 33.],\n",
       "       [ 4., 13., 21., 28., 34., 35., 36., 37., 38., 39.],\n",
       "       [ 5., 14., 22., 29., 35., 40., 41., 42., 43., 44.],\n",
       "       [ 6., 15., 23., 30., 36., 41., 45., 46., 47., 48.],\n",
       "       [ 7., 16., 24., 31., 37., 42., 46., 49., 50., 51.],\n",
       "       [ 8., 17., 25., 32., 38., 43., 47., 50., 52., 53.],\n",
       "       [ 9., 18., 26., 33., 39., 44., 48., 51., 53., 54.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0a65798-d93b-405a-be38-cf83e61b16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_groups(n):\n",
    "    groups = np.zeros((n, n))\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            groups[i,j] = count\n",
    "            groups[j,i] = count\n",
    "            count +=1\n",
    "    return groups\n",
    "\n",
    "# now we want a function that returns the group from the array\n",
    "def get_groups(arr, groups):\n",
    "    return groups[arr[:,0,0],arr[:,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ff71157-919d-4ea0-ad93-be9f1fd889cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "groups = set_groups(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d351e206-1a89-4664-b5b5-4f75b614f5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 4, 2, 5])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_groups(arr, groups).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835cfc1f-0c29-4261-90e9-77614adda84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = numpy.unique(a, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25f2d106-a25d-4c3c-867e-65efa261f7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 22 23 24 26 29]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "nb_groups = 10\n",
    "unique =  np.array([0,2,3,4,6,9])\n",
    "print(idx*nb_groups+unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c20da-c594-41df-88ac-2ad357fe0e73",
   "metadata": {},
   "source": [
    "# Testing on pandas datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6c5668-93c5-4f20-9e31-b7503e8681b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df705c25-c12c-4390-b873-a1e593862062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Index(['1', '2', '3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['1','2','3'])\n",
    "print(type(df)==pd.DataFrame)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af522cf-ae80-4c47-90d5-f498505e844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1  2  3\n",
      "2930  1  2  3\n",
      "2930  4  5  6\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1,2,3],[4,5,6]])\n",
    "iteration = 2930\n",
    "df = df.append(pd.DataFrame(data = arr, index = [iteration]*arr.shape[0], columns = ['1','2','3']))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f5e07a-7023-4605-8809-db2000926000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.DataFrame(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50843b51-b732-4b9e-9855-baf7c0061c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1e9b8bc-85bf-449c-8a86-60afbf16bcea",
   "metadata": {},
   "source": [
    "# Angles issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b224d82a-f2c9-4393-8089-6732daa5cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# both arctan and arctan2 returns pi/2 (or -pi/2) for input = np.inf.\n",
    "# wall\n",
    "wall = np.array([1,0,1,1]) # vertical wall at x = 1, of lenght 1\n",
    "directing_vector = np.array([0,1])\n",
    "cTheta, sTheta = directing_vector[0], directing_vector[1]\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    theta = np.arctan(np.divide(directing_vector[1],directing_vector[0])) # does not need arctan2 since we are in the 1st and 4th quadrants\n",
    "\n",
    "# velocity\n",
    "v = np.array((1.,1.,-1.), dtype = float)\n",
    "norm = np.linalg.norm(v)\n",
    "#with np.errstate(divide='ignore', invalid='ignore'):\n",
    "a = np.arctan2(v[1], v[0]) # arctan2 will not return an error if dividing by zeros. \n",
    "b = np.arctan2(v[2], v[0])\n",
    "# with atan2, both returned angle are in [-pi, pi]\n",
    "# in theory we would need only this for one of the two, so maybe we could go from arctan2 -> arctan on b which would be in [-pi/2, pi/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a84e1950-7721-4c5a-9f25-19bb8d4b3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_a = a-theta\n",
    "new_b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9038e301-984e-47a5-82fc-9a0a7ab64744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.ones((10,3))\n",
    "x = np.zeros((10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dcb9dfc-6281-4d50-803b-9746d050e7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11153fd2-e819-42c8-a94d-a40d8af78ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_wall = 30 # m/s\n",
    "def reflect_fn(arr, idxes_walls, a, ct, cp): # _specular\n",
    "    k1, k2 = 2*a[:,0]**2-1, 2*a[:,0]*a[:, 1]\n",
    "\n",
    "    # velocity after the collision\n",
    "    arr[:,2] = arr[:,2]*k1+ arr[:,3]*k2   # i.e. : vx = vx*k1+vy*k2\n",
    "    arr[:,3] = - arr[:,3]*k1+arr[:,2]*k2  # i.e. : vy = -vy*k1+vx*k2\n",
    "\n",
    "    # new position (we could add some scattering which we do not do there)\n",
    "    arr[:,0] = cp[:,0]+ct*arr[:,2] # new x pos \n",
    "    arr[:,1] = cp[:,1]+ct*arr[:,3] # new y pos\n",
    "    \n",
    "    # then we add a given drift to all particles that collided with walls 1 (since this is the top wall)\n",
    "    top_wall_idxes = np.where(idxes_walls == 1)[0]\n",
    "    arr[top_wall_idxes,0] = arr[top_wall_idxes,0] + drift_wall # in place\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d95e899-31df-4684-bdca-04231020b8c7",
   "metadata": {},
   "source": [
    "# Trying benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46f0c58-c419-4fab-a086-9d4711708b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725754b0-f1cb-4369-92e4-d04bca880a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as ld\n",
    "from pprint import pprint\n",
    "# cfg_path = 'benchmarks/couette.ini'\n",
    "# cfg_path = 'benchmarks/couette.ini'\n",
    "cfg_path = 'benchmarks/simple_tube.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91d6bb-0060-4c2d-a381-fd384ce991d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = ld.config.cfg_reader.read(cfg_path)\n",
    "params = ld.run(cfg_path, save = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8160761-480e-4c53-a0a5-fcfe3145a5b5",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e26dde2-e99d-4a56-833e-b307ae581363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_evolution(data, mass):\n",
    "    from lppydsmc.utils.physics import BOLTZMAN_CONSTANT\n",
    "    # speed norm\n",
    "    data['v2'] = data['vx']*data['vx']+data['vy']*data['vy']+data['vz']*data['vz']\n",
    "    data['v'] = np.sqrt(data['v2'])\n",
    "\n",
    "    # drift \n",
    "    v_mean = data.groupby(data.index).mean()\n",
    "    v_mean['drift2'] = v_mean['vx']*v_mean['vx']+v_mean['vy']*v_mean['vy']+v_mean['vz']*v_mean['vz']\n",
    "    v_mean['drift'] = np.sqrt(v_mean['drift2'])\n",
    "\n",
    "    # 3/2 k T = 1/2 m (<v²>-|<v>|²)\n",
    "    temperature = mass/(3.*BOLTZMAN_CONSTANT)*(v_mean['v2']-v_mean['drift2'])\n",
    "    # temperature = mass/(3.*BOLTZMAN_CONSTANT)*((v_mean['v']-v_mean['drift'])**2)\n",
    "\n",
    "    return temperature\n",
    "\n",
    "def variance_speed_evolution(data):\n",
    "    data['v2'] = data['vx']*data['vx']+data['vy']*data['vy']+data['vz']*data['vz']\n",
    "    data['v'] = np.sqrt(data['v2'])\n",
    "    data_var = data.groupby(data.index).var()\n",
    "    return data_var['v']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3956f85-42eb-498a-aaf6-f92de873d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/dsmc_collisions', '/dsmc_tracking', '/particles', '/wall_collisions']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "results_path = 'results/benchmarks/couette/monitoring.h5'\n",
    "store = pd.HDFStore(results_path)\n",
    "print(store.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "134f4919-0f3e-4569-b75e-150911b1ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1e-7\n",
    "dy = 2.5e-5\n",
    "dx = 2.5e-5\n",
    "dz = 1e-3\n",
    "particles_weight = 12500000000 # 6400000000\n",
    "nb_cells = 40\n",
    "# nb_particles_simu = 10000\n",
    "mass = 2.16e-25 # kg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c6dbd9-d3e5-4acf-af61-65503eb1b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = store['particles']\n",
    "indexes = np.unique(particles.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e2566b0-7f8f-49d4-bc44-63525c3e0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_evo = temperature_evolution(particles, mass)\n",
    "speed_var = variance_speed_evolution(particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3882317c-56ab-4b2f-b414-d4e4edda05d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbba12274054da8ba4743ecccbd994f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, constrained_layout = True)\n",
    "ax[0].plot(indexes*dt, temp_evo)\n",
    "ax[1].plot(indexes*dt, speed_var);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79805ddd-e82d-4e45-8ee2-518273c204bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b8315ed1ec4998b495aaa53a156581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = 3000\n",
    "bins = 50\n",
    "frame_df = particles.loc[particles.index == frame]\n",
    "fig, ax = plt.subplots(2,2, constrained_layout = True)\n",
    "ax[0,0].hist(frame_df['vx'],bins = bins,  color = 'r')\n",
    "ax[0,1].hist(frame_df['vy'],bins = bins,  color = 'g')\n",
    "ax[1,0].hist(frame_df['vz'],bins = bins,  color = 'b')\n",
    "ax[1,1].hist(frame_df['v'], bins = bins, color = 'k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0121cb0-dd43-45b8-95ce-c07ffda7e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles['idx_cell'] = (particles['y']/dy).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c993675-91ef-44d2-9fbc-31b731072371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afb05466ff24768b0d546497c4ba4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa6857e49d0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_count = particles.groupby('idx_cell').count()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(groups_count['v']/(dx*dy*dz*indexes.shape[0])*particles_weight, groups.index*dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1febe5da-88c7-4d01-a229-24ac74ddb713",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = particles.groupby('idx_cell').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80c40e-5a97-4661-bf0f-0d1b9ec216e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f025f6c-2af0-4b0c-9187-736b4ad3301a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b7a7bdf9c34f8bbab3bcadf01a6d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa6859f9610>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(groups['v'], groups.index*dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44590611-bea7-45b5-94ae-404577e7e760",
   "metadata": {},
   "source": [
    "# Choosing your simulations values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31db956f-11a3-4ea9-965d-f110c4719041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_iterations(time_step_factor, target_accuracy, temperature, mass, caracteristic_speed, discretization_factor, total_number_particles):\n",
    "    kb = 1.38e-23 \n",
    "    return (time_step_factor*kb*temperature*total_number_particles)/(target_accuracy**2*mass*caracteristic_speed**2*total_number_particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc41e9cf-3282-41a0-b682-cd4bb6ae4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_factor = 4\n",
    "target_accuracy = 5e-2\n",
    "temperature = 300 # K\n",
    "mass = 2.16e-25 # kg \n",
    "caracteristic_speed = np.linspace(1, 200, 200) \n",
    "mean_particle_per_cell = 100\n",
    "nb_cells_x = 1\n",
    "nb_cells_y = 40\n",
    "discretization_factor = 40 # at leqst the number of cells\n",
    "total_number_particles = nb_cells_x*nb_cells_y*mean_particle_per_cell # at least nb_cells_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a7323013-f893-4aec-ac4c-fb2beaade1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = minimum_iterations(time_step_factor, target_accuracy, temperature, mass, caracteristic_speed, discretization_factor, total_number_particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "82e525f8-51af-437a-9d09-7483473ee20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d88c2aefa64bee8f7430aadbaa7a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "ax.plot(caracteristic_speed, iterations);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68f284af-5d7e-4081-93fe-edccd4b343b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3066.6666666666665"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d486f-cbd4-4f6f-b6eb-cdde2b8b6895",
   "metadata": {},
   "source": [
    "# Energie d'une loi unforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f02677cd-cfe7-4a5d-afd9-ae3e6678d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# maxwellienne \n",
    "temperature = 300 # K\n",
    "kb = 1.38e-23\n",
    "nrj_maxwellian = 3/2*kb*temperature # J "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af3e71bb-3b29-4bca-8468-7e19e43384f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a uniform law\n",
    "u_arr = np.linspace(1, 1000, 100)\n",
    "mass = 2.16e-25 # kg \n",
    "\n",
    "def get_nrj_uniform_distrib(mass, u, dimensions = 1, nb_samples = int(1e5)):\n",
    "    list_U = np.zeros((nb_samples, dimensions))\n",
    "    for k in range(dimensions):\n",
    "        list_U[:,k] = np.random.uniform(low = -u, high = u, size = nb_samples)\n",
    "    \n",
    "    U2 = np.linalg.norm(list_U, axis = 1)**2\n",
    "    return 0.5*mass*np.mean(U2)\n",
    "\n",
    "nrjs_uniform_1D = np.array([get_nrj_uniform_distrib(mass, u) for u in u_arr]) # 414 in 1D\n",
    "nrjs_uniform_3D = np.array([get_nrj_uniform_distrib(mass, u, dimensions = 3) for u in u_arr]) # 239,7 in 3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "13cc4255-28d7-4a80-9875-534d1e65a8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdcaf9a989044ba8ca2e7204bd99ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.axhline(y=nrj_maxwellian)\n",
    "ax.plot(u_arr, nrjs_uniform_1D,'r');\n",
    "ax.plot(u_arr, nrjs_uniform_3D,'g');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1738951-1778-49e5-b784-afc59dc033aa",
   "metadata": {},
   "source": [
    "# Diffusive boundary conditions\n",
    "It seems to work fine. Sure the temperature is a little low (but this is because there is a \"drift\"), I think the injection is working.\n",
    "\n",
    "I am going to test for injection this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e234ea-cb10-4356-a2d0-feeb8813526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as ld\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de248c11-2ea9-4d81-a992-55bd97712b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation : 1.372e+02 m/s\n",
      "{'temperature': 300, 'mass': 2.2e-25, 'normal_vectors': array([[ 0, -1],\n",
      "       [ 0, -1],\n",
      "       [ 0, -1],\n",
      "       ...,\n",
      "       [ 0, -1],\n",
      "       [ 0, -1],\n",
      "       [ 0, -1]]), 'ct': array([1., 1., 1., ..., 1., 1., 1.]), 'cp': array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]]), 'tangent_drift': 100}\n"
     ]
    }
   ],
   "source": [
    "# arr = np.array([[0,0,1,1,1],[0,0,1,1,1],[0,0,1,1,1],[0,0,1,1,1],[0,0,1,1,1]]) # particles\n",
    "arr = np.zeros((int(1e6),5))\n",
    "mass = 2.2e-25\n",
    "temperature = 300\n",
    "print('Standard deviation : {:.3e} m/s'.format(ld.utils.physics.gaussian(temperature, mass)))\n",
    "kwargs = {\n",
    "    'temperature': temperature,\n",
    "    'mass' : mass,\n",
    "    'normal_vectors' : np.array([[0,-1]]*arr.shape[0]),\n",
    "    'ct' : np.ones(arr.shape[0]),\n",
    "    'cp' : np.zeros((arr.shape[0],2)),\n",
    "    'tangent_drift' : 100,\n",
    "}\n",
    "\n",
    "print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6e11387-644e-4bfd-a92b-c019c846de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_reflected = ld.advection.boundaries._reflect_particle_diffusive(arr, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d5882db-e94e-4364-8664-2918c8d17b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift : [ 9.98759192e+01 -1.71826264e+02 -3.47353853e-03] m/s\n",
      "Local temperature : 2.427e+02 K\n",
      "Standard deviation on the gaussian : 1.371e+02 m/s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fe1bc009844938badda4af60c5e788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bins = 200\n",
    "velocity = arr_reflected[:,[2,3,4]]\n",
    "v = np.linalg.norm(velocity, axis = 1)\n",
    "drift = np.mean(velocity, axis = 0)\n",
    "drift_norm = np.linalg.norm(drift)\n",
    "kb = ld.utils.physics.BOLTZMAN_CONSTANT\n",
    "print('Drift : {} m/s'.format(drift))\n",
    "print(\"Local temperature : {:.3e} K\".format((np.mean(v*v)-drift_norm*drift_norm)*mass/(kb*3)))\n",
    "print('Standard deviation on the gaussian : {:.3e} m/s'.format(np.std(arr_reflected[:,4])))\n",
    "fig, ax = plt.subplots(2,2,constrained_layout = True)\n",
    "ax[0,0].hist(arr_reflected[:,2], label = 'vx', color = 'r', bins = bins)\n",
    "ax[0,1].hist(arr_reflected[:,3], label = 'vy', color = 'g', bins = bins)\n",
    "ax[1,0].hist(arr_reflected[:,4], label = 'vz', color = 'b', bins = bins)\n",
    "ax[1,1].hist(v, label = 'v', color = 'k' ,bins = bins);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ac3d0-a7fe-4c1d-8b1a-492aadcbd530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
