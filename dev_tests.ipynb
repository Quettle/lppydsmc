{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f5d244-2fbf-49c0-8ab0-15689d05a38c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d7ee75957376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'widget'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.utils import is_notebook\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-christian",
   "metadata": {},
   "source": [
    "# Module Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa58db60-ce2b-4218-8236-04fecfd75e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src.plotting import plot_boundaries, plot_particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-accident",
   "metadata": {},
   "source": [
    "## System creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "from src.system_creator import SystemCreator\n",
    "\n",
    "# Tube creation :\n",
    "tube_segments = 0.001*np.array([[0,0,10,0], [0,0,0,1], [10,0,10,1], [0,1,10,1]])\n",
    "tube = SystemCreator(tube_segments)\n",
    "\n",
    "offsets = tube.get_offsets()\n",
    "system_shape = tube.system_shape()\n",
    "a = tube.get_dir_vects()\n",
    "\n",
    "print(f'Tube : \\noffsets : {offsets}')\n",
    "print(f'System size : {system_shape} \\n')\n",
    "\n",
    "# Cylinder\n",
    "circle = [[5+np.cos(k*np.pi/8), 5+np.sin(k*np.pi/8), 5+np.cos((k+1)*np.pi/8), 5+np.sin((k+1)*np.pi/8)] for k in range(16)]\n",
    "cylinder_segments = 0.001*np.array([[0,0,10,0], [0,0,0,10], [10,0,10,10], [0,10,10,10]]+circle)\n",
    "cylinder = SystemCreator(cylinder_segments)\n",
    "\n",
    "print(f'Cylinder : \\noffsets : {cylinder.get_offsets()}')\n",
    "print(f'System size : {cylinder.system_shape()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots();\n",
    "plot_boundaries(ax, tube_segments);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, cylinder_segments)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-impact",
   "metadata": {},
   "source": [
    "## Particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Particle, get_mass_part\n",
    "\n",
    "# Iodine\n",
    "container = Particle('I', 0, get_mass_part(53, 53, 74), radius = 2e-10, size_array = 10000)\n",
    "N = 500\n",
    "arr =  np.random.random((N,5))\n",
    "print(f'mass, charge, radius, cross-section = {container.get_params()}'); # mass, charge, radius, cross-section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "container.add_multiple(arr)\n",
    "print(container.get_current())\n",
    "print(container.get_particles().shape)\n",
    "print(container.arr.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of particles : {container.get_current()}')\n",
    "for k in range(3):\n",
    "    container.add_multiple(np.random.random((1000,5)))\n",
    "    print(f'Number of particles : {container.get_current()}')\n",
    "    container.delete_multiple(np.random.choice(a = container.get_current(), size = 500, replace = False))\n",
    "    print(f'Number of particles : {container.get_current()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : make 'dynamic' arrays (when increasing the size).\n",
    "container.add_multiple(np.random.random((3000,5)))\n",
    "print(f'Number of particles : {container.get_current()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-library",
   "metadata": {},
   "source": [
    "**Conclusion**  : make 'dynamic' array (can increase time, but not decrease it for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-hollow",
   "metadata": {},
   "source": [
    "## Grid\n",
    "For now : 2D-ndarray with value of type *ndarray* which are 2D.\n",
    "```python\n",
    "# grid[x_int, y_int] is the container for a cell\n",
    "# grid[x_int, y_int][idx] contains the particle indexes\n",
    "grid[x_int, y_int][idx] = [idx_container, idx_particle_in_container]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Grid, pos_in_grid\n",
    "resolutions = np.array([4,4])\n",
    "max_number_per_cell = 10 # to initialize the array which will contain the particles indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid(resolutions, max_number_per_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, vx, vy, vz\n",
    "arr = np.array([[-1.5,1.2,1,0,0], [-1.3,-0.8,0,-1,0], [1.3,-0.5,-1,0,0], [1,1,-1,-1,-1], [-1,1,1,0,0]])\n",
    "print(arr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signature : pos_in_grid(pos, grid_res, offsets, system_shape)\n",
    "pos = pos_in_grid(arr[:,:2], resolutions, offsets = np.array([-2, -2]), system_shape = np.array([4,4])) # not inplace\n",
    "print(pos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [pos_x, pos_y, idx_container, idx_particle_in_container]\n",
    "idx_container = np.array([0,0,0,0,0])\n",
    "idx_particle_in_container = np.array([0,1,2,3,4])\n",
    "idxes = np.stack((idx_container, idx_particle_in_container), axis = 1)\n",
    "new_arr = np.concatenate((pos, idxes), axis = 1)\n",
    "print(new_arr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.reset()\n",
    "grid.add_multiple(new_arr)\n",
    "print(grid.current);\n",
    "print(grid.get([0,1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : delete multiple\n",
    "grid.delete([0,1], 0) # can still take lots of time\n",
    "print(grid.current);\n",
    "print(grid.get([0,1]));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-laptop",
   "metadata": {},
   "source": [
    "**Conclusion** :\n",
    "- Add a 'delete_multiple' built on *NumPy* - **DONE**\n",
    "- Maybe change the grid to a 4D-array :\n",
    "    - Pro : faster everything.\n",
    "    - Cons : waste of memory for system with density gradients, increasing size of the array costs much more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-seller",
   "metadata": {},
   "source": [
    "## Injector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    " # notebook\n",
    "from src.plotting import plot_particles, plot_boundaries\n",
    "import src.plotting.analysis as analysis\n",
    "from src.utils import inject \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signature : inject(in_wall, in_vect, debit, vel_std, radius, dt)\n",
    "in_wall =  np.array([0,0,0,1]) # np.array([0,0,0,1]) # np.array([0,0,1,0]) # np.array([0,0,0,1]) # np.array([0,0,1,1])\n",
    "a = np.array([0,1,1])\n",
    "in_vect = np.array([1,0]) # (1/np.sqrt(2))*np.array([-1,1]) # -np.array([1,0]) #  -np.array([0,1]) # np.array([1,0])# (1/np.sqrt(2))*np.array([1,1])\n",
    "debit = 100000000 # particles / s\n",
    "dt = 0.001\n",
    "vel_std = 200. # m/s\n",
    "radius = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr, remains = inject(in_wall, in_vect, debit, vel_std, radius, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, np.expand_dims(in_wall, axis = 0))\n",
    "plot_particles(ax, arr, r = 10*radius, arrows = False)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(arr, columns = ['x', 'y', 'vx', 'vy', 'vz'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.velocity_distribution(df, bins = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-backup",
   "metadata": {},
   "source": [
    "## Advection (and schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import advect\n",
    "from src.utils import euler_explicit, leap_frog\n",
    "from src.plotting import plot_particles, plot_boundaries\n",
    "\n",
    "# notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signature : advect(arr, f, dt, args, scheme)\n",
    "arr = np.array([[1,1,1,1,0], [2,1,-1,-1,0]], dtype = float)\n",
    "#arr = np.random.random((10,5))\n",
    "def f(arr, dt):\n",
    "    return np.zeros(shape = (arr.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_ = np.copy(arr)\n",
    "advect(arr_, f, dt = 0.1, args = [], scheme = euler_explicit) # seems ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr__ =  np.copy(arr)\n",
    "advect(arr__, f, dt = 0.1, args = [], scheme = leap_frog) # seems ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_particles(ax, arr, r = 10) \n",
    "plot_particles(ax, arr_, r = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-dinner",
   "metadata": {},
   "source": [
    "## Collision with walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plotting import plot_boundaries, plot_particles\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized, make_collisions_out_walls\n",
    "import numpy as np\n",
    "N = 10\n",
    "walls = 1.5*np.array([[0,0,1,0], [0,0,0,1], [1,0,1,1], [0,1,1,1]]) # bottom, left, right, top\n",
    "a = np.array([[1,0, 1.5],[0,1, 1.5],[0,1, 1.5],[1,0, 1.5]])\n",
    "# arr = np.array([[2,0.5,1,0,0], [0.5,2,0,1,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [-0.5,0.5,-1,0,0]])  # np.random.random((N,5)) # \n",
    "arr = np.array([[1.5,2,1,1,0]])\n",
    "arr[:,2:] = 5*arr[:,2:]\n",
    "radius = 0.1\n",
    "idx_out_walls = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, walls)\n",
    "plot_particles(ax, arr, r = 8, arrows = True)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct, cp = handler_wall_collision(arr, walls, a, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr_1 = np.copy(arr)\n",
    "new_arr_2 = np.copy(arr)\n",
    "new_arr_3 = np.copy(arr)\n",
    "make_collisions(new_arr_1, a, ct, cp)\n",
    "make_collisions_vectorized(new_arr_2, a, ct, cp)\n",
    "indexes = make_collisions_out_walls(new_arr_3, a, ct, cp, idx_out_walls)\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "\n",
    "plot_boundaries(ax[0,0], walls)\n",
    "plot_particles(ax[0,0], arr, r = 8, arrows = True)\n",
    "\n",
    "plot_boundaries(ax[0,1], walls)\n",
    "plot_particles(ax[0,1], new_arr_1, r = 8, arrows = True)\n",
    "\n",
    "plot_boundaries(ax[1,0], walls)\n",
    "plot_particles(ax[1,0], new_arr_2, r = 8, arrows = True)\n",
    "\n",
    "plot_boundaries(ax[1,1], walls)\n",
    "plot_particles(ax[1,1], new_arr_3, r = 8, arrows = True)\n",
    "\n",
    "ax[0,0].axis('equal')\n",
    "ax[0,1].axis('equal')\n",
    "ax[1,0].axis('equal')\n",
    "ax[1,1].axis('equal')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-michael",
   "metadata": {},
   "source": [
    "#### Collision with walls - and outwalls\n",
    "\n",
    "Problem : sometimes a particle can collide and be reflected but remain outside the system. In such a case, we have to make sure the particle is reflected again, and as many time as necessary. In addition, particles that went out (by the out walls) should be taken into account and :\n",
    " - not reflected back into the system but instead removed\n",
    " - a particle can, after its second reflection in a row, finds itself going trough the 'out wall'. In such a case it should be added to the list of particle to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized, make_collisions_out_walls\n",
    "import numpy as np\n",
    "from src.plotting import plot_boundaries, plot_particles\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 10\n",
    "segments = 1.5*np.array([[0,0,1,0], [0,0,0,1], [1,0,1,1], [0,1,1,1]]) # bottom, left, right, top\n",
    "a = np.array([[1,0, 1.5],[0,1, 1.5],[0,1, 1.5],[1,0, 1.5]])\n",
    "arr = np.array([[-4,5.5,-1,1,0], [1.6,2,1,1,0],[2,0.5,1,0,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [-0.5,0.5,-1,0,0]])  # np.random.random((N,5)) # \n",
    "radius = 0.01\n",
    "idx_out_walls = [2] # 2 : Right\n",
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, segments)\n",
    "plot_particles(ax, arr, r = 8, arrows = True)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.full(shape = (arr.shape[0]), fill_value = True)\n",
    "idxes_out = []\n",
    "c = 0\n",
    "while(np.sum(count, where = count == True) > 0):\n",
    "        print(c)\n",
    "        c+=1\n",
    "        ct, cp = handler_wall_collision(arr[count], segments, a, radius)\n",
    "        print(cp)\n",
    "        count, idxes_out_ = make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "        idxes_out.append(idxes_out_)\n",
    "        fig, ax = plt.subplots()\n",
    "        plot_boundaries(ax, segments)\n",
    "        plot_particles(ax, arr, r = 8, arrows = True)\n",
    "        plt.axis('equal');\n",
    "        \n",
    "        #print(count)\n",
    "        if(c>20):\n",
    "            break\n",
    "print(c)\n",
    "idxes_out = np.concatenate(idxes_out)\n",
    "\n",
    "arr[idxes_out.shape[0]:,:] = np.delete(arr, idxes_out, axis = 0) # operation is not inplace\n",
    "c-=idxes_out.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e07cabc",
   "metadata": {},
   "source": [
    "### Collision with walls - cylinder - why does it not work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4fbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import handler_wall_collision, make_collisions, make_collisions_vectorized, make_collisions_out_walls, deal_with_corner\n",
    "import numpy as np\n",
    "from src.plotting import plot_boundaries, plot_particles\n",
    "import matplotlib.pyplot as plt\n",
    "from src.system_creator import SystemCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb265779",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 4\n",
    "circle = [[1.5+0.5*np.cos(k*np.pi/res), 1+0.5*np.sin(k*np.pi/res), 1.5+0.5*np.cos((k+1)*np.pi/res), 1+0.5*np.sin((k+1)*np.pi/res)] for k in range(2*res)]\n",
    "segments = 0.001*np.array([[0,0,3,0], [0,0,0,2], [3,0,3,2], [0,2,3,2]]+circle)\n",
    "system = SystemCreator(segments)\n",
    "\n",
    "offsets = system.get_offsets()\n",
    "system_shape = system.system_shape()\n",
    "a = system.get_dir_vects()\n",
    "segments = system.get_segments()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_boundaries(ax, segments, color = 'k')\n",
    "\n",
    "# liste_vectors_segment = np.concatenate((segments[:,:2], segments[:,:2]+0.001*a[:,:2]), axis = 1)\n",
    "# plot_boundaries(ax, liste_vectors_segment, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining particles\n",
    "# arr = 0.001*np.array([[-4,5.5,-1,1,0], [1.6,2,1,1,0],[2,0.5,1,0,0], [2,2,1,1,0], [0.5,0.5,1,0,0], [-0.5,0.5,-1,0,0]])  # np.random.random((N,5)) # \n",
    "arr = np.array([[0.0015, 0.001, 100, 0,0]])\n",
    "radius = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.full(shape = (arr.shape[0]), fill_value = True)\n",
    "idxes_out = []\n",
    "c = 0\n",
    "idx_out_walls = []\n",
    "while(np.sum(count, where = count == True) > 0):\n",
    "        c+=1\n",
    "        ct, cp = handler_wall_collision(arr[count], segments, a, radius)\n",
    "        print(ct)\n",
    "        deal_with_corner(ct)\n",
    "        print(ct)\n",
    "        count, idxes_out_ = make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "        idxes_out.append(idxes_out_)\n",
    "        fig, ax = plt.subplots()\n",
    "        plot_boundaries(ax, segments)\n",
    "        plot_particles(ax, arr, r = 1, arrows = False)\n",
    "        plt.axis('equal');\n",
    "\n",
    "        if(c>20):\n",
    "            break\n",
    "\n",
    "np.concatenate(idxes_out)\n",
    "\n",
    "# arr[idxes.shape[0]:,:] = np.delete(arr, idxes, axis = 0) # operation is not inplace\n",
    "# current-=idxes.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-angle",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-mortality",
   "metadata": {},
   "source": [
    "## Particles collisions\n",
    "\n",
    "Signatures of the functions :\n",
    "* candidates(currents, dt, average, pmax, volume_cell, mr, remains)\n",
    "* index_choosen_couples(current, candidates)\n",
    "* probability(vr_norm, pmax, cross_sections)\n",
    "* is_colliding(proba)\n",
    "* reflect(arr, vr_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import candidates, index_choosen_couples, probability, is_colliding, reflect\n",
    "import numpy as np\n",
    "from src.plotting import plot_particles, plot_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "currents = 10*np.array([\n",
    "    [16,22,14],\n",
    "    [9,13,11],\n",
    "    [4,9,6]\n",
    "])\n",
    "dt = 1e-7\n",
    "averages = 10*np.array([\n",
    "    [15,20,15],\n",
    "    [10,15,10],\n",
    "    [5,10,5]\n",
    "])\n",
    "radius = 2e-10\n",
    "cross_section = 4 * np.pi * radius**2\n",
    "pmax = cross_section * 600\n",
    "pmax_vect = cross_section * 600 * np.ones(averages.shape)\n",
    "print(pmax_vect.shape)\n",
    "volume_cell = (0.001)**3\n",
    "mr = 1e15\n",
    "remains = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "remains, cands = candidates(currents, dt, averages, pmax, volume_cell, mr, remains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f371a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remains, cands = candidates(currents, dt, averages, pmax_vect, volume_cell, mr, remains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [np.random.uniform(low = -1, high = 1, size = (current, 5)) for current in currents.flatten()]\n",
    "arr = np.concatenate(arrays, axis = 0)\n",
    "arr_save = np.copy(arr)\n",
    "print(arr.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_shape = currents.shape\n",
    "system_shape = (2.,2.)\n",
    "offsets = np.array([-1, -1])\n",
    "fig, ax = plt.subplots()\n",
    "plot_grid(ax, grid_shape, system_shape, offsets)\n",
    "plot_particles(ax, arr, r = 0.1)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-syndrome",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for count, (i, j) in enumerate(np.ndindex(currents.shape)):\n",
    "    choice = index_choosen_couples(currents[i,j], int(cands[i,j]))\n",
    "    vr_norm = np.linalg.norm((arrays[count][choice][:,1,2:]-arrays[count][choice][:,0,2:]), axis = 1)\n",
    "    proba = probability(vr_norm = vr_norm, pmax = pmax, cross_sections = cross_section)\n",
    "    collidings_couples = is_colliding(proba)\n",
    "    print(np.sum(collidings_couples))\n",
    "    # if(not all(~collidings_couples)):\n",
    "    #    ic(all(~collidings_couples))\n",
    "    #    ic(arr)\n",
    "    # can not be inplace\n",
    "    arrays[count][choice[collidings_couples]] = reflect(arrays[count][choice[collidings_couples]], vr_norm[collidings_couples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.concatenate(arrays, axis = 0)\n",
    "df1 = pd.DataFrame(arr_save, columns = ['x','y','vx','vy','vz'])\n",
    "df2 = pd.DataFrame(arr, columns = ['x','y','vx','vy','vz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "df1['vx'].plot.hist(bins=50, ax = ax[0,0])\n",
    "df1['vy'].plot.hist(bins=50, ax = ax[0,1])\n",
    "df2['vx'].plot.hist(bins=50, ax = ax[1,0])\n",
    "df2['vy'].plot.hist(bins=50, ax = ax[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "g = sns.JointGrid(data=df1, x=\"vx\", y=\"vy\", space=0)\n",
    "g.plot_joint(sns.kdeplot,\n",
    "             fill=True,\n",
    "             thresh=0, levels=100, cmap=\"rocket\")\n",
    "g.plot_marginals(sns.histplot, color=\"#03051A\", alpha=1, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "g = sns.JointGrid(data=df2, x=\"vx\", y=\"vy\", space=0)\n",
    "g.plot_joint(sns.kdeplot,\n",
    "             fill=True,\n",
    "             thresh=0, levels=100, cmap=\"rocket\")\n",
    "g.plot_marginals(sns.histplot, color=\"#03051A\", alpha=1, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "x = df1['x']\n",
    "y = df2['y']\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y, c=z, s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-bangladesh",
   "metadata": {},
   "source": [
    "### From grid, get particles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.utils import candidates, index_choosen_couples, probability, is_colliding, reflect\n",
    "\n",
    "currents = 10*np.array([\n",
    "    [24,26],\n",
    "    [25,25]\n",
    "], dtype = int)\n",
    "\n",
    "arr = [np.random.uniform(low = -1.0, high = 1.0, size = (1000,5))]\n",
    "arr_copy = np.copy(arr[0])\n",
    "# zer = np.zeros(250)\n",
    "t = np.arange(1000)\n",
    "np.random.shuffle(t)\n",
    "arr1, arr2, arr3, arr4 = np.split(t, indices_or_sections = [240,500,750], axis = 0)\n",
    "p1, p2 = np.stack((np.zeros(240), arr1), axis = 1), np.stack((np.zeros(260), arr2), axis = 1)\n",
    "p3, p4 = np.stack((np.zeros(250), arr3), axis = 1), np.stack((np.zeros(250), arr4), axis = 1)\n",
    "\n",
    "grid = np.array([\n",
    "    [p1, p2],\n",
    "    [p3, p4]],\n",
    "    dtype = np.ndarray)\n",
    "\n",
    "print(f'Currents : \\n {currents}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to get all that is in arr from grid...\n",
    "# and do this in place ... which will be VERY fucking hard\n",
    "# VERY SLOW\n",
    "cands = np.array([[120,123],[124,124]])\n",
    "cross_section = 1\n",
    "pmax = 2\n",
    "for k, (i, j) in enumerate(np.ndindex(currents.shape)):\n",
    "    choice = index_choosen_couples(currents[i,j], int(cands[i,j])) # choice contains the possible couples\n",
    "    # now, we have to get their pos and speed\n",
    "    g = grid[i,j]\n",
    "    parts = np.array([[g[c[0]], g[c[1]]] for c in choice], dtype = int)\n",
    "    array = np.array([[ arr[c[0,0]][c[0,1]] , arr[c[1,0]][c[1,1]] ] for c in parts])\n",
    "    # blablabla [...] -> DSMC etc.\n",
    "    # TODO: make those stuff and see if it still works\n",
    "\n",
    "    vr_norm = np.linalg.norm((array[:,1,2:]-array[:,0,2:]), axis = 1)\n",
    "    proba = probability(vr_norm = vr_norm, pmax = pmax, cross_sections = cross_section)\n",
    "\n",
    "    # TODO : should update pmax here (or return something)...\n",
    "    collidings_couples = is_colliding(proba)\n",
    "    array[collidings_couples] = reflect(array[collidings_couples], vr_norm[collidings_couples])\n",
    "    \n",
    "    for k in range(len(array)):\n",
    "        c1, c2 = array[k,0], array[k,1]\n",
    "        c = parts[k]\n",
    "        arr[c[0,0]][c[0,1]][:] = c1 # copy\n",
    "        arr[c[1,0]][c[1,1]][:] = c2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(arr_copy, arr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-server",
   "metadata": {},
   "source": [
    "### Reflection study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import reflect\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "arr = np.array([[[1,1,1,1,1], [1,1,-1,-1,1]]])\n",
    "vr_norm = np.linalg.norm((arr[:,1,2:]-arr[:,0,2:]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_ = reflect(np.copy(arr),vr_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr);\n",
    "print(arr_);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-painting",
   "metadata": {},
   "source": [
    "## Update position in grids - tests\n",
    "\n",
    "##### Idea : \n",
    "1. Create particles and initialize them in the grids\n",
    "2. Do something \n",
    "3. Update position in the grid\n",
    "\n",
    "For now, we are simply resetting all of them as it does not cost much to do so. (structured grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Grid, pos_in_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 100\n",
    "arr = np.random.uniform(low = -1, high = 1, size = (N,5))\n",
    "grid = Grid(np.array([3,7]), 10)\n",
    "\n",
    "from src.plotting import plot_particles, plot_grid\n",
    "resolutions = (3,7)\n",
    "system_shape = (2.,2.)\n",
    "offsets = np.array([-1, -1])\n",
    "fig, ax = plt.subplots()\n",
    "plot_grid(ax, resolutions, system_shape, offsets)\n",
    "plot_particles(ax, arr, r = 0.1)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grid_datatype(positions, new, old = 0):\n",
    "    index_container = np.zeros((new-old))\n",
    "    index_in_container = np.arange(old, new)\n",
    "    indexes = np.stack((index_container, index_in_container), axis = 1)\n",
    "    return np.concatenate((positions, indexes), axis = 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = pos_in_grid(arr[:,:2], resolutions, offsets, system_shape)\n",
    "particles = convert_to_grid_datatype(positions, new = positions.shape[0])\n",
    "print(particles[:10])\n",
    "grid.add_multiple(particles)\n",
    "print(grid.current);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.reset() # that's how we are going to do...\n",
    "print(grid.current);\n",
    "grid.add_multiple(particles)\n",
    "print(grid.current);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-construction",
   "metadata": {},
   "source": [
    "# Integration test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-mattress",
   "metadata": {},
   "source": [
    "Signatures :\n",
    " - SystemCreator(segments)\n",
    " - inject(in_wall, in_vect, debit, vel_std, radius, dt, remains)\n",
    " - advect(arr, f, dt, args, scheme)\n",
    " - handler_wall_collision(arr, walls, a, radius)\n",
    " - make_collisions_vectorized(arr, a, ct, cp)\n",
    " - Particle(part_type, charge, mass, radius, size_array)\n",
    " - Grid(resolutions, max_number_per_cell)\n",
    " - collider(arr, grid, currents, dt, average, pmax, cross_section, volume_cell, mr, remains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# system\n",
    "from src.system_creator import SystemCreator\n",
    "\n",
    "# Grid\n",
    "from src.utils import Grid, pos_in_grid, convert_to_grid_datatype\n",
    "\n",
    "# Particles\n",
    "from src.utils import Particle\n",
    "\n",
    "# injection \n",
    "from src.utils import inject\n",
    "\n",
    "# advection\n",
    "from src.utils import advect\n",
    "from src.utils import euler_explicit, leap_frog\n",
    "\n",
    "# collisions\n",
    "from src.utils import handler_wall_collision, handler_wall_collision_point, make_collisions_vectorized, make_collisions_out_walls, deal_with_corner\n",
    "\n",
    "# utils \n",
    "from src.utils import gaussian, maxwellian_flux, maxwellian_mean_speed, get_mass_part, mean_free_path, mean_free_time\n",
    "\n",
    "# systems\n",
    "from src.utils import systems\n",
    "\n",
    "# plotting \n",
    "from src.plotting import plot_boundaries, plot_particles, plot_grid, plot_system\n",
    "from src.plotting import analysis\n",
    "\n",
    "# collisions between particles\n",
    "from src.utils import handler_particles_collisions, candidates # candidates, index_choosen_couples, probability, is_colliding, reflect, \n",
    "\n",
    "# saving \n",
    "from src.data import Saver\n",
    "\n",
    "# other imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "np.random.seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System :\n",
    "dz = 0.001\n",
    "\n",
    "    # tube, square etc.\n",
    "system, idx_out_walls, idx_in_wall = systems.system_rectangle(lx = 0.01, ly = 0.001)\n",
    "\n",
    "    # thruster \n",
    "# dp = 0.001\n",
    "# isystem, idx_out_walls, idx_in_wall = systems.thruster_system(w_in = 5*dp, l_in = 3*dp, w1 = 3*dp, l1 = dp, l_int = dp, w2 = dp, l2 = 5*dp, w_out = 5*dp, l_out = dp, offsets = np.array([0,0]))\n",
    "\n",
    "    # cylinder\n",
    "# system, idx_out_walls, idx_in_wall = systems.cylinder_system(res = 4, lx = 0.003, ly = 0.001, cx = 0.0015 , cy = 0.0005, r = 0.0001)\n",
    "\n",
    "offsets = system.get_offsets()\n",
    "system_shape = system.system_shape()\n",
    "a = system.get_dir_vects()\n",
    "segments = system.get_segments()\n",
    "\n",
    "# grid :\n",
    "mean_number_per_cell = 1000\n",
    "max_number_per_cell = 10*mean_number_per_cell\n",
    "resolutions = np.array((10,1), dtype = int) # tube\n",
    "# resolutions = np.array((11,5), dtype = int) # thruster\n",
    "# resolutions = np.array((9,9), dtype = int) # cylinder\n",
    "\n",
    "grid = Grid(resolutions, max_number_per_cell)\n",
    "volume_cell = dz * system_shape[0]/resolutions[0] * system_shape[1]/resolutions[1]\n",
    "\n",
    "# Particles - 1 type \n",
    "density = 3.2e19 # m-3\n",
    "n_simu = mean_number_per_cell*np.prod(resolutions) # number of particles in the simulated system\n",
    "n_real = volume_cell * density * np.prod(resolutions) # number of particles in the real system\n",
    "mr = n_real/n_simu # macro particules ratio = number of particles in the real system / number of macro part in the simulated system\n",
    "density_dsmc = density/mr\n",
    "temperature = 300 # K\n",
    "\n",
    "part_type = 'I'\n",
    "charge, mass, radius = 0, get_mass_part(53, 53, 74), 2e-10\n",
    "size_array = 2*mean_number_per_cell*np.prod(resolutions)\n",
    "v_mean = maxwellian_mean_speed(temperature, mass)\n",
    "container = Particle(part_type, charge, mass, radius, size_array)\n",
    "cross_section = container.get_params()[3]\n",
    "\n",
    "# mean free path and time\n",
    "mfp = mean_free_path(cross_section, density)\n",
    "typical_lenght = 0.001\n",
    "mft = mean_free_time(typical_lenght, v_mean = v_mean)\n",
    "\n",
    "    # Injection params\n",
    "in_wall = segments[idx_in_wall]\n",
    "# you may have to change in_vect (adding a '-' should be enough) depending on the direction of injection of the particles\n",
    "in_vect = np.array([a[idx_in_wall,1], -a[idx_in_wall,0]]) # np.array([in_wall[3]-in_wall[1],in_wall[0]-in_wall[2]]) # a[idx_in_wall]\n",
    "\n",
    "debit = maxwellian_flux(density_dsmc, v_mean)*np.linalg.norm(in_wall[:2]-in_wall[2:])*dz\n",
    "vel_std = gaussian(temperature, mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da17a6-808a-455b-9534-58f8ebdd46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation params\n",
    "iterations = 1000\n",
    "dt = 1e-6 # in sec, should be a fraction of the mean free time\n",
    "\n",
    "# saving params\n",
    "saving_period = 10\n",
    "adding_period = 1\n",
    "\n",
    "# advection\n",
    "def f(arr, dt):\n",
    "    return np.zeros(shape = (arr.shape[0], 3))\n",
    "\n",
    "args = []\n",
    "scheme = euler_explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v_mean);\n",
    "print(mfp);\n",
    "print(mft);\n",
    "print(debit*dt);\n",
    "print(\"{:e}\".format(n_real))\n",
    "print(\"{:e}\".format(mr));\n",
    "print(vel_std)\n",
    "print(v_mean)\n",
    "new, remains = inject(in_wall, in_vect, debit*100, vel_std, radius, dt, 0)\n",
    "print(np.mean(np.linalg.norm(new[:,2:], axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_system(None, segments, radius, resolutions, system_shape, offsets);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a04e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAME tests\n",
    "from pathlib import Path\n",
    "\n",
    "dir_path = Path('results/')\n",
    "name = 'test_tube.h5'\n",
    "\n",
    "saver = Saver(dir_path, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-hotel",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['x','y','vx','vy','vz']) # bucket for the particles - index of particles is the iteration number\n",
    "\n",
    "# defining useful arrays and ints \n",
    "remains = 0 # fractionnal part of the number of particles to inject (it is then passed to the following time step)\n",
    "averages = np.full(shape = grid.current.shape, fill_value = mean_number_per_cell) # average number of particles per cell\n",
    "pmax = 2*v_mean*cross_section*np.ones(averages.shape) # max proba per cell in the simu\n",
    "remains_per_cell = np.zeros(shape = grid.current.shape, dtype = float) # remains per cell for the particles collisions step\n",
    "\n",
    "# SIMULATING\n",
    "print('|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|'.format(' it ', ' INIT ', ' INJECT ', ' DEL ', ' TRY'))\n",
    "print('{:-^56}'.format(''))\n",
    "\n",
    "for it in range(iterations): # tqdm\n",
    "    n1 = container.get_current()\n",
    "                   \n",
    "    # injecting particles\n",
    "    new, remains = inject(in_wall, in_vect, debit, vel_std, radius, dt, remains)\n",
    "    container.add_multiple(new)\n",
    "                   \n",
    "    n2 = container.get_current()-n1\n",
    "    \n",
    "    # PHASE : ADVECTING\n",
    "        # MOVING PARTICLES\n",
    "    arr = container.get_particles()\n",
    "    \n",
    "    if(it%adding_period == 0):\n",
    "        df = df.append(pd.DataFrame(data=arr, index=[it]*arr.shape[0], columns = ['x','y','vx','vy','vz']))\n",
    "    \n",
    "    advect(arr, f, dt, args, scheme) # advect is inplace\n",
    "    \n",
    "        # HANDLING BOUNDARIES \n",
    "    count = np.full(fill_value = True, shape = arr.shape[0])\n",
    "    idxes_out = []\n",
    "    c = 0\n",
    "    collisions_with_walls = 0\n",
    "    while(np.sum(count, where = count == True) > 0):\n",
    "        c+=1\n",
    "        ct, cp = handler_wall_collision_point(arr[count], segments, a) # handler_wall_collision(arr[count], segments, a, radius)\n",
    "        count, idxes_out_ = make_collisions_out_walls(arr, a, ct, cp, idx_out_walls, count) # idxes_out : indexes of the particles (in arr) that got out of the system\n",
    "        # tracking then number of wall collisions\n",
    "        if(c == 1):\n",
    "            collisions_with_walls = np.sum(count, where = count == True)\n",
    "        # the first value of np.sum(count, where = count == True) is then number of colliding particles !\n",
    "        idxes_out.append(idxes_out_)\n",
    "    \n",
    "    idxes_out = np.concatenate(idxes_out)\n",
    "    \n",
    "    # TODO : make delete multiple better - currently the function creates a new array where as we can do it inplace.\n",
    "    container.delete_multiple(idxes_out)\n",
    "    \n",
    "    arr = container.get_particles()\n",
    "    \n",
    "    # PHASE : COLLISIONS\n",
    "        # UPDATING GRID - HARD RESET\n",
    "        # TODO : change the way it's done\n",
    "    grid.reset()\n",
    "    positions = pos_in_grid(arr[:,:2], resolutions, offsets, system_shape)\n",
    "    particles = convert_to_grid_datatype(positions, new = positions.shape[0])\n",
    "    grid.add_multiple(particles)\n",
    "        \n",
    "        # DSMC\n",
    "        # TODO: make parallel\n",
    "    currents = grid.get_currents()\n",
    "    averages = (it*averages+currents)/(it+1) # may be it too violent ? \n",
    "    \n",
    "    remains_per_cell, nb_colls, pmax, monitor = handler_particles_collisions([arr], grid.get_grid(), currents, dt, averages, pmax, cross_section, volume_cell, mr, remains_per_cell, monitoring = True)\n",
    "    # PLOTTING AND SAVING (OPTIONAL)\n",
    "    if(it%saving_period==0 or it == iterations-1): # saving if last iterations too\n",
    "        saver.save(it = it, append = {\n",
    "                        'df' : df,\n",
    "                        'collisions_per_cell' : nb_colls, # evolution of the number of collisions per cell - size : grid.shape[0] x grid.shape[1] (2D)\n",
    "                        'total_distance' : float(monitor[0]), # evolution of the sum of the distance accross all cells \n",
    "                        'total_proba' : float(monitor[1]), # evolution of the sum of proba accross all cells\n",
    "                        'pmax_per_cell' : pmax,  # evolution of the sum of pmax - per cell (2D)\n",
    "                        'total_deleted' : len(idxes_out), # evolution of the number of deleted particles per cell (int)\n",
    "                        'averages_per_cell' : averages,\n",
    "                        'collisions_with_walls' : collisions_with_walls\n",
    "                  })\n",
    "        \n",
    "        # resetting dataframe to not use too much memory\n",
    "        df = pd.DataFrame(columns = ['x','y','vx','vy','vz'])\n",
    "        print('|{:^10}|{:^10}|{:^10}|{:^10}|{:^10}|'.format(it, n1, n2, idxes_out.shape[0], c))\n",
    "saver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from src.data import Saver\n",
    "from src.plotting import analysis\n",
    "dir_path = Path('results/')\n",
    "name = 'test_tube.h5'\n",
    "store = pd.HDFStore(dir_path/name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82cee6-1daa-4118-a18c-a7a633abac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_per_cell = store['collisions_per_cell'] \n",
    "df = store['df']\n",
    "pmax_per_cell = store['pmax_per_cell']\n",
    "averages_per_cell = store['averages_per_cell']\n",
    "total_deleted = store['total_deleted']\n",
    "total_distance = store['total_distance']\n",
    "total_proba = store['total_proba']\n",
    "collisions_with_walls = store['collisions_with_walls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d631f6-cd67-4d56-a30e-8f42abdf22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_index = df.index.unique().values\n",
    "nb_save = unique_index.shape[0]\n",
    "iterations = np.max(unique_index)\n",
    "adding_period = unique_index[1]-unique_index[0] # adding period - required to\n",
    "frames = unique_index[int(0.8*nb_save):nb_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892ad3b-7eb7-496d-89ec-60203405e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5fb7d",
   "metadata": {},
   "source": [
    "## Number of particles - evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "analysis.nb_particles_evolution(ax, store['df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a5201-2759-42ba-a8df-fe6eae2e712c",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50fd1de-cd30-4047-a1cd-7c6c27ffeaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "analysis.state(ax, df.loc[df.index == 999], c = None)\n",
    "# analysis.velocity_distribution(df, frames);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fae861-bbf6-4d34-82d6-ac9bdc01dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.spatial_hist2d(df, frames, val = 'vx', x_res = 10, y_res = 1, x_step = 0.001, y_step=0.001);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97277115",
   "metadata": {},
   "source": [
    "## Number of collisions between particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_collisions_per_cell = store['collisions_per_cell']\n",
    "nb_collisions_per_cell = nb_collisions_per_cell.groupby(nb_collisions_per_cell.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(nb_collisions_per_cell) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of collision : \\n', np.sum(nb_collisions_per_cell));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34ee3d-89ad-4719-8c69-e2ab6f2cc0d3",
   "metadata": {},
   "source": [
    "## Number of collisions with walls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea32de-aa38-46ce-a7de-4971356192ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(collisions_with_walls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210b44e",
   "metadata": {},
   "source": [
    "## DSMC - monitoring \n",
    "\n",
    "- proba (over the system - not by cell)\n",
    "- distance between collisioning particles (over the system - not by cell)\n",
    "- average number of particle per cell (by cell)\n",
    "- pmax (by cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = total_proba/nb_collisions_per_cell\n",
    "dist = total_distance/nb_collisions_per_cell\n",
    "print('Mean proba : {:e}'.format(np.mean(proba)))\n",
    "print('Mean distance : {:e} m'.format(np.mean(dist)))\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].plot(proba.index, proba, label = 'proba')\n",
    "ax[1].plot(dist.index, dist, label = 'distance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e53bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmax = pmax_per_cell.groupby(pmax_per_cell.index).sum()\n",
    "averages = averages_per_cell.groupby(averages_per_cell.index).sum()\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].plot(pmax, label = 'proba')\n",
    "ax[1].plot(averages, label = 'averages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f4f7b-9e64-400d-a5b2-164c522040c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speed_norm'] = np.sqrt(df['vx']**2+df['vy']**2+df['vz']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "# plt.style.use('seaborn-pastel')\n",
    "\n",
    "def update_hist(num, df):\n",
    "    #plt.cla() # to clear the current figure\n",
    "    dfit = df.loc[df.index == num]\n",
    "    # since we modifying scat we dont want to use plt.cla\n",
    "    scat.set_offsets(np.c_[dfit['x'],dfit['y']])\n",
    "    # scat.set_array(df['speed_norm'])\n",
    "    # plot_grid(ax, resolutions, system_shape)\n",
    "    ax.set_title('{}/{}'.format(num+1, 1000), fontsize=15)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "dfit = df.loc[df.index == 0]\n",
    "scat = ax.scatter(dfit['x'], dfit['y'], s=0.1, c = dfit['speed_norm'], cmap='seismic') #  c = df['speed_norm']\n",
    "plot_boundaries(ax, segments)\n",
    "# plot_grid(ax, resolutions, system_shape)\n",
    "ax.set_title('{}/{}'.format(1, 1000), fontsize=12)\n",
    "\n",
    "# ax.axis('equal')\n",
    "# ax.set_xlim(x_min, x_max)\n",
    "# ax.set_ylim(y_min, y_max)\n",
    "\n",
    "ax.axis('equal')\n",
    "# min_x, min_y, max_x, max_y = min(df['x']), min(df['y']), max(df['x']), max(df['y'])\n",
    "# ax.set(xlim=(-0.001, 0.011), ylim=(-0.0001, 0.0011))\n",
    "# ax.set(xlim=(0, 0.003), ylim=(0, 0.002))\n",
    "\n",
    "interval = 40 # 25 images per second\n",
    "\n",
    "anim = FuncAnimation(fig, update_hist, interval=interval, frames=1000, fargs=(df, ), save_count=1000)\n",
    "# plt.show()\n",
    "anim.save('system_evo_thruster_test.mp4', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ce723-babc-4290-a33c-bf48409a322e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reactions - collision with walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4b6e3-47fa-4532-95d3-d880127c3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as ld\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fedac-4ed9-4efd-a1ef-941648354c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1.2,3.2,1,2,0], [1.2,3.2,9,1,10], [1.2,3.2,4,6,4], [1.2,3.2,1,2,1]])\n",
    "count = np.array([2, 0, 1, 1])\n",
    "\n",
    "law = lambda part, c : (0.5)**c # part = [x,y,vx,vy,vz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75319879-aeeb-47ea-87d0-7b3e788b24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reacts = ld.advection.reactions.basic(arr, count, law)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d633ef-e1cb-431a-941c-109e565a4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "reacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e77260-455b-489e-bc90-33d933126d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = np.random.random(10)\n",
    "proba = np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a1978-91c3-48c6-a365-7cd83c5e17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(proba>draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82418451-5d16-43ac-804a-44bab452e44a",
   "metadata": {},
   "source": [
    "## Adding reactioons betweeen particles\n",
    "\n",
    "Following this [article](https://doi.org/10.1080/00268976.2019.1602740). The goal is to make a \"background gas\" (made of $[I]$), interacting with it (collisions and reactions) and follow two species : the ion $[I^-]$ and the Iodine $[I]$.\n",
    "\n",
    "To simplify the approach, the background gas will not be updated.\n",
    "\n",
    "What needs to be implemented is :\n",
    "1. The background gas\n",
    "2. The collisions with it\n",
    "3. The potential reactions resulting from these collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05030395-d192-430b-92c2-e876973e9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56f69a-bef6-4707-9707-6d19319ff9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for particle sent ONE by ONE.\n",
    "# which is why its okay doing it this way.\n",
    "\n",
    "class BackgroundGas(object):\n",
    "    # compatible with as many species as we want\n",
    "    # densities - shape : number of species x number of cells\n",
    "    # or : number of cells x number of species (this has the advantage that we are iterating over the cells)\n",
    "    # which would result in better performance most likely.\n",
    "    # this is easy to revert though\n",
    "    \n",
    "    # second question is : how to take into acccount the functional / non functional forms ? (and use the efficiently).\n",
    "    \n",
    "    def __init__(self, densities, velocities, species, diameters, frequency_update = 10):\n",
    "        # we are considering that *number_of_velocities* is the same for every specie, and direction.\n",
    "        self.densities = densities # shape : number of cells x number of species - ndarrays of floats\n",
    "        self.dynamics = velocities # shape : number of cells x number of species x 3 - ndarray of object of type DistributionSampler\n",
    "\n",
    "        self.frequency_update = frequency_update # for now it is not used\n",
    "        self.species_dict = species # e.g. : {'I': 1, 'I-' : 2}\n",
    "        self.diameters = diameters # e.g. : {'I':2e-10, } # in meter\n",
    "\n",
    "    def probability(self, position, species, diameter, vel, dt, approx = None):\n",
    "        density = self.densities[position, self.species_dict[species]]\n",
    "        if(diameter == None):\n",
    "            cross_section = np.pi * self.diameters[self.species_dict[species]]\n",
    "        else:\n",
    "            cross_section = 0.5 * np.pi * (self.diameters[self.species_dict[species]]+diameter)\n",
    "            \n",
    "        if(approx == None):\n",
    "            # to do - a case without approximation\n",
    "            # vel_norm = ...\n",
    "            vr = np.linalg.norm(vel) # this is wrong\n",
    "            pass\n",
    "        elif(approx == 'faster'):\n",
    "            # vr ~ v_particle\n",
    "            vr = np.linalg.norm(vel)\n",
    "            # in this cas, the particle colliding is supposed to be much faster than the backgroung gas\n",
    "        elif(approx == 'slower'):\n",
    "            # vr ~ v_background_gas\n",
    "            vr = self.dynamics[position, self.species_dict[species]].mean_speed()\n",
    "        elif(approx == 'equal'):\n",
    "            # vr = vr_background_gas\n",
    "            vr = self.dynamics[position, self.species_dict[species]].mean_relative_speed()\n",
    "\n",
    "        return self.proba_collision(density, cross_section, vr, dt)\n",
    "    \n",
    "    # probability of collision with each gaz \n",
    "    def proba_collision(self, density, cross_section, vr, dt): # the one used in the article by Schullian - it is an approximation though (for small values of V)\n",
    "        return density * cross_section * vr * dt\n",
    "    \n",
    "    def update(self):\n",
    "        # should update each distribution, and the proba computed with those\n",
    "        pass\n",
    "    \n",
    "class DistributionSampler(object):\n",
    "    \n",
    "    def __init__(self, params, functional = True):\n",
    "        \n",
    "        self.params = params\n",
    "        self.functional = functional\n",
    "        if(functional):\n",
    "            self.random_variates = self.params\n",
    "        else:\n",
    "            self.current = 0\n",
    "            self.number_of_samples = self.params.shape[0]\n",
    "            self.random_variates = lambda size : np.choice(self.params, size=size, replace=True, p=None) # self.params should be 1D, if not this function should fails\n",
    "        \n",
    "    def draw(self, size = 1):\n",
    "        return self.random_variates(size)\n",
    "    \n",
    "    def update(self, new):\n",
    "        if(self.functional):\n",
    "            print(\"You cannot update a distribution which was given in a functional form.\")\n",
    "        else:\n",
    "            # replacing the k \"older\" ones by k more recent ones ; k = new_params.shape[0]\n",
    "            next_current = self.current + new.shape[0]\n",
    "            if(next_current > self.number_of_samples):\n",
    "                self.params[self.current:] = new[:self.number_of_samples-self.current]\n",
    "                next_current %= self.number_of_samples\n",
    "                self.params[:next_current] = new[self.number_of_samples-self.current:]\n",
    "            else:\n",
    "                self.params[self.current:next_current] = new\n",
    "                \n",
    "            self.current = next_current%self.number_of_samples\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b27d0a-3b4a-4345-a709-83ab7f4f3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a grid of 3 cells\n",
    "# we will make 4 distributions basically\n",
    "# considering it the same for vy, vz, for all cells\n",
    "# and that there is a different drift added in each cell along vx\n",
    "vx_distrib_form = lambda drift, std : (lambda size: np.random.normal(loc = drift, scale = std, size=size))\n",
    "vx1_distrib = DistributionSampler(params = vx_distrib_form(100, 200))\n",
    "vx2_distrib = DistributionSampler(params = vx_distrib_form(120, 200))\n",
    "vx3_distrib = DistributionSampler(params = vx_distrib_form(110, 200))\n",
    "vyz_distrib = DistributionSampler(params = vx_distrib_form(0, 200))\n",
    "densities = np.array([[3.2e19],[3.0e19],[2.5e19]], dtype = float)\n",
    "velocities = np.array([[vx1_distrib,vyz_distrib,vyz_distrib],[vx2_distrib,vyz_distrib,vyz_distrib],[vx2_distrib,vyz_distrib,vyz_distrib]], dtype = DistributionSampler)\n",
    "species = ['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54250d95-d7a6-4c95-8b00-7d279cb6b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_gas = BackgroundGas(densities = densities, velocities = velocities, species = species) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb7933-fa25-433e-8101-cfa1b54fd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBABILITY OF COLLISION\n",
    "\n",
    "def proba_approx(density, v1, cross_section, dt): # in our case, we will suppose relative velocity ~ v1 (because the ion is much much faster than the background gas)\n",
    "    return density*np.linalg.norm(v1)*cross_section*dt # proba that the particle collided with the slow background gas of density *density*.\n",
    "\n",
    "def proba(v1, v2, cross_section, cell_volume, dt):\n",
    "    return np.linalg.norm(v2-v1)*cross_section*dt/cell_volume\n",
    "\n",
    "def proba_gas(density, mean_speed_times_cross_section, dt): # the one used in the article by Schullian\n",
    "    return density * mean_speed_times_cross_section * dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea29581-ad01-4ac2-b668-214ca109c450",
   "metadata": {},
   "source": [
    "# Reactions with walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036c1797-4e08-43e3-b534-26c20c65c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc.advection.reactions as reactions\n",
    "import lppydsmc as ld\n",
    "path = 'walls_reactions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda7fadc-df3f-46a6-9856-1a83d813dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-': {'#': 1, 'reactants': ['I-'], 1: ['I']}, 'I2': {'#': 3, 'reactants': ['I2'], 1: ['I', 'I'], 2: ['I-', 'I+'], 3: ['I+', 'I']}}\n"
     ]
    }
   ],
   "source": [
    "print(reactions.parse_file(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cbfaf2f-3ac0-407e-971c-8459c0b279c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def p(size):\n",
    "    proba = np.random.uniform(low=0.0, high=1.0, size = size)\n",
    "    return (proba*p_+1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4613a2c4-4ea4-4368-b5b8-5cdf285f1839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ = 1\n",
    "p(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d342a4-a34d-4a8c-8933-cb3620b7d2a5",
   "metadata": {},
   "source": [
    "## testing reactions functions - with walls to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e677b96f-16eb-45f7-9222-3f0f6cb96c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_reacting_particles = np.array([[1]], dtype = int)\n",
    "\n",
    "arr1 = np.array([[0,0,3,4,0],[0,0,0,-4,0,]])\n",
    "arr2 = np.array([[0,0,2,3,0],[0,0,-1,17,9,]])\n",
    "arrays = [arr1, arr2]\n",
    "\n",
    "masses = np.array([1,2], dtype = float)\n",
    "\n",
    "types_dict = {\n",
    "    'I' : 0,\n",
    "    'I-' : 1\n",
    "}\n",
    "\n",
    "reactions_list = [\n",
    "    'I- : I'\n",
    "]\n",
    "nb_species = 2\n",
    "types = ['I', 'I-']\n",
    "reactions_dict = reactions.parse(reactions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72a2498a-a751-4281-af7d-044a37365a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "reacting_particles, particles_to_add = ld.advection.reactions.react(idx_reacting_particles, arrays, masses, types_dict, reactions_dict['I-'], p = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ca1c9c8-e8f1-4f59-aad5-089be43f2446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-': {'#': 1, 'reactants': ['I-'], 1: ['I']}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reactions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "123a7350-277f-4521-af6f-73f76d8f06ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reacting_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d188d3f5-dccb-4246-a366-d4d34d435f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': [array([-2., 34., 18.])]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particles_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d136815-1853-42cf-9f44-10832af4cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_counts = [np.array([]), reacting_particles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d545c4b0-37fd-4cfe-a814-ffc37ef0d2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE\n",
      "I - 0\n",
      "Deleting 0 particles of type I\n",
      "ADDING - I - 1\n",
      "I- - 1\n",
      "Deleting 1 particles of type I-\n"
     ]
    }
   ],
   "source": [
    "# print(f'Total collision with walls: {collisions_with_walls}')\n",
    "print('DELETE')\n",
    "for k in range(nb_species): # here it's only one particle as it is colliding with the wall\n",
    "    # thus it is easier to delete\n",
    "    print('{} - {}'.format(types[k], list_counts[k].shape[0]))\n",
    "    print(f'Deleting {len(list_counts[k])} particles of type {types[k]}')\n",
    "    # containers[k].delete_multiple(list_counts[k])\n",
    "    if(types[k] in particles_to_add):\n",
    "        print('ADDING - {} - {}'.format(types[k], len(particles_to_add[types[k]])))\n",
    "        # containers[k].add_multiple(np.array(particles_to_add[types[k]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b64af-1f4b-4565-8b02-eb77525dc14e",
   "metadata": {},
   "source": [
    "### Cfg - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729c68a3-1eff-4c22-9b52-7cee94a19afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as %ldir\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d407586-d0cd-4515-81dd-8df17b14ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_cfg = \"lppydsmc/config/example.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbef70d-4285-4c62-8633-c3cc2fbb1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ld.config.cfg_reader.read(path_to_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a8ebd-7450-4cc9-a993-6f5e665990de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(config.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29de3d7-e6ca-4ad7-9c94-6d7c90d1c93b",
   "metadata": {},
   "source": [
    "## Testing cfg run module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26640281-f2af-48ca-aef4-f0eb636abdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as ld\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afdbd5a4-8d7a-436e-9098-ed8f5fd7fdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:29<00:00, 17.06it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_cfg = \"lppydsmc/config/example.ini\"\n",
    "params = ld.run.run(path_to_cfg, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b966bb-551a-406d-9a97-299be03fb35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container filled at 5 x 449/18000 - Particle I : m = 2.160e-25 kg - q = 0.000e+00 C, r = 2.000e-10 m, cs = 5.027e-19 m2\n",
      "Container filled at 5 x 279/18000 - Particle I2 : m = 4.320e-25 kg - q = 0.000e+00 C, r = 2.660e-10 m, cs = 8.891e-19 m2\n",
      "Container filled at 5 x 4/162 - Particle I- : m = 2.160e-25 kg - q = -1.600e-19 C, r = 2.000e-10 m, cs = 5.027e-19 m2\n",
      "Container filled at 5 x 2/180 - Particle I+ : m = 2.160e-25 kg - q = 1.600e-19 C, r = 2.000e-10 m, cs = 5.027e-19 m2\n",
      "Container filled at 5 x 0/18 - Particle e- : m = 9.000e-31 kg - q = -1.600e-19 C, r = 2.800e-15 m, cs = 9.852e-29 m2\n"
     ]
    }
   ],
   "source": [
    "for key, val in params['setup']['containers'].items():\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaaeebda-d626-483b-b1a6-c3a0392fbe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/calot/Documents/projets/lppydsmc/results/cfg_tests/example/monitoring.h5\n"
     ]
    }
   ],
   "source": [
    "# quick analysis - just loading the hdf5\n",
    "path = params['setup']['path']/'monitoring.h5'\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8088c94f-32e3-40b4-9749-aad744ca8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "133436b6-d9f8-4e08-a9b7-b4e6c9601d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/dsmc_collisions',\n",
       " '/dsmc_tracking',\n",
       " '/fluxes',\n",
       " '/out_particles',\n",
       " '/particles',\n",
       " '/wall_collisions']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c526faf5-201d-454b-a2ce-526bb2269223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           in  out\n",
       "species           \n",
       "0.0      40.0  4.0\n",
       "1.0      22.0  6.0\n",
       "2.0       0.0  0.0\n",
       "3.0       3.0  0.0\n",
       "4.0       0.0  0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['fluxes'].groupby('species').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac40ec3-a4a5-479b-92c2-692e99ad3936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.097942</td>\n",
       "      <td>-64.483980</td>\n",
       "      <td>-70.999019</td>\n",
       "      <td>-217.069107</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.018271</td>\n",
       "      <td>-91.542858</td>\n",
       "      <td>422.012482</td>\n",
       "      <td>41.608822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>-0.000165</td>\n",
       "      <td>0.790314</td>\n",
       "      <td>-86.849304</td>\n",
       "      <td>262.801457</td>\n",
       "      <td>-196.828448</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-0.000352</td>\n",
       "      <td>0.575575</td>\n",
       "      <td>-192.892495</td>\n",
       "      <td>-273.955835</td>\n",
       "      <td>552.126195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.000580</td>\n",
       "      <td>0.291321</td>\n",
       "      <td>-477.168419</td>\n",
       "      <td>634.686763</td>\n",
       "      <td>990.690483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.000107</td>\n",
       "      <td>0.290153</td>\n",
       "      <td>-244.731716</td>\n",
       "      <td>-19.149619</td>\n",
       "      <td>-422.012169</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.000424</td>\n",
       "      <td>0.318646</td>\n",
       "      <td>-361.687988</td>\n",
       "      <td>158.361502</td>\n",
       "      <td>815.654353</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>-0.000548</td>\n",
       "      <td>0.623547</td>\n",
       "      <td>-285.529161</td>\n",
       "      <td>-192.840088</td>\n",
       "      <td>68.492630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.000148</td>\n",
       "      <td>0.423337</td>\n",
       "      <td>-298.369176</td>\n",
       "      <td>396.681956</td>\n",
       "      <td>-4.735549</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>-0.000127</td>\n",
       "      <td>0.721899</td>\n",
       "      <td>-362.398142</td>\n",
       "      <td>40.778194</td>\n",
       "      <td>286.158906</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y          vx          vy          vz  species\n",
       "20  -0.000068  0.097942  -64.483980  -70.999019 -217.069107      1.0\n",
       "200 -0.000029  0.018271  -91.542858  422.012482   41.608822      0.0\n",
       "230 -0.000165  0.790314  -86.849304  262.801457 -196.828448      0.0\n",
       "240 -0.000352  0.575575 -192.892495 -273.955835  552.126195      0.0\n",
       "300 -0.000580  0.291321 -477.168419  634.686763  990.690483      0.0\n",
       "300 -0.000107  0.290153 -244.731716  -19.149619 -422.012169      1.0\n",
       "300 -0.000424  0.318646 -361.687988  158.361502  815.654353      1.0\n",
       "310 -0.000548  0.623547 -285.529161 -192.840088   68.492630      1.0\n",
       "350 -0.000148  0.423337 -298.369176  396.681956   -4.735549      1.0\n",
       "390 -0.000127  0.721899 -362.398142   40.778194  286.158906      1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['out_particles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34958d9c-7ddc-4e2e-8e65-3e0344001439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x  y  vx  vy  vz\n",
       "species                  \n",
       "0.0      4  4   4   4   4\n",
       "1.0      6  6   6   6   6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['out_particles'].groupby('species').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7b8f4-3439-4ce2-a6f1-9dd32ff88994",
   "metadata": {},
   "source": [
    "# Computing an approximation of a given volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39645a96-27b4-41ea-b694-8a05de6e1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "import lppydsmc as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "253eae00-c19f-453d-ad5f-8c216894c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([(0,0),(0,1),(1,2),(1,0)])\n",
    "samples = [10,100,1000,int(1e4),int(1e5), int(1e6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1df7bb-132e-41ba-83aa-1f93adebb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples :\n",
    "    t1 = time()\n",
    "    print(ld.utils.estimation.estimate_surface(sample, points)) \n",
    "    # works but it is pretty slow - I should see for reusing my algorithms which are vectorized and kind of optimized already\n",
    "    print('Time : {} s'.format(time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4e215-4997-4966-bea8-22d8a9626600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fe12c-6121-4ad5-9478-a24ad375ea2b",
   "metadata": {},
   "source": [
    "# Tests with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ced2a7-6e90-428e-9fc4-74484a985cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a0134a-978c-41f9-9f17-ed0b5f3934df",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros((2,3))\n",
    "inject = np.array([10,23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76d494f-34d5-42da-a710-58bc850af66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[:,0] = inject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f21b60-7d1e-4b3d-af94-d354b7ece6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.,  0.,  0.],\n",
       "       [23.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa10fd7-a3ca-4f3b-8a8d-a873a5d8a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lppydsmc as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3040bf0-03d5-446e-a478-cd5745e6e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "debits = np.array([1.108301380e8, 2.13390831e8, 1.10397103987e9])\n",
    "remains = np.array([0.9, 0.85, 0.2])\n",
    "dt = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e41f3bb-9056-45b7-8cc7-4b3ed2a2cab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.20138  , 0.75831  , 0.9103987]), array([ 1109,  2134, 11039]))\n"
     ]
    }
   ],
   "source": [
    "print(ld.injection.get_quantity(debits, remains, dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72626f40-35f3-4705-8a2c-231401afa122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1108.30138  ,  2133.90831  , 11039.7103987])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debits*dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "375358ce-2b36-4c31-aaef-1d693c144303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject(remains, debits, dt):\n",
    "    remains[:], inject_qties = ld.injection.get_quantity(debits, remains, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a777e7b8-4f81-4bbb-ac7d-6c89b05627eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20138   0.75831   0.9103987]\n",
      "[0.50276   0.66662   0.6207974]\n"
     ]
    }
   ],
   "source": [
    "print(remains)\n",
    "inject(remains, debits, dt)\n",
    "print(remains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0afdea8b-f043-4e49-a988-4dd873f96233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5, 649],\n",
       "       [702, 705],\n",
       "       [889, 136],\n",
       "       [162, 951],\n",
       "       [153,  93],\n",
       "       [568, 631],\n",
       "       [896, 458],\n",
       "       [954, 130],\n",
       "       [444,  91],\n",
       "       [820, 773]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.collision.collider.index_choosen_couples(1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8728f142-1178-44ea-b5f9-da871fc75340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_np(X, groups, axis = 0, uf = np.add, out = None, minlength = 0, identity = None):\n",
    "    if minlength < groups.max() + 1:\n",
    "        minlength = groups.max() + 1\n",
    "    if identity is None:\n",
    "        identity = uf.identity\n",
    "    i = list(range(X.ndim))\n",
    "    del i[axis]\n",
    "    i = tuple(i)\n",
    "    n = out is None\n",
    "    if n:\n",
    "        if identity is None:  # fallback to loops over 0-index for identity\n",
    "            assert np.all(np.in1d(np.arange(minlength), groups)), \"No valid identity for unassinged groups\"\n",
    "            s = [slice(None)] * X.ndim\n",
    "            for i_ in i:\n",
    "                s[i_] = 0\n",
    "            out = np.array([uf.reduce(X[tuple(s)][groups == i]) for i in range(minlength)])\n",
    "        else:\n",
    "            out = np.full((minlength,), identity, dtype = X.dtype)\n",
    "    uf.at(out, groups, uf.reduce(X, i))\n",
    "    if n:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9031f592-8b7c-4d48-90da-914b5e364624",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_species = 3\n",
    "arr = np.array([[[0,103],[1,20]],[[0,1],[0,13]],[[1,4411],[2,94]],[[2,4411],[0,94]],[[2,4411],[2,94]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dca21d57-a36b-4414-bb6a-d50f082eb048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "545649c4-bc82-449c-a263-35cfafc66a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      0,       0,       0,       1,  829268, 1658536])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_np(X = arr, groups = np.array([1,0,4,2,5]), axis = 0, uf = np.multiply, out = None, minlength = 0, identity = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9dba078-3636-4479-b99d-40980437f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = (arr[:,0,0]*nb_species+arr[:,1,0]) # you would have to sort first !!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c3372bd-38c1-4805-a647-2fce53a643f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 5, 6, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2406dddb-211e-4b5b-9acb-2778b9b0fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad971922-ce05-4599-bcea-0772c7fa05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first function\n",
    "# grouping like we want to \n",
    "# not something generic\n",
    "\n",
    "def groups_1(arr, nb_species): # with the loops\n",
    "    groups = np.zeros(arr.shape[0])\n",
    "    for k, a in enumerate(arr):\n",
    "        c1, c2 = arr[0][0], arr[0][1]\n",
    "        if(c1>c2):\n",
    "            groups[k] = c1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf3756ed-725d-41d7-8db1-432512b4d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_species = 10\n",
    "groups = np.zeros((nb_species, nb_species))\n",
    "count = 0\n",
    "for i in range(nb_species):\n",
    "    for j in range(i, nb_species):\n",
    "        groups[i,j] = count\n",
    "        groups[j,i] = count\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18d895dd-e8f9-4f27-95a4-e0f094b954ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
       "       [ 1., 10., 11., 12., 13., 14., 15., 16., 17., 18.],\n",
       "       [ 2., 11., 19., 20., 21., 22., 23., 24., 25., 26.],\n",
       "       [ 3., 12., 20., 27., 28., 29., 30., 31., 32., 33.],\n",
       "       [ 4., 13., 21., 28., 34., 35., 36., 37., 38., 39.],\n",
       "       [ 5., 14., 22., 29., 35., 40., 41., 42., 43., 44.],\n",
       "       [ 6., 15., 23., 30., 36., 41., 45., 46., 47., 48.],\n",
       "       [ 7., 16., 24., 31., 37., 42., 46., 49., 50., 51.],\n",
       "       [ 8., 17., 25., 32., 38., 43., 47., 50., 52., 53.],\n",
       "       [ 9., 18., 26., 33., 39., 44., 48., 51., 53., 54.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0a65798-d93b-405a-be38-cf83e61b16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_groups(n):\n",
    "    groups = np.zeros((n, n))\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            groups[i,j] = count\n",
    "            groups[j,i] = count\n",
    "            count +=1\n",
    "    return groups\n",
    "\n",
    "# now we want a function that returns the group from the array\n",
    "def get_groups(arr, groups):\n",
    "    return groups[arr[:,0,0],arr[:,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ff71157-919d-4ea0-ad93-be9f1fd889cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "groups = set_groups(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d351e206-1a89-4664-b5b5-4f75b614f5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 4, 2, 5])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_groups(arr, groups).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835cfc1f-0c29-4261-90e9-77614adda84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = numpy.unique(a, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25f2d106-a25d-4c3c-867e-65efa261f7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 22 23 24 26 29]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "nb_groups = 10\n",
    "unique =  np.array([0,2,3,4,6,9])\n",
    "print(idx*nb_groups+unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c20da-c594-41df-88ac-2ad357fe0e73",
   "metadata": {},
   "source": [
    "# Testing on pandas datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6c5668-93c5-4f20-9e31-b7503e8681b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df705c25-c12c-4390-b873-a1e593862062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Index(['1', '2', '3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['1','2','3'])\n",
    "print(type(df)==pd.DataFrame)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af522cf-ae80-4c47-90d5-f498505e844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1  2  3\n",
      "2930  1  2  3\n",
      "2930  4  5  6\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1,2,3],[4,5,6]])\n",
    "iteration = 2930\n",
    "df = df.append(pd.DataFrame(data = arr, index = [iteration]*arr.shape[0], columns = ['1','2','3']))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f5e07a-7023-4605-8809-db2000926000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.DataFrame(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50843b51-b732-4b9e-9855-baf7c0061c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d86d59-3748-4f6f-918c-b14e7945eabc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
